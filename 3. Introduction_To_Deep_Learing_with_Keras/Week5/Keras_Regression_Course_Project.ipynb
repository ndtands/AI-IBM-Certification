{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Keras Regression Course Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MqyyONQmCn3N",
        "81e4fXjdCn3v"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRu07HvICnyV"
      },
      "source": [
        "# Importing the neccessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statistics as stats\n",
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from datetime import datetime\n",
        "\n",
        "# Forcing keras to use CPU.\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "0mtKqCCnCnzj",
        "outputId": "9a8a21c5-6348-4d87-ce8a-113525ba51e3"
      },
      "source": [
        "# Reading the Data and storing it in a dataframe\n",
        "\n",
        "df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  ...  Fine Aggregate  Age  Strength\n",
              "0   540.0                 0.0      0.0  ...           676.0   28     79.99\n",
              "1   540.0                 0.0      0.0  ...           676.0   28     61.89\n",
              "2   332.5               142.5      0.0  ...           594.0  270     40.27\n",
              "3   332.5               142.5      0.0  ...           594.0  365     41.05\n",
              "4   198.6               132.4      0.0  ...           825.5  360     44.30\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIPKnavAD9CN",
        "outputId": "e3c4240e-6f44-4458-dd23-e960cd9e974b"
      },
      "source": [
        "print('\\nShape of dataframe : ',df.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Shape of dataframe :  (1030, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "Zhv8B2BqCnzo",
        "outputId": "b23e53dc-2e8f-457e-e525-7384c3889a5b"
      },
      "source": [
        "# Summary of the dataset\n",
        "df.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "      <td>1030.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>281.167864</td>\n",
              "      <td>73.895825</td>\n",
              "      <td>54.188350</td>\n",
              "      <td>181.567282</td>\n",
              "      <td>6.204660</td>\n",
              "      <td>972.918932</td>\n",
              "      <td>773.580485</td>\n",
              "      <td>45.662136</td>\n",
              "      <td>35.817961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>104.506364</td>\n",
              "      <td>86.279342</td>\n",
              "      <td>63.997004</td>\n",
              "      <td>21.354219</td>\n",
              "      <td>5.973841</td>\n",
              "      <td>77.753954</td>\n",
              "      <td>80.175980</td>\n",
              "      <td>63.169912</td>\n",
              "      <td>16.705742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>121.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>801.000000</td>\n",
              "      <td>594.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>192.375000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>164.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>932.000000</td>\n",
              "      <td>730.950000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>23.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>272.900000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>968.000000</td>\n",
              "      <td>779.500000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>34.445000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>350.000000</td>\n",
              "      <td>142.950000</td>\n",
              "      <td>118.300000</td>\n",
              "      <td>192.000000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>1029.400000</td>\n",
              "      <td>824.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>46.135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>540.000000</td>\n",
              "      <td>359.400000</td>\n",
              "      <td>200.100000</td>\n",
              "      <td>247.000000</td>\n",
              "      <td>32.200000</td>\n",
              "      <td>1145.000000</td>\n",
              "      <td>992.600000</td>\n",
              "      <td>365.000000</td>\n",
              "      <td>82.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Cement  Blast Furnace Slag  ...          Age     Strength\n",
              "count  1030.000000         1030.000000  ...  1030.000000  1030.000000\n",
              "mean    281.167864           73.895825  ...    45.662136    35.817961\n",
              "std     104.506364           86.279342  ...    63.169912    16.705742\n",
              "min     102.000000            0.000000  ...     1.000000     2.330000\n",
              "25%     192.375000            0.000000  ...     7.000000    23.710000\n",
              "50%     272.900000           22.000000  ...    28.000000    34.445000\n",
              "75%     350.000000          142.950000  ...    56.000000    46.135000\n",
              "max     540.000000          359.400000  ...   365.000000    82.600000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNXQoRrvCnz1"
      },
      "source": [
        "<b>Note </b> : As the data is the same as used in this course, the video lectures have already shown that there is no need to perform any kind of pre-processing on the data. Hence, even the most common checks of data such as checking for missing values are not performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfuYHM6gCnz9",
        "outputId": "f7b6a034-528d-4be9-9470-4e8d15b17a6c"
      },
      "source": [
        "# Creating dataframes of features (X) and target (Y)\n",
        "X = df.iloc[:, 0:8]\n",
        "Y = df.iloc[:,8]\n",
        "\n",
        "# Printing the dataframes X and Y to ensure we have created the dataframes with the correct columns\n",
        "print('The features or the predictors (X) are : ', X, '\\n\\n') \n",
        "print('The target (Y) is : ', Y, '\\n\\n')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The features or the predictors (X) are :        Cement  Blast Furnace Slag  ...  Fine Aggregate  Age\n",
            "0      540.0                 0.0  ...           676.0   28\n",
            "1      540.0                 0.0  ...           676.0   28\n",
            "2      332.5               142.5  ...           594.0  270\n",
            "3      332.5               142.5  ...           594.0  365\n",
            "4      198.6               132.4  ...           825.5  360\n",
            "...      ...                 ...  ...             ...  ...\n",
            "1025   276.4               116.0  ...           768.3   28\n",
            "1026   322.2                 0.0  ...           813.4   28\n",
            "1027   148.5               139.4  ...           780.0   28\n",
            "1028   159.1               186.7  ...           788.9   28\n",
            "1029   260.9               100.5  ...           761.5   28\n",
            "\n",
            "[1030 rows x 8 columns] \n",
            "\n",
            "\n",
            "The target (Y) is :  0       79.99\n",
            "1       61.89\n",
            "2       40.27\n",
            "3       41.05\n",
            "4       44.30\n",
            "        ...  \n",
            "1025    44.28\n",
            "1026    31.18\n",
            "1027    23.70\n",
            "1028    32.77\n",
            "1029    32.40\n",
            "Name: Strength, Length: 1030, dtype: float64 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQDcZ_ioCn0G"
      },
      "source": [
        "<b>Note 1</b> : Unlike the method in this course, the splitting is done using indexing instead of using the names of the columns. Additionally, a different notation is used. The word <i>features</i> is used instead of <i>predictors</i>.\n",
        "\n",
        "\n",
        "<b>Note 2</b> : Pandas indexes columns starting from 0. Note in the code below for the features (X) indexing is used as `[:, 0:8]`. The first part preceding the coma `(:)` tells pandas to include ALL rows of the original dataframe (df) in the new dataframe called X while the part succedding the comma `(0:8)` tells pandas to include all columns of the original dataframe (df) starting from column with index = 0 and ending with column with index = 7, <b> but not to include the column with index = 8 </b>  \n",
        "\n",
        "<b>Note 3</b> : In order to split the data into train and test sets, the train_test_split function of the sklearn library is used. `The random_state` is used to ensure that the train and test split is the same each time, i.e. the train set and the test set have the same samples each time the code is run which is good for reproducing the results. If left empty, the random state is used by `np.random`. Since the Project requires splitting data the into <b>random</b> sets, hence `random_state` is not used, i.e. no value is set for random state. As the data hase to be split randomly  into train and test sets <b>50</b> times, a for loop will be used to to split the data in train test sets for <b>each model</b> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGS_ZMfjCn0u"
      },
      "source": [
        "def regression_model() :\n",
        "    \n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, activation='relu', input_shape=(X.shape[1],)))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5hCc4wMCn0y"
      },
      "source": [
        "def data_split() :\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "    \n",
        "    # Create a list containing X_train, X_test, Y_train, Y_test and return the list\n",
        "    splits = [X_train, X_test, Y_train, Y_test] \n",
        "    return splits"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSO4JZEdCn00"
      },
      "source": [
        "<b>Note </b> : In the above function `data_split()` the <i>X_train, X_test, Y_train, Y_test</i> sets are stored in a list and list is returned. This is to ensure that the <i>X_train, X_test, Y_train, Y_test</i> sets are not printed when the function is called"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByKfofKVCn01"
      },
      "source": [
        "def predict() :\n",
        "    return model.predict(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WCIcC1dCn02"
      },
      "source": [
        "def calculate_mse() :\n",
        "    return mean_squared_error(Y_test,Y_predicted)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd7c-eHhCn03"
      },
      "source": [
        "<b>Note 1</b> : The function `regression_model` as defined above only **compiles** the model and doesn't fit the model to training set. This is because in PART C, the number of epochs are changed and this would allow to fit the model with new number of epochs. This function will be used for **PART A**, **PART B** and **PART C**.\n",
        "\n",
        "<b>Note 2</b> : Since the splitting data, prediction and mean squared error calculations are all being used repeatly as well, hence there are separate functions created for them to remove redundancy of typing the same line of code while also making the code more neat. However,  as we the features (X) are to be normalized only **once**, hence there is no need to create a function for it\n",
        "\n",
        "<b>Note 3</b> : As the split function is executed first, the training and test sets are obtained and hence there is no need to explicitly pass any arguments to `predict()` and `calculate_mse()` functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJKT1KPFCn09"
      },
      "source": [
        "# <font color = blue> PART A : BUILDING A BASELINE MODEL </font>\n",
        "\n",
        "\n",
        "<b>The baseline model consists of the following : </b>\n",
        "    <ul>\n",
        "        <li> Input layer with 10 nodes </li>\n",
        "        <li> A single hidden layer with 10 nodes and ReLU activation function </li>\n",
        "        <li> Adam optimizer and mean squared error loss function </li>\n",
        "    </ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjrEc5j1Cn0-"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGehHvyhCn0-"
      },
      "source": [
        "## <font color = darkorange>Task 1 : Train and Test the Baseline Model</font>\n",
        "\n",
        "In order to train and test the the baseline model, the following steps are performed :\n",
        "<ol>\n",
        "    <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "    <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "    <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "    <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTrZAb_xCn1C"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Randomly split the data into <i>X_train, X_test, Y_train, Y_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpAoOMr_Cn1C"
      },
      "source": [
        "# Split data into X_train, X_test, Y_train, Y_test\n",
        "X_train, X_test, Y_train, Y_test = data_split()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0ta8fMGCn1D"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Train the model using <i>X_train, Y_train</i> using 50 epochs </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN2pJYRhCn1E",
        "outputId": "62ef20f4-484b-4345-a468-ada7af24b59a"
      },
      "source": [
        "# Create the model\n",
        "model = regression_model()\n",
        "\n",
        "# Fit the model on the train set\n",
        "model.fit(X_train, Y_train, validation_split=0.3, epochs=50)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 607.5514 - val_loss: 418.4524\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 397.4071 - val_loss: 347.5311\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 332.0757 - val_loss: 293.2103\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 270.6738 - val_loss: 250.0178\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 246.1282 - val_loss: 219.0081\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.5568 - val_loss: 196.0515\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.3123 - val_loss: 178.0841\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.0628 - val_loss: 167.1625\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.6251 - val_loss: 157.8757\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.8151 - val_loss: 148.1642\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 121.2527 - val_loss: 141.3624\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.4654 - val_loss: 138.1445\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.3748 - val_loss: 130.1969\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 115.8895 - val_loss: 130.9328\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 132.6247 - val_loss: 126.1688\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.1185 - val_loss: 122.3960\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.5347 - val_loss: 119.9969\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.0903 - val_loss: 116.3918\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.4013 - val_loss: 115.0304\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.8078 - val_loss: 110.9128\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 105.0038 - val_loss: 107.3742\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.3424 - val_loss: 105.7893\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.1575 - val_loss: 108.6058\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.6596 - val_loss: 103.9478\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.6440 - val_loss: 101.7520\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.8444 - val_loss: 104.8496\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.1101 - val_loss: 98.8585\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.7670 - val_loss: 97.4398\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.1294 - val_loss: 96.8619\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.3117 - val_loss: 104.2603\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 89.8809 - val_loss: 95.3344\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 93.2465 - val_loss: 94.2779\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.4197 - val_loss: 95.7241\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.1275 - val_loss: 91.5855\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.2255 - val_loss: 91.3659\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 82.8661 - val_loss: 90.5475\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.5811 - val_loss: 88.7216\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84.9937 - val_loss: 89.0958\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 85.8589 - val_loss: 87.0593\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.7627 - val_loss: 88.2118\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 83.8321 - val_loss: 88.9150\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 79.5673 - val_loss: 84.9176\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 93.5254 - val_loss: 93.0724\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 87.2058 - val_loss: 83.5957\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 81.8579 - val_loss: 82.3205\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 78.8594 - val_loss: 83.0366\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 86.8715 - val_loss: 82.3603\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 78.5956 - val_loss: 81.4551\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 73.5017 - val_loss: 80.2402\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 78.9873 - val_loss: 78.6525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56d4fc1438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfgW0GPaCn1e"
      },
      "source": [
        "### <font color = #2980B9> Step 3 : Get the predictions on the X_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxeFicsrCn1e"
      },
      "source": [
        "# Store the predictions in a variable Y_Predicted\n",
        "Y_predicted = predict()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5tW-5bKCn1f"
      },
      "source": [
        "<b>Note </b> : Y_test or the original values are also sometimes refered to as Y_true and this is the notation used in the examples found on the [mean square error page of sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html). However, in this notebook the Y_test notations is used for original values "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_QAoGnkCn1g"
      },
      "source": [
        "### <font color = #2980B9> Step 4 : Compute the <i>mean squared error</i> on the test set using sklearn </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5PLpb4mCn1j",
        "outputId": "6be1e009-4784-4a22-c9eb-e2f78f988fe8"
      },
      "source": [
        "# Calculate the mean square error\n",
        "mse = calculate_mse()\n",
        "#mse = mean_squared_error(Y_test,Y_predicted)\n",
        "print('Mean Square Error (MSE) of the Baseline Model is : ' , mse)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Square Error (MSE) of the Baseline Model is :  88.39285073988803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOV7lPHKCn1m"
      },
      "source": [
        "## <font color = darkorange>Task 2 : Create 50 Models and Calculate the <i>µ</i> & <i>σ</i> of their MSE Errors</font>\n",
        "\n",
        "In order to train 50 models and calulate the mean (µ) and standard deviation (σ) of their mean square errors (MSE)  :\n",
        "<ol>\n",
        "    <li>Create an empty list <code>list_of_mse</code> to store the mean square error of each of the models</li>\n",
        "    <li>Define a for loop and perform each of the following steps in the loop</li>\n",
        "        <ol>\n",
        "        <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "        <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "        <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "        <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "        <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "    </ol>\n",
        "</ol>\n",
        "\n",
        "<b>Note</b> : To calcuate the mean and standard deviation of the mean square errors (mse) of 50 models which are stored in <code>list_of_means</code>, I will be using the python library <code>statistics</code> which has builtin functions to help caluclate the mean and standard deviation of a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrQU4K6GCn1o"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Creating the <i>list_of_mse</i> list</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9Mw4_nUCn1o"
      },
      "source": [
        "# Create the empty lists\n",
        "list_of_mse = []"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwMRptMeCn1r"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Creating 50 Models, Calculating The MSE for Each and <i>µ</i> & <i>σ</i> of the 50 MSE Values in <i>list_of_mse</i> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHNDfpmYCn1s",
        "outputId": "cb71ddf3-bf87-4bf1-8ef4-4c5262ba7884"
      },
      "source": [
        "# Create the for loop to split the data, create, compile & fit model, evaluate & nake predictions, caluclate mse and store\n",
        "# in list_of_mse\n",
        "\n",
        "start_time = datetime.now() # Starting time of the for loop execution\n",
        "\n",
        "for i in range(50) :\n",
        "    # Split the data into train and test set\n",
        "    data_split()\n",
        "    \n",
        "    # Create and compile the regression model using the function regression_model as defined in TASK 1\n",
        "    model = regression_model()\n",
        "\n",
        "    # Fit the model on the train set\n",
        "    print('\\n\\n\\nTraining Model # ' , i+1 , '\\n\\n') # Print the Model Number that is being trained\n",
        "    model.fit(X_train, Y_train, validation_split=0.3, epochs=50)\n",
        "    print('\\n')\n",
        "    \n",
        "    # Make prediction on the test set\n",
        "    Y_predicted = predict()\n",
        "    \n",
        "    # Calculate the mean square error\n",
        "    mse = calculate_mse()\n",
        "    print('Mean Squared Error for Training Model # ', i+1 , ' : ', mse)\n",
        "    \n",
        "    # Add the mse to the list_of_mse list\n",
        "    list_of_mse.append(mse)\n",
        "\n",
        "end_time = datetime.now() # Ending time of the for loop execution\n",
        "\n",
        "# Print time taken for fitting 50 models and calucating the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nTotal Execution Time : ' , format(end_time - start_time))\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 632.1438 - val_loss: 508.2395\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 471.7532 - val_loss: 456.2940\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 469.7366 - val_loss: 420.8598\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 461.0926 - val_loss: 395.2240\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 404.3616 - val_loss: 364.9857\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 348.8219 - val_loss: 344.0170\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 318.0613 - val_loss: 325.5320\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 327.4472 - val_loss: 307.3285\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 323.8883 - val_loss: 290.9370\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 279.9023 - val_loss: 280.0568\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 301.9740 - val_loss: 265.6270\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 250.1368 - val_loss: 256.7651\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 261.1037 - val_loss: 246.6733\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 245.8949 - val_loss: 239.5490\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 245.7899 - val_loss: 231.6505\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.7604 - val_loss: 226.0651\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 211.1721 - val_loss: 221.2830\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.1992 - val_loss: 215.2593\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.1629 - val_loss: 209.9464\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.6458 - val_loss: 207.0801\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.6729 - val_loss: 202.0255\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.4091 - val_loss: 198.6682\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.0689 - val_loss: 194.7814\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.1144 - val_loss: 191.3807\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191.2579 - val_loss: 188.3773\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199.5627 - val_loss: 185.5901\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.7699 - val_loss: 182.9900\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.0437 - val_loss: 180.8962\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.3174 - val_loss: 177.4985\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.8661 - val_loss: 176.1222\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.7138 - val_loss: 172.7036\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.8317 - val_loss: 170.6884\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.3436 - val_loss: 167.8309\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.4203 - val_loss: 165.4081\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.6262 - val_loss: 163.3530\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 173.5119 - val_loss: 161.1704\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 152.6766 - val_loss: 159.7757\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.9937 - val_loss: 157.5445\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.1650 - val_loss: 156.3605\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.6143 - val_loss: 154.6019\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.1176 - val_loss: 152.5170\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.9252 - val_loss: 150.9693\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.5155 - val_loss: 149.5414\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.9842 - val_loss: 148.3712\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.1890 - val_loss: 146.8925\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  5  :  174.02342073178283\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  6 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 32337.1754 - val_loss: 11127.0000\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7687.3165 - val_loss: 2383.4084\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1883.0292 - val_loss: 1784.0530\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1710.4451 - val_loss: 1655.4330\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1595.7240 - val_loss: 1490.2795\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1534.7824 - val_loss: 1383.0295\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1282.6184 - val_loss: 1277.4265\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1259.0692 - val_loss: 1174.1489\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1154.1817 - val_loss: 1081.2004\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 949.3240 - val_loss: 992.6529\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 980.5081 - val_loss: 906.1340\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 845.9892 - val_loss: 829.4706\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 683.4562 - val_loss: 758.2737\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 749.5389 - val_loss: 693.5897\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 622.0085 - val_loss: 629.9928\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 569.6984 - val_loss: 575.8073\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 551.3320 - val_loss: 525.2567\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 480.2616 - val_loss: 485.4402\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 440.5878 - val_loss: 445.0269\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 413.2315 - val_loss: 410.2586\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 379.9034 - val_loss: 382.8139\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 370.9952 - val_loss: 355.8676\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 314.6731 - val_loss: 333.6690\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 331.3535 - val_loss: 314.4076\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 272.3107 - val_loss: 296.7563\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 269.3619 - val_loss: 281.9039\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 270.4732 - val_loss: 267.0592\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 270.8615 - val_loss: 255.5196\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219.4483 - val_loss: 243.3155\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221.5986 - val_loss: 233.0313\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 208.8608 - val_loss: 223.8398\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 210.5760 - val_loss: 217.0962\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 207.1669 - val_loss: 207.5897\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.1882 - val_loss: 203.0103\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.4315 - val_loss: 194.3420\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.9780 - val_loss: 189.8915\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.7345 - val_loss: 184.7081\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 184.3066 - val_loss: 180.0564\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 166.1299 - val_loss: 177.2808\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.2440 - val_loss: 173.1074\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.2245 - val_loss: 171.1025\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.8985 - val_loss: 168.1553\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.3640 - val_loss: 165.8035\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.4097 - val_loss: 164.8459\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.2451 - val_loss: 161.9229\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.2775 - val_loss: 160.7282\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.0125 - val_loss: 158.9437\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.5515 - val_loss: 156.9220\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.0322 - val_loss: 156.2260\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.1345 - val_loss: 154.3823\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  6  :  179.96899157979055\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  7 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 88981.3424 - val_loss: 31717.5430\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 21823.5822 - val_loss: 7546.8213\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6994.8450 - val_loss: 5070.5044\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4034.3152 - val_loss: 3290.2515\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2704.3404 - val_loss: 2673.3682\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2605.6673 - val_loss: 2350.5681\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2512.6527 - val_loss: 2120.4607\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2274.3413 - val_loss: 1924.8613\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1968.9640 - val_loss: 1759.9052\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1703.7942 - val_loss: 1611.6675\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1580.5388 - val_loss: 1483.3301\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1513.1301 - val_loss: 1365.7004\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1341.0336 - val_loss: 1258.6288\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1250.3953 - val_loss: 1157.6929\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1205.9962 - val_loss: 1076.4352\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1055.4004 - val_loss: 998.5903\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 981.1683 - val_loss: 922.1277\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 996.5797 - val_loss: 856.5120\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 818.5154 - val_loss: 798.8950\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 766.7895 - val_loss: 744.6812\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 686.1978 - val_loss: 696.3130\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 685.6021 - val_loss: 652.2028\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 637.8537 - val_loss: 611.4901\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 584.8204 - val_loss: 574.5823\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 570.0750 - val_loss: 540.5416\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 509.5679 - val_loss: 511.1959\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 513.0309 - val_loss: 479.2577\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 462.4053 - val_loss: 460.1332\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 435.9068 - val_loss: 432.4951\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 420.1823 - val_loss: 414.7949\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 392.2116 - val_loss: 390.7095\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 349.2320 - val_loss: 374.6998\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 352.5837 - val_loss: 359.1254\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 379.2321 - val_loss: 337.8654\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 336.8298 - val_loss: 325.6593\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.3559 - val_loss: 323.1266\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 304.8674 - val_loss: 303.6787\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 300.3926 - val_loss: 289.9463\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.1668 - val_loss: 280.3033\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 267.5232 - val_loss: 275.2912\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 266.4709 - val_loss: 265.4446\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.0552 - val_loss: 255.2959\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.6368 - val_loss: 254.7714\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 228.8799 - val_loss: 236.7600\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 236.8386 - val_loss: 240.4282\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219.2839 - val_loss: 229.4258\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.5768 - val_loss: 213.7736\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 217.8005 - val_loss: 209.1012\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.1247 - val_loss: 221.5085\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.9451 - val_loss: 196.4650\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  7  :  222.88510604751397\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  8 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 444327.2702 - val_loss: 248120.0938\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 201731.5211 - val_loss: 111198.8594\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93254.4678 - val_loss: 53810.5703\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 45472.4881 - val_loss: 25545.1934\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20469.9756 - val_loss: 11527.9219\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9400.4420 - val_loss: 5342.1660\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4655.5165 - val_loss: 3102.3225\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3063.2266 - val_loss: 2469.0046\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2655.2730 - val_loss: 2270.0178\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2343.5227 - val_loss: 2141.7063\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2044.9658 - val_loss: 2023.9701\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2224.6169 - val_loss: 1906.9866\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2043.6257 - val_loss: 1800.6925\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1828.2737 - val_loss: 1704.5427\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1788.7677 - val_loss: 1610.1567\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1817.3447 - val_loss: 1516.5492\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1634.7143 - val_loss: 1429.5320\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1511.9815 - val_loss: 1347.5984\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1515.5418 - val_loss: 1270.4757\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1443.6535 - val_loss: 1199.3705\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1295.3530 - val_loss: 1131.8617\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1421.0242 - val_loss: 1063.2880\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1134.8630 - val_loss: 1004.2475\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 994.0238 - val_loss: 948.3486\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1105.7811 - val_loss: 892.6638\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 959.4954 - val_loss: 841.0933\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1011.5837 - val_loss: 791.4896\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 857.0736 - val_loss: 747.3204\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 811.5449 - val_loss: 703.7729\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 738.1228 - val_loss: 662.6986\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 790.2933 - val_loss: 624.0687\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 738.8646 - val_loss: 587.8246\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 680.0245 - val_loss: 554.7827\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 624.7290 - val_loss: 522.9317\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 567.6029 - val_loss: 493.4831\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 552.0040 - val_loss: 465.9743\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 555.1631 - val_loss: 439.2960\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 562.3139 - val_loss: 414.9686\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 501.2556 - val_loss: 392.4796\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 500.2927 - val_loss: 371.1470\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 468.3302 - val_loss: 351.3107\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 443.0319 - val_loss: 334.0520\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 410.2875 - val_loss: 316.6391\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 388.3849 - val_loss: 300.8062\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 370.2801 - val_loss: 285.7383\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 337.3195 - val_loss: 272.2789\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 332.7980 - val_loss: 259.4682\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.4688 - val_loss: 247.5429\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 308.5051 - val_loss: 236.5902\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.4547 - val_loss: 226.3208\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  8  :  301.20438334949995\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  9 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 868026.0625 - val_loss: 628088.0625\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 568356.8070 - val_loss: 400869.4062\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361288.0515 - val_loss: 247033.0938\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219303.4605 - val_loss: 144466.0156\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125449.8704 - val_loss: 78163.8984\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 64669.2564 - val_loss: 30719.6660\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20722.7521 - val_loss: 5348.3081\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3914.4122 - val_loss: 3110.9648\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3025.2144 - val_loss: 2903.2773\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2899.9135 - val_loss: 2585.0203\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2237.1963 - val_loss: 2426.6345\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2195.3520 - val_loss: 2251.8179\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2216.4179 - val_loss: 2096.1165\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1924.4122 - val_loss: 1945.8038\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1743.5797 - val_loss: 1815.8893\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1826.3735 - val_loss: 1675.0248\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1527.7573 - val_loss: 1539.8696\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1438.7076 - val_loss: 1387.2330\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1355.0698 - val_loss: 1239.2485\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1282.8526 - val_loss: 1081.6906\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1015.0758 - val_loss: 941.2866\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 807.8267 - val_loss: 825.3411\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 727.5176 - val_loss: 727.8953\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 695.2438 - val_loss: 663.9482\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 590.5827 - val_loss: 606.4791\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 571.3527 - val_loss: 564.3829\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 521.4922 - val_loss: 530.0383\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 531.0006 - val_loss: 499.7112\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 505.3617 - val_loss: 474.4347\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 434.9871 - val_loss: 449.0190\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 473.4752 - val_loss: 427.2252\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 402.4158 - val_loss: 411.4955\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 374.0671 - val_loss: 390.7557\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 372.6112 - val_loss: 375.0580\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 338.6557 - val_loss: 362.9901\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 397.3541 - val_loss: 347.2699\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 338.8935 - val_loss: 333.9844\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 361.2050 - val_loss: 322.0235\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 319.0153 - val_loss: 312.5647\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 327.0103 - val_loss: 301.2126\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280.7707 - val_loss: 294.6161\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 291.8179 - val_loss: 283.6497\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.1234 - val_loss: 276.3940\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 303.3241 - val_loss: 268.9514\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.0083 - val_loss: 260.3995\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.2021 - val_loss: 256.8399\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.8074 - val_loss: 247.4531\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 281.9917 - val_loss: 241.1198\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.8292 - val_loss: 239.1841\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253.8533 - val_loss: 230.1432\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  9  :  266.4159208077549\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  10 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 1349.3694 - val_loss: 807.2802\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 699.6976 - val_loss: 533.8940\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 490.7844 - val_loss: 446.3005\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 414.4255 - val_loss: 414.9324\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 377.4096 - val_loss: 373.2279\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.5873 - val_loss: 360.4221\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 286.3611 - val_loss: 335.5714\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 265.8203 - val_loss: 325.9028\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253.3957 - val_loss: 301.3166\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 266.1782 - val_loss: 288.0427\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 222.8662 - val_loss: 295.9650\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.0170 - val_loss: 266.8083\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 225.7611 - val_loss: 254.8120\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.7368 - val_loss: 247.5733\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 213.7331 - val_loss: 238.2856\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 195.0116 - val_loss: 230.4965\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 203.2135 - val_loss: 222.5060\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.1215 - val_loss: 226.7876\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.0621 - val_loss: 208.5943\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.6316 - val_loss: 205.5670\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.7352 - val_loss: 198.2062\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 177.7508 - val_loss: 191.5764\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.9135 - val_loss: 186.7638\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.2120 - val_loss: 187.5420\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.3308 - val_loss: 178.7978\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.8757 - val_loss: 185.9864\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.2209 - val_loss: 172.5417\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.7804 - val_loss: 167.9491\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.4564 - val_loss: 165.3247\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 138.2134 - val_loss: 160.4445\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4107 - val_loss: 161.3237\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139.9222 - val_loss: 155.6867\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.9283 - val_loss: 152.7157\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.6119 - val_loss: 151.7231\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.0247 - val_loss: 146.9676\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.6079 - val_loss: 149.8324\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4687 - val_loss: 144.4295\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.5169 - val_loss: 141.0684\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.3986 - val_loss: 138.3945\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.8218 - val_loss: 136.3966\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.1068 - val_loss: 133.6647\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.4391 - val_loss: 132.2464\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4539 - val_loss: 133.2764\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.8324 - val_loss: 130.3714\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.8604 - val_loss: 131.9378\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.4672 - val_loss: 127.0919\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.4646 - val_loss: 135.6038\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.7014 - val_loss: 138.9466\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.5881 - val_loss: 133.9662\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.4878 - val_loss: 126.3820\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  10  :  138.38084809469603\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  11 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 2732.3893 - val_loss: 1351.1071\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1301.1127 - val_loss: 850.7175\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 732.3361 - val_loss: 620.0757\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 575.4598 - val_loss: 449.6897\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 452.7898 - val_loss: 344.6833\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 344.6020 - val_loss: 270.8232\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.1800 - val_loss: 225.1824\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.8684 - val_loss: 189.9606\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.1784 - val_loss: 167.6540\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.1828 - val_loss: 151.1627\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.0643 - val_loss: 143.1515\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.4345 - val_loss: 138.5136\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.3682 - val_loss: 137.8278\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.5330 - val_loss: 128.9202\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.1541 - val_loss: 125.7595\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.5107 - val_loss: 124.7092\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.2425 - val_loss: 119.9002\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.6017 - val_loss: 116.8837\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.4852 - val_loss: 118.4961\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.0976 - val_loss: 120.6743\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.6295 - val_loss: 110.8995\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.6092 - val_loss: 113.5637\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.5917 - val_loss: 109.1593\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.5333 - val_loss: 113.3032\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.2168 - val_loss: 103.7811\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.4206 - val_loss: 102.9044\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.3149 - val_loss: 101.8875\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.9319 - val_loss: 120.1179\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.5983 - val_loss: 100.8748\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 108.2747 - val_loss: 110.5932\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.1642 - val_loss: 108.9193\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4095 - val_loss: 104.6684\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.0315 - val_loss: 97.5762\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.3133 - val_loss: 95.6334\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.5473 - val_loss: 96.4979\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.5646 - val_loss: 95.6232\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.8018 - val_loss: 101.4713\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.4260 - val_loss: 96.0370\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.6335 - val_loss: 95.4226\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.3593 - val_loss: 99.8668\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7687 - val_loss: 95.7344\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.9207 - val_loss: 97.2753\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.5529 - val_loss: 99.3598\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.9435 - val_loss: 108.4039\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.7213 - val_loss: 94.9765\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.7024 - val_loss: 96.7883\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.8320 - val_loss: 94.9015\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4307 - val_loss: 95.1474\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.2111 - val_loss: 95.2093\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.4075 - val_loss: 99.4045\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  11  :  121.45406517059051\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  12 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 197406.2500 - val_loss: 81038.0703\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 58928.0241 - val_loss: 15754.1689\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 10426.4607 - val_loss: 1604.0953\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1424.0370 - val_loss: 1029.3002\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1000.5830 - val_loss: 790.2882\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 894.8286 - val_loss: 658.8221\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 747.1367 - val_loss: 604.3301\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 742.0053 - val_loss: 561.9006\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 643.7982 - val_loss: 520.4891\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 632.8489 - val_loss: 479.1469\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 556.4671 - val_loss: 441.6004\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 481.3318 - val_loss: 407.6166\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 443.6059 - val_loss: 371.0773\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 476.9301 - val_loss: 336.4826\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 398.2305 - val_loss: 307.1581\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.6738 - val_loss: 284.9446\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.2627 - val_loss: 265.5285\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 348.3769 - val_loss: 250.3561\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.0950 - val_loss: 235.5286\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.7673 - val_loss: 222.7276\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.6418 - val_loss: 213.4314\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.2829 - val_loss: 204.6182\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.8718 - val_loss: 197.7408\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.2852 - val_loss: 191.9484\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.7523 - val_loss: 185.9549\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 208.2843 - val_loss: 181.5935\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.3476 - val_loss: 176.5499\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.0579 - val_loss: 173.4322\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.5073 - val_loss: 168.4508\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.7729 - val_loss: 165.5281\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.4232 - val_loss: 160.6623\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.5186 - val_loss: 158.2153\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.2806 - val_loss: 154.4446\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.1537 - val_loss: 152.5996\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.2675 - val_loss: 148.3571\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.8456 - val_loss: 146.8981\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.1656 - val_loss: 142.8813\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.8037 - val_loss: 142.6449\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.0231 - val_loss: 137.7105\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.6180 - val_loss: 136.8348\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4104 - val_loss: 134.2734\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.0917 - val_loss: 131.5193\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.4666 - val_loss: 129.5031\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.4455 - val_loss: 127.4819\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.4854 - val_loss: 125.9541\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.5210 - val_loss: 123.0020\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.9329 - val_loss: 122.0381\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.6190 - val_loss: 120.3595\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.5639 - val_loss: 118.6949\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.1391 - val_loss: 116.7946\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  12  :  146.5552513932734\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  13 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 12ms/step - loss: 5251.0202 - val_loss: 2462.1792\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2110.1428 - val_loss: 1879.2114\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2045.7834 - val_loss: 1549.3667\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1512.1454 - val_loss: 1283.2255\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1208.1005 - val_loss: 1056.0947\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 969.4835 - val_loss: 845.8251\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 718.0598 - val_loss: 714.2693\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 552.5667 - val_loss: 626.5213\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 518.9071 - val_loss: 572.3730\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 472.9234 - val_loss: 511.9303\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 403.8311 - val_loss: 481.7523\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 405.0994 - val_loss: 467.0320\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.0609 - val_loss: 435.0701\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 390.4424 - val_loss: 426.3928\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 340.3173 - val_loss: 408.5313\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 312.9052 - val_loss: 388.2114\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 316.7160 - val_loss: 387.5637\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 329.7141 - val_loss: 366.9175\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 318.8935 - val_loss: 367.9884\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 306.8445 - val_loss: 336.0022\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 319.7015 - val_loss: 324.4032\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.3749 - val_loss: 334.6361\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.4272 - val_loss: 326.9599\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 294.0358 - val_loss: 290.7750\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 237.6068 - val_loss: 278.5519\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.1161 - val_loss: 285.8440\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.9442 - val_loss: 258.5613\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.9482 - val_loss: 249.2426\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.2647 - val_loss: 242.2526\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.0803 - val_loss: 236.4840\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.0507 - val_loss: 234.2927\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.0724 - val_loss: 233.0542\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.1104 - val_loss: 213.6282\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.1681 - val_loss: 228.9323\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.8221 - val_loss: 213.9031\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.0291 - val_loss: 196.4671\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 170.1324 - val_loss: 201.2497\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168.8129 - val_loss: 189.7221\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.8819 - val_loss: 179.9015\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.3494 - val_loss: 174.7859\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.8553 - val_loss: 170.2595\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.4394 - val_loss: 165.1106\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.4710 - val_loss: 162.7396\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.1325 - val_loss: 159.4401\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.1516 - val_loss: 159.2619\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.2553 - val_loss: 151.9955\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.5084 - val_loss: 156.2953\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.1171 - val_loss: 143.4229\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.0397 - val_loss: 144.8036\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.3315 - val_loss: 139.4033\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  13  :  151.46029525528186\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  14 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 263609.9651 - val_loss: 130040.2500\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100299.3199 - val_loss: 43639.8789\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 34105.8413 - val_loss: 13902.9551\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10127.9281 - val_loss: 4579.9814\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3612.8969 - val_loss: 1990.5680\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1934.7252 - val_loss: 1318.1283\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1357.5089 - val_loss: 1084.2545\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1195.3547 - val_loss: 944.5185\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1086.4301 - val_loss: 831.2120\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 948.7312 - val_loss: 737.6133\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 800.0510 - val_loss: 663.8898\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 769.4959 - val_loss: 606.8734\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 714.3667 - val_loss: 564.5649\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 625.9550 - val_loss: 529.7029\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 589.7760 - val_loss: 504.6201\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 600.4457 - val_loss: 486.8510\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 550.0751 - val_loss: 472.5883\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 541.2168 - val_loss: 460.1414\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 555.8344 - val_loss: 450.5621\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 487.0799 - val_loss: 443.2553\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 470.8573 - val_loss: 436.1750\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 438.1189 - val_loss: 429.4645\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 477.8864 - val_loss: 424.7151\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 472.5713 - val_loss: 419.5926\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 434.0007 - val_loss: 415.3575\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 435.8263 - val_loss: 411.4611\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 413.7141 - val_loss: 407.2882\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 447.3999 - val_loss: 403.6307\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 409.9423 - val_loss: 399.6790\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 410.4941 - val_loss: 395.4013\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 448.1225 - val_loss: 391.6131\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 419.0903 - val_loss: 387.6049\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 377.9420 - val_loss: 383.9852\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 411.8668 - val_loss: 380.2406\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 419.6222 - val_loss: 376.2409\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 352.8917 - val_loss: 372.7700\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 387.5886 - val_loss: 369.1208\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 340.7807 - val_loss: 365.5989\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 377.2967 - val_loss: 362.6789\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.5175 - val_loss: 359.0230\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 348.1683 - val_loss: 355.3093\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 366.5438 - val_loss: 352.3926\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 356.2425 - val_loss: 349.3462\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 322.1098 - val_loss: 346.2069\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 358.5556 - val_loss: 343.1378\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 316.4064 - val_loss: 340.2710\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 337.9863 - val_loss: 337.2538\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 333.3328 - val_loss: 334.2154\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 329.0479 - val_loss: 331.1212\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 339.9451 - val_loss: 328.5117\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  14  :  351.20143001357286\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  15 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 9196.0230 - val_loss: 2365.7170\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2074.1580 - val_loss: 1864.0498\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1867.6495 - val_loss: 1554.9669\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1588.0364 - val_loss: 1463.7710\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1505.4512 - val_loss: 1280.6017\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1271.3339 - val_loss: 1170.8921\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1178.1974 - val_loss: 1078.2716\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1047.1708 - val_loss: 987.5453\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1016.2076 - val_loss: 917.4222\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 975.2439 - val_loss: 844.9421\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 919.6536 - val_loss: 793.2817\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 874.5024 - val_loss: 735.4980\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 781.3054 - val_loss: 696.5360\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 708.8811 - val_loss: 651.2170\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 667.7874 - val_loss: 607.6747\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 640.6968 - val_loss: 571.1716\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 575.6345 - val_loss: 535.8452\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 586.7595 - val_loss: 504.3831\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 514.2726 - val_loss: 475.3731\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 479.7346 - val_loss: 448.4990\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 429.9814 - val_loss: 423.2501\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 447.7489 - val_loss: 399.3201\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 389.8964 - val_loss: 374.2024\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 394.8161 - val_loss: 355.4950\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 396.7910 - val_loss: 335.3626\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339.9363 - val_loss: 320.4794\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 358.2655 - val_loss: 302.3824\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.6346 - val_loss: 291.1585\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 283.4710 - val_loss: 275.8102\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 277.9433 - val_loss: 264.3648\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 258.3351 - val_loss: 250.9771\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.7340 - val_loss: 240.5628\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.5844 - val_loss: 230.7857\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239.3619 - val_loss: 221.8605\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.7869 - val_loss: 211.6310\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.6966 - val_loss: 202.1858\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.8326 - val_loss: 199.7737\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.3246 - val_loss: 188.3338\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.8202 - val_loss: 181.0379\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.2712 - val_loss: 174.8829\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.9798 - val_loss: 168.8488\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168.0934 - val_loss: 163.5012\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.6890 - val_loss: 158.1781\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.2543 - val_loss: 154.9471\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 165.0204 - val_loss: 150.3720\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.4537 - val_loss: 145.2494\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.4475 - val_loss: 140.9640\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.3314 - val_loss: 137.4222\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.2640 - val_loss: 134.2020\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.0139 - val_loss: 132.4157\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  15  :  136.3097235915616\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  16 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 8652.6911 - val_loss: 2239.1311\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2187.5195 - val_loss: 1665.7283\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1476.6120 - val_loss: 902.7727\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 846.9229 - val_loss: 548.2029\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 509.2895 - val_loss: 459.5350\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 433.9292 - val_loss: 392.2121\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.5032 - val_loss: 348.4427\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 338.6929 - val_loss: 313.6254\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 330.9056 - val_loss: 281.5176\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.9502 - val_loss: 253.0131\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.9392 - val_loss: 227.9656\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.7929 - val_loss: 207.4476\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.0165 - val_loss: 188.6526\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.1468 - val_loss: 172.8590\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.6482 - val_loss: 159.8713\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.8318 - val_loss: 149.9575\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.9409 - val_loss: 140.4950\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 148.0088 - val_loss: 135.1912\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.9441 - val_loss: 127.5114\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.3138 - val_loss: 123.4796\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.5505 - val_loss: 118.8331\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.7215 - val_loss: 116.8285\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.6140 - val_loss: 113.4098\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 128.4738 - val_loss: 111.0024\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.2797 - val_loss: 111.9663\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.8773 - val_loss: 108.3972\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.6014 - val_loss: 108.0739\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.8865 - val_loss: 105.2475\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.4042 - val_loss: 106.1270\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8198 - val_loss: 103.7964\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.0394 - val_loss: 104.5595\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.1487 - val_loss: 103.5894\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.4627 - val_loss: 101.8936\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.4345 - val_loss: 105.2796\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.9975 - val_loss: 101.1600\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.1417 - val_loss: 100.9063\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.5319 - val_loss: 102.2472\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.2517 - val_loss: 100.5118\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4829 - val_loss: 104.7535\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.6944 - val_loss: 103.7481\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.5671 - val_loss: 100.0635\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.9585 - val_loss: 98.9975\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.0743 - val_loss: 99.0331\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.7835 - val_loss: 99.0353\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.4454 - val_loss: 99.8089\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.4267 - val_loss: 102.6251\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.6575 - val_loss: 98.2314\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.4329 - val_loss: 99.3290\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.4020 - val_loss: 97.8238\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8805 - val_loss: 98.3104\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  16  :  126.57938853755446\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  17 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 211349.1801 - val_loss: 105902.7656\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85988.1696 - val_loss: 29212.4180\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20666.4683 - val_loss: 4992.6528\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4150.8130 - val_loss: 2690.9092\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2546.5372 - val_loss: 1894.6801\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1830.7320 - val_loss: 1191.0574\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1249.9898 - val_loss: 869.6431\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 776.2289 - val_loss: 689.4484\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 660.3723 - val_loss: 574.6311\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 618.4788 - val_loss: 512.4592\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 427.7228 - val_loss: 479.0044\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 426.3824 - val_loss: 453.5809\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 439.5866 - val_loss: 435.5593\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 406.3383 - val_loss: 420.4339\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 411.2470 - val_loss: 407.0098\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 350.5469 - val_loss: 394.9261\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 384.1310 - val_loss: 381.6892\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 380.0254 - val_loss: 368.3112\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 342.5644 - val_loss: 357.8865\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 318.0619 - val_loss: 344.9217\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 326.0078 - val_loss: 334.7686\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.2837 - val_loss: 323.2083\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.9060 - val_loss: 313.2971\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 285.3103 - val_loss: 303.2475\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.5335 - val_loss: 293.5960\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 248.2218 - val_loss: 284.2753\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 260.5717 - val_loss: 276.2680\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.5632 - val_loss: 267.7523\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.7339 - val_loss: 260.4454\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.3593 - val_loss: 252.3190\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 187.3607 - val_loss: 245.4260\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.2008 - val_loss: 238.4466\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 211.5093 - val_loss: 232.9024\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 225.6708 - val_loss: 225.4882\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 210.5671 - val_loss: 220.7122\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.5436 - val_loss: 215.1923\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.2715 - val_loss: 209.8286\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.2305 - val_loss: 205.3917\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.5352 - val_loss: 201.7793\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168.1837 - val_loss: 196.6262\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.6627 - val_loss: 194.0106\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.8637 - val_loss: 188.9482\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.9558 - val_loss: 185.8701\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.4016 - val_loss: 182.4919\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.3397 - val_loss: 178.1398\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.5819 - val_loss: 176.1316\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.2136 - val_loss: 173.1068\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.4243 - val_loss: 170.1758\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.7055 - val_loss: 166.7520\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.2848 - val_loss: 165.4902\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  17  :  206.4849465808575\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  18 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 29245.6450 - val_loss: 15225.0059\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11744.7807 - val_loss: 5453.3457\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4165.1986 - val_loss: 1559.9640\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1404.6822 - val_loss: 789.0043\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 805.1734 - val_loss: 676.1822\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 748.3695 - val_loss: 595.5269\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 628.0047 - val_loss: 485.0425\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 541.5451 - val_loss: 431.2088\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 465.6801 - val_loss: 389.2108\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 386.0973 - val_loss: 342.7766\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 352.3287 - val_loss: 298.3230\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 332.2418 - val_loss: 266.9202\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.3283 - val_loss: 244.8702\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 268.4555 - val_loss: 225.4071\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.0063 - val_loss: 209.9418\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.3147 - val_loss: 199.6030\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.2971 - val_loss: 188.6651\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.7612 - val_loss: 178.5971\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.1932 - val_loss: 169.2441\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.7469 - val_loss: 161.8289\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.1764 - val_loss: 155.4898\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.3285 - val_loss: 150.4847\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.9497 - val_loss: 156.1183\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.2153 - val_loss: 141.7601\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.6593 - val_loss: 136.9823\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.3700 - val_loss: 133.5556\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.2209 - val_loss: 130.9607\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.1326 - val_loss: 128.9433\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.0122 - val_loss: 124.8570\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.1598 - val_loss: 122.7572\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.5683 - val_loss: 122.6227\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.1584 - val_loss: 119.3406\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.4753 - val_loss: 123.1312\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.7316 - val_loss: 115.9270\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3277 - val_loss: 116.4123\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.3634 - val_loss: 119.3457\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.3129 - val_loss: 115.0965\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.9162 - val_loss: 121.9882\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.5871 - val_loss: 110.6688\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.4362 - val_loss: 111.6768\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.4665 - val_loss: 109.2644\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.2474 - val_loss: 116.4402\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.9185 - val_loss: 107.4366\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.7173 - val_loss: 107.4405\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.3028 - val_loss: 106.9397\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.3052 - val_loss: 108.2611\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.6822 - val_loss: 105.3833\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.7141 - val_loss: 106.2604\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.6245 - val_loss: 109.4589\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.6096 - val_loss: 123.6573\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  18  :  145.62882434387106\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  19 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 28369.3261 - val_loss: 8109.2026\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6312.9781 - val_loss: 3820.0701\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4309.1069 - val_loss: 3292.2551\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3976.2094 - val_loss: 2709.3772\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2945.4400 - val_loss: 2149.2815\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2369.6761 - val_loss: 1606.6931\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1579.1071 - val_loss: 1303.1055\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1508.1109 - val_loss: 1028.2123\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1066.0087 - val_loss: 833.3834\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 940.7285 - val_loss: 681.2751\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 751.3731 - val_loss: 571.8302\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 624.1159 - val_loss: 495.7491\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 550.7091 - val_loss: 437.3117\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 452.0412 - val_loss: 392.1693\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 391.8131 - val_loss: 364.1831\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 393.5189 - val_loss: 338.6162\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 378.6840 - val_loss: 317.3999\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.4262 - val_loss: 302.1293\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 341.8180 - val_loss: 289.2173\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.0044 - val_loss: 281.0841\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.3310 - val_loss: 269.1378\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.3351 - val_loss: 260.9484\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.5008 - val_loss: 253.8830\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 270.2060 - val_loss: 249.4648\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.9095 - val_loss: 242.3910\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 257.5219 - val_loss: 237.4078\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.5995 - val_loss: 230.4428\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.5186 - val_loss: 225.9667\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.0642 - val_loss: 221.4846\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.2346 - val_loss: 221.1959\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.7847 - val_loss: 213.3529\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.5971 - val_loss: 209.8749\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.1710 - val_loss: 210.4457\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.9067 - val_loss: 203.1547\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.9160 - val_loss: 201.0202\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 223.6932 - val_loss: 197.5928\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 224.7122 - val_loss: 195.7596\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.6824 - val_loss: 192.8251\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.3389 - val_loss: 191.7654\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.0568 - val_loss: 192.6548\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.1312 - val_loss: 189.3975\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.5383 - val_loss: 188.2805\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.2440 - val_loss: 183.8863\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 208.2437 - val_loss: 182.9706\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.9948 - val_loss: 181.2788\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.4417 - val_loss: 177.8249\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.2360 - val_loss: 176.8495\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.9511 - val_loss: 175.2209\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.1210 - val_loss: 173.8326\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.7796 - val_loss: 173.1818\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  19  :  212.15120322392124\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  20 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 3464.8262 - val_loss: 941.6551\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 780.5545 - val_loss: 469.4842\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 389.3186 - val_loss: 307.2356\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 294.2043 - val_loss: 250.9600\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.6195 - val_loss: 232.6406\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.1589 - val_loss: 224.2034\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.9519 - val_loss: 219.1263\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.8971 - val_loss: 216.5865\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 239.1855 - val_loss: 213.8758\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.8088 - val_loss: 211.3841\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.9608 - val_loss: 210.0909\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.9372 - val_loss: 208.7911\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.1350 - val_loss: 207.0044\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.1042 - val_loss: 206.2959\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.5716 - val_loss: 204.9854\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.7654 - val_loss: 203.3143\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.7059 - val_loss: 202.0777\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.9086 - val_loss: 200.8242\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 214.9228 - val_loss: 198.3527\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.6330 - val_loss: 196.6187\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.6232 - val_loss: 195.0653\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.9111 - val_loss: 192.4185\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.8207 - val_loss: 189.8528\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.9817 - val_loss: 186.7804\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.7227 - val_loss: 184.1786\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 192.2928 - val_loss: 181.4288\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.8767 - val_loss: 178.5716\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.5518 - val_loss: 175.2463\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.2336 - val_loss: 172.2506\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.0762 - val_loss: 169.2856\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 181.8768 - val_loss: 166.9919\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.4195 - val_loss: 163.9627\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.0150 - val_loss: 161.4382\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.4162 - val_loss: 158.5987\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.7157 - val_loss: 156.0530\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.4026 - val_loss: 153.0428\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.8296 - val_loss: 150.7923\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.7061 - val_loss: 147.5756\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.8442 - val_loss: 145.0089\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.4177 - val_loss: 142.4473\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.9880 - val_loss: 140.2043\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.4736 - val_loss: 137.6016\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.4851 - val_loss: 135.1603\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.3949 - val_loss: 132.8642\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.1303 - val_loss: 130.5898\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.7188 - val_loss: 128.1889\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.0259 - val_loss: 126.1923\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.8103 - val_loss: 124.0051\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.4868 - val_loss: 122.4742\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.0364 - val_loss: 120.7926\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  20  :  133.38922774766726\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  21 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 4286.9863 - val_loss: 1547.9990\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1566.0575 - val_loss: 974.9287\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1034.0509 - val_loss: 643.5329\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 612.7737 - val_loss: 419.2563\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 446.1467 - val_loss: 318.0477\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 377.6282 - val_loss: 237.0333\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 262.6784 - val_loss: 199.6142\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.1774 - val_loss: 181.5870\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.3375 - val_loss: 175.9921\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.6114 - val_loss: 152.8036\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.5007 - val_loss: 144.1927\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.5650 - val_loss: 141.9837\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.1698 - val_loss: 136.6065\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.3184 - val_loss: 132.5359\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.6862 - val_loss: 129.7242\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.5799 - val_loss: 140.7305\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.7678 - val_loss: 128.7194\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.1544 - val_loss: 123.9236\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.2188 - val_loss: 127.1496\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.8502 - val_loss: 124.1379\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.5696 - val_loss: 119.3417\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5895 - val_loss: 124.5587\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.8159 - val_loss: 120.9764\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2157 - val_loss: 116.1804\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.0443 - val_loss: 114.2683\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.6428 - val_loss: 113.5008\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.1906 - val_loss: 112.3289\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.7430 - val_loss: 111.3479\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.2856 - val_loss: 112.0443\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.8932 - val_loss: 108.7990\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.4694 - val_loss: 109.6784\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.8309 - val_loss: 111.7262\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.3412 - val_loss: 108.6639\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2511 - val_loss: 106.9413\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.3344 - val_loss: 107.0534\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.6130 - val_loss: 107.7172\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.6589 - val_loss: 111.3590\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.6733 - val_loss: 105.0710\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.8708 - val_loss: 106.1782\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.3227 - val_loss: 108.3864\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.1315 - val_loss: 104.7742\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2144 - val_loss: 104.9336\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 110.8181 - val_loss: 118.6250\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.7466 - val_loss: 105.8040\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.2679 - val_loss: 103.5469\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.5939 - val_loss: 116.6505\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.0776 - val_loss: 102.1231\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.2515 - val_loss: 106.6263\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.5415 - val_loss: 116.7548\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.5417 - val_loss: 103.8639\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  21  :  119.52812929114921\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  22 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 21300.6172 - val_loss: 11574.2393\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9564.2669 - val_loss: 6376.1206\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5329.0185 - val_loss: 3632.8750\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 3170.2488 - val_loss: 2165.8855\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1935.2353 - val_loss: 1311.1741\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1265.7170 - val_loss: 755.9368\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 695.7303 - val_loss: 432.1950\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 427.3363 - val_loss: 306.5880\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.8058 - val_loss: 284.6987\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 292.4541 - val_loss: 268.4909\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.7247 - val_loss: 257.8179\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.5365 - val_loss: 249.0109\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.8690 - val_loss: 242.5340\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.3992 - val_loss: 237.4195\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.3449 - val_loss: 232.2072\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.4549 - val_loss: 227.8982\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.7649 - val_loss: 222.8961\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.3026 - val_loss: 219.1739\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.5750 - val_loss: 215.0216\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.0177 - val_loss: 212.2583\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.9393 - val_loss: 209.0362\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.5036 - val_loss: 205.5706\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.1933 - val_loss: 201.8542\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.7803 - val_loss: 199.3895\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.1629 - val_loss: 196.4652\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.6362 - val_loss: 194.1190\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.0382 - val_loss: 191.6369\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.0155 - val_loss: 189.2179\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.9968 - val_loss: 186.3175\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.4267 - val_loss: 184.3512\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.0541 - val_loss: 181.6917\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.1525 - val_loss: 180.0162\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.0823 - val_loss: 177.7037\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.4110 - val_loss: 175.8174\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.9265 - val_loss: 173.2447\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.9534 - val_loss: 171.0966\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.9357 - val_loss: 168.6851\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.3151 - val_loss: 166.8810\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.7990 - val_loss: 164.9411\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.4369 - val_loss: 163.8996\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.7364 - val_loss: 162.7806\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.4136 - val_loss: 161.6522\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.1333 - val_loss: 160.0499\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.4387 - val_loss: 159.0333\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.2473 - val_loss: 157.6946\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.4859 - val_loss: 156.8216\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.0386 - val_loss: 155.7946\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.8545 - val_loss: 154.7428\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.8449 - val_loss: 153.8129\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.3873 - val_loss: 153.2563\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  22  :  211.6755802804515\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  23 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 7869.0917 - val_loss: 1743.9399\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1990.1543 - val_loss: 1771.3171\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1779.6621 - val_loss: 1190.5277\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1316.5938 - val_loss: 991.2267\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1039.0712 - val_loss: 837.6014\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 865.1628 - val_loss: 716.9017\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 793.3812 - val_loss: 615.9258\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 637.6513 - val_loss: 548.8809\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 559.5387 - val_loss: 503.5818\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 570.1737 - val_loss: 469.5027\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 490.1198 - val_loss: 444.3373\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 505.8507 - val_loss: 420.4517\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 438.3313 - val_loss: 401.9165\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 432.5242 - val_loss: 382.5749\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 403.5977 - val_loss: 367.7377\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 394.2069 - val_loss: 351.1837\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 360.7584 - val_loss: 336.3640\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 359.4948 - val_loss: 323.1388\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 364.8270 - val_loss: 311.1160\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 348.3621 - val_loss: 300.2552\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 348.8973 - val_loss: 289.8465\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 320.9447 - val_loss: 280.0231\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 306.9292 - val_loss: 271.6371\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.5327 - val_loss: 263.2933\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.0863 - val_loss: 254.6335\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.3444 - val_loss: 246.6007\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.1148 - val_loss: 242.2827\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.3203 - val_loss: 232.6367\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.6311 - val_loss: 226.1355\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 269.2504 - val_loss: 219.7908\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.1064 - val_loss: 213.6046\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.2904 - val_loss: 209.6399\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.5554 - val_loss: 211.8031\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.6132 - val_loss: 199.1529\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.8102 - val_loss: 192.2928\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.9275 - val_loss: 192.7819\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.2005 - val_loss: 190.5361\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.3768 - val_loss: 180.4273\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.5602 - val_loss: 173.3566\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.2727 - val_loss: 168.3952\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.3206 - val_loss: 169.9208\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.5068 - val_loss: 162.0398\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.9359 - val_loss: 156.5717\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.1353 - val_loss: 152.4509\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.1522 - val_loss: 149.5555\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.2469 - val_loss: 150.9300\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.1593 - val_loss: 144.2287\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.9778 - val_loss: 139.3446\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.2776 - val_loss: 136.3718\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.9884 - val_loss: 135.4412\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  23  :  161.9924781029137\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  24 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 23ms/step - loss: 35874.1641 - val_loss: 4707.5444\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3269.7413 - val_loss: 2816.1389\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3073.8327 - val_loss: 1582.9380\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1942.6821 - val_loss: 1523.7157\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1742.2845 - val_loss: 1326.8724\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1661.8239 - val_loss: 1212.9349\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1436.3464 - val_loss: 1120.9028\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1323.3777 - val_loss: 1027.3920\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1199.4250 - val_loss: 937.4487\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1146.0530 - val_loss: 872.9837\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 907.7170 - val_loss: 799.8895\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 933.4129 - val_loss: 742.3486\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 833.8375 - val_loss: 686.5826\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 843.8082 - val_loss: 636.1719\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 849.9378 - val_loss: 594.6501\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 718.5706 - val_loss: 557.0168\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 678.9327 - val_loss: 516.5877\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 577.2703 - val_loss: 487.8295\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 618.1836 - val_loss: 458.2736\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 569.3819 - val_loss: 428.4003\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 518.8084 - val_loss: 403.8934\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 487.3178 - val_loss: 380.9246\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 459.5986 - val_loss: 363.4337\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 396.0345 - val_loss: 340.4367\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 409.9248 - val_loss: 330.2138\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 371.4146 - val_loss: 306.2988\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 365.8066 - val_loss: 292.4169\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 358.5832 - val_loss: 278.0946\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 335.0315 - val_loss: 264.3850\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 339.0186 - val_loss: 253.5078\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 313.4117 - val_loss: 240.4274\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 296.3806 - val_loss: 230.1434\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.4114 - val_loss: 222.8787\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 269.6696 - val_loss: 211.1425\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 241.6915 - val_loss: 204.2020\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.3667 - val_loss: 194.3351\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.8718 - val_loss: 191.6872\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.4167 - val_loss: 181.3100\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.1382 - val_loss: 173.5014\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.2292 - val_loss: 169.4182\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.2529 - val_loss: 162.0712\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.2344 - val_loss: 159.1002\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 167.0765 - val_loss: 154.7895\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.4577 - val_loss: 150.2014\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.9602 - val_loss: 143.9353\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.9253 - val_loss: 144.5444\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.3159 - val_loss: 137.0516\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.9447 - val_loss: 133.7372\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.5502 - val_loss: 130.7017\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.3839 - val_loss: 131.0218\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  24  :  155.570958302453\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  25 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 45830.2806 - val_loss: 12566.6133\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9275.6496 - val_loss: 4858.3628\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3945.4846 - val_loss: 3900.9971\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2952.6702 - val_loss: 2643.7100\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2187.1288 - val_loss: 1975.8271\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1714.6229 - val_loss: 1464.2887\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1238.3640 - val_loss: 1122.5654\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 929.6530 - val_loss: 891.8204\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 941.5924 - val_loss: 714.3643\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 620.5368 - val_loss: 602.6458\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 452.6527 - val_loss: 527.1649\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 461.9259 - val_loss: 455.9329\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 457.1965 - val_loss: 403.9849\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 428.3280 - val_loss: 365.0411\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.0866 - val_loss: 338.1155\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 326.3712 - val_loss: 307.0276\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 306.2800 - val_loss: 287.5197\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.3327 - val_loss: 271.0332\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.0931 - val_loss: 247.6566\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.8839 - val_loss: 239.0318\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.2378 - val_loss: 221.3038\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.8967 - val_loss: 208.4480\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.2452 - val_loss: 208.0294\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.5873 - val_loss: 187.5574\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.9682 - val_loss: 186.2126\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.5803 - val_loss: 175.4840\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.6812 - val_loss: 169.4510\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.1386 - val_loss: 166.1423\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.4082 - val_loss: 160.3108\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.8894 - val_loss: 156.8798\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 158.0150 - val_loss: 152.6156\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.6915 - val_loss: 158.3774\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.9876 - val_loss: 149.9468\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.2834 - val_loss: 146.7080\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.9228 - val_loss: 144.7370\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4951 - val_loss: 142.7268\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.3938 - val_loss: 144.1161\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.4411 - val_loss: 145.7644\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.8462 - val_loss: 139.4269\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.3960 - val_loss: 151.5701\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.4861 - val_loss: 138.1012\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.8553 - val_loss: 137.3396\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.5576 - val_loss: 136.1055\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.9058 - val_loss: 139.0897\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 139.9575 - val_loss: 136.2005\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.0334 - val_loss: 134.1034\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.7650 - val_loss: 135.2161\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.2943 - val_loss: 133.9595\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.4655 - val_loss: 132.8039\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.0382 - val_loss: 132.5957\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  25  :  157.93178598500512\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  26 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 165709.5919 - val_loss: 99357.0859\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83864.8130 - val_loss: 45319.0781\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 36456.4213 - val_loss: 17549.3652\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13715.9562 - val_loss: 5421.2490\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3953.9646 - val_loss: 1439.1511\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1111.0605 - val_loss: 599.8965\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 642.9571 - val_loss: 492.0465\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 534.5702 - val_loss: 451.9348\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 521.0661 - val_loss: 421.6707\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 419.0034 - val_loss: 401.6685\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 393.4234 - val_loss: 384.4951\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 413.7941 - val_loss: 369.8817\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 369.0613 - val_loss: 354.0316\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 399.9138 - val_loss: 340.2991\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 367.5521 - val_loss: 327.4358\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 332.7869 - val_loss: 311.6373\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 315.8264 - val_loss: 289.9626\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.8678 - val_loss: 270.4437\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 317.6581 - val_loss: 251.3831\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 262.6866 - val_loss: 234.5386\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.0373 - val_loss: 218.1899\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.5489 - val_loss: 202.8549\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.7507 - val_loss: 190.0446\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.4634 - val_loss: 180.1178\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.0391 - val_loss: 172.0647\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.6185 - val_loss: 165.8120\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.0178 - val_loss: 163.1165\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.6680 - val_loss: 158.6881\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.5987 - val_loss: 156.2715\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.4667 - val_loss: 153.3296\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.4692 - val_loss: 154.1329\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.2926 - val_loss: 149.2720\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.7264 - val_loss: 147.7220\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.4644 - val_loss: 146.1427\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.5816 - val_loss: 147.9608\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.8958 - val_loss: 143.7637\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.2437 - val_loss: 143.9275\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.7259 - val_loss: 142.5370\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.8281 - val_loss: 141.1882\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.8663 - val_loss: 140.3476\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.1602 - val_loss: 138.8540\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.7239 - val_loss: 137.6072\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.9266 - val_loss: 139.1935\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.3334 - val_loss: 137.1223\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.9650 - val_loss: 135.7267\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.0773 - val_loss: 134.2163\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.7006 - val_loss: 133.1101\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.2587 - val_loss: 135.3913\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.3316 - val_loss: 131.2230\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.4590 - val_loss: 132.2258\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  26  :  158.64317877591998\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  27 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 4659.4189 - val_loss: 2899.6191\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2541.6631 - val_loss: 1631.1373\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1559.3862 - val_loss: 1020.6426\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 810.2216 - val_loss: 594.2857\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 545.7050 - val_loss: 444.9228\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.6821 - val_loss: 358.9999\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 337.0945 - val_loss: 315.0356\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 348.8192 - val_loss: 288.6402\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.0507 - val_loss: 286.2917\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 260.6001 - val_loss: 229.8992\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.4339 - val_loss: 202.2597\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.5906 - val_loss: 209.1890\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.5240 - val_loss: 193.7452\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.3395 - val_loss: 180.0943\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.1887 - val_loss: 174.4598\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.2354 - val_loss: 154.7488\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.1878 - val_loss: 153.3024\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.3193 - val_loss: 159.7412\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.2278 - val_loss: 142.7812\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.2010 - val_loss: 135.6111\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.1581 - val_loss: 132.9807\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.4561 - val_loss: 131.4663\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.7760 - val_loss: 127.7470\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.3970 - val_loss: 138.5098\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.1677 - val_loss: 126.7853\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.5886 - val_loss: 122.3903\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.0227 - val_loss: 117.1441\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.5326 - val_loss: 126.6815\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.8779 - val_loss: 145.0048\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.3869 - val_loss: 122.1002\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.8513 - val_loss: 110.2841\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.8914 - val_loss: 107.8307\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.6245 - val_loss: 103.9587\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2541 - val_loss: 100.6058\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.8153 - val_loss: 99.4621\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.6384 - val_loss: 102.9051\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.1341 - val_loss: 101.7612\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0950 - val_loss: 93.2156\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.6807 - val_loss: 106.5971\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.6795 - val_loss: 101.8517\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.2568 - val_loss: 91.7444\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.7374 - val_loss: 91.4398\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.3937 - val_loss: 97.1056\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.1649 - val_loss: 98.8215\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.5403 - val_loss: 92.4475\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.4000 - val_loss: 87.5374\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.0897 - val_loss: 87.2072\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.2657 - val_loss: 86.0417\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.3205 - val_loss: 86.5751\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.7936 - val_loss: 120.3371\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  27  :  139.37038781155792\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  28 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 27935.8892 - val_loss: 10488.9297\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6904.5107 - val_loss: 907.9811\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 867.8346 - val_loss: 857.8432\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 804.7879 - val_loss: 568.6507\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 597.6862 - val_loss: 553.7757\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 581.6196 - val_loss: 508.9351\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 520.0311 - val_loss: 483.5728\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 447.4713 - val_loss: 461.1144\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 502.2363 - val_loss: 438.3556\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 455.0629 - val_loss: 418.4705\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 505.6227 - val_loss: 401.4716\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 407.1059 - val_loss: 386.1602\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 436.1698 - val_loss: 371.6071\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 391.3473 - val_loss: 358.7444\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 396.3901 - val_loss: 349.2535\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 353.1509 - val_loss: 338.1693\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 382.7648 - val_loss: 328.2899\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 358.9223 - val_loss: 319.5614\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 350.6520 - val_loss: 312.2968\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.6866 - val_loss: 306.0805\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 317.0289 - val_loss: 299.8034\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 299.1605 - val_loss: 292.7556\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 305.1996 - val_loss: 286.8242\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 327.7580 - val_loss: 281.7475\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 292.8712 - val_loss: 276.7007\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 299.0979 - val_loss: 272.2530\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 270.7014 - val_loss: 268.2505\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 276.1394 - val_loss: 264.0885\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.8302 - val_loss: 260.3311\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.4444 - val_loss: 256.7591\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.3687 - val_loss: 253.7162\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.3929 - val_loss: 250.5580\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.4271 - val_loss: 247.5794\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 254.4143 - val_loss: 244.7526\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.6936 - val_loss: 241.9507\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.5183 - val_loss: 239.2899\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.1601 - val_loss: 236.9209\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 264.9430 - val_loss: 235.2183\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.9083 - val_loss: 231.8612\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.1939 - val_loss: 229.4684\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.9015 - val_loss: 227.2794\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.1423 - val_loss: 225.1974\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.4774 - val_loss: 223.1658\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 224.2362 - val_loss: 221.0949\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.6821 - val_loss: 219.0708\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.5831 - val_loss: 217.2591\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.0162 - val_loss: 215.4934\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.0256 - val_loss: 213.5455\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.6071 - val_loss: 211.9567\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.7556 - val_loss: 211.0013\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  28  :  239.01023796113512\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  29 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 750.9111 - val_loss: 474.4055\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 461.4488 - val_loss: 316.9860\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.5242 - val_loss: 242.8217\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.0489 - val_loss: 232.7004\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.7860 - val_loss: 216.6763\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.5358 - val_loss: 212.9076\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.8150 - val_loss: 209.3034\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.2426 - val_loss: 205.0581\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.4092 - val_loss: 201.3188\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.4947 - val_loss: 196.0405\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.7653 - val_loss: 190.1578\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.1288 - val_loss: 184.7471\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.4692 - val_loss: 180.0399\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.1705 - val_loss: 177.6452\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.7296 - val_loss: 173.3617\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.5779 - val_loss: 169.2438\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.9445 - val_loss: 166.3389\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.2324 - val_loss: 163.2632\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.4027 - val_loss: 159.6207\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.4627 - val_loss: 156.5974\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.5509 - val_loss: 152.7589\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.9356 - val_loss: 149.7504\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.2131 - val_loss: 147.5412\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.0250 - val_loss: 144.2585\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.2582 - val_loss: 141.4809\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 160.2689 - val_loss: 140.2775\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.2937 - val_loss: 137.2065\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.2685 - val_loss: 135.7443\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.0921 - val_loss: 134.3867\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.0400 - val_loss: 131.8719\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.5696 - val_loss: 129.6683\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.6923 - val_loss: 127.1399\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.5864 - val_loss: 124.8168\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.8031 - val_loss: 122.6832\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.4080 - val_loss: 121.9490\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.1201 - val_loss: 120.5398\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.4550 - val_loss: 118.2867\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.3465 - val_loss: 120.5076\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.1164 - val_loss: 116.6748\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.5094 - val_loss: 116.1255\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.6824 - val_loss: 115.2283\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.2935 - val_loss: 116.8576\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.8824 - val_loss: 115.3102\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.6272 - val_loss: 116.2422\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.5511 - val_loss: 112.8286\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.0006 - val_loss: 114.2624\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.0261 - val_loss: 112.0144\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.7271 - val_loss: 112.1446\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.0269 - val_loss: 111.5035\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.9233 - val_loss: 111.4796\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  29  :  132.8314251464516\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  30 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 100394.9453 - val_loss: 39962.9453\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 29074.1549 - val_loss: 9012.2148\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6054.5719 - val_loss: 1235.9886\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1115.8575 - val_loss: 791.9852\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 907.0320 - val_loss: 737.2259\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 770.8152 - val_loss: 729.1675\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 832.9258 - val_loss: 721.3826\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 766.5992 - val_loss: 711.1549\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 783.5975 - val_loss: 696.1865\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 701.9328 - val_loss: 682.1926\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 746.1207 - val_loss: 668.4306\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 695.9544 - val_loss: 654.6310\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 709.7331 - val_loss: 641.1550\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 659.0806 - val_loss: 625.6904\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 681.1071 - val_loss: 611.1867\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 670.5869 - val_loss: 597.5583\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 616.7074 - val_loss: 583.8514\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 591.8067 - val_loss: 568.2921\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 604.4731 - val_loss: 554.0114\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 586.7269 - val_loss: 538.4595\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 574.3745 - val_loss: 523.5671\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 535.9434 - val_loss: 506.2579\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 515.7259 - val_loss: 489.9131\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 527.8020 - val_loss: 472.6594\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 525.6494 - val_loss: 451.4044\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 482.6769 - val_loss: 430.5857\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 487.6178 - val_loss: 410.8962\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 426.0658 - val_loss: 391.5426\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 409.5579 - val_loss: 368.1225\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 353.3513 - val_loss: 349.6718\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 376.3452 - val_loss: 329.2057\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 337.6860 - val_loss: 316.2309\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.6247 - val_loss: 305.2815\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 340.1257 - val_loss: 299.4112\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.3379 - val_loss: 292.8660\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 322.3296 - val_loss: 287.5907\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 291.2218 - val_loss: 282.7825\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 264.5609 - val_loss: 278.1144\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 265.1358 - val_loss: 274.0832\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.2769 - val_loss: 269.3921\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.7185 - val_loss: 264.8048\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 263.8624 - val_loss: 261.2651\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 280.1306 - val_loss: 256.2200\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 256.2036 - val_loss: 253.0945\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.6568 - val_loss: 248.2784\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.0079 - val_loss: 244.5937\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.9451 - val_loss: 240.8105\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.3521 - val_loss: 237.9846\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.3128 - val_loss: 233.8783\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.9504 - val_loss: 230.6319\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  30  :  252.95818183534053\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  31 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 103668.0551 - val_loss: 50061.3008\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 41752.6455 - val_loss: 16319.8389\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 13553.1631 - val_loss: 4916.5083\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3970.2424 - val_loss: 1968.1902\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1667.0262 - val_loss: 1225.8267\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1237.4329 - val_loss: 1012.2864\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1250.3984 - val_loss: 895.7477\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 886.8269 - val_loss: 807.3997\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 836.8174 - val_loss: 728.5460\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 622.7427 - val_loss: 665.7620\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 666.4940 - val_loss: 610.6325\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 576.3893 - val_loss: 563.9404\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 573.9284 - val_loss: 524.1443\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 486.6435 - val_loss: 491.5527\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 473.9298 - val_loss: 461.4550\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 479.5582 - val_loss: 435.6403\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.3479 - val_loss: 414.5603\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 420.9750 - val_loss: 396.7087\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 391.7246 - val_loss: 380.7847\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339.3821 - val_loss: 366.9315\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 365.8793 - val_loss: 355.0864\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 355.2299 - val_loss: 344.6605\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 350.9143 - val_loss: 334.4526\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 355.0587 - val_loss: 324.7072\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 338.4357 - val_loss: 315.7747\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 339.8222 - val_loss: 307.1623\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 337.2595 - val_loss: 299.5508\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 322.4898 - val_loss: 292.7673\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.5678 - val_loss: 286.3415\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 305.5051 - val_loss: 282.0690\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.6701 - val_loss: 276.4633\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.6620 - val_loss: 272.0069\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 269.7315 - val_loss: 267.6198\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 287.5549 - val_loss: 265.1151\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 304.1498 - val_loss: 260.9562\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 286.8904 - val_loss: 257.4180\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.0538 - val_loss: 254.1055\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.6813 - val_loss: 250.6418\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 281.3362 - val_loss: 247.5872\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.0691 - val_loss: 245.0302\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.7712 - val_loss: 242.6546\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.5383 - val_loss: 240.1036\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.9617 - val_loss: 238.0476\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.6673 - val_loss: 235.8582\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.6674 - val_loss: 234.5669\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.9782 - val_loss: 232.4807\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 230.5515 - val_loss: 231.1512\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.4833 - val_loss: 229.7356\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.9846 - val_loss: 228.9692\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.4314 - val_loss: 226.8395\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  31  :  286.9843290088475\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  32 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 1077.6209 - val_loss: 614.1035\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 676.1808 - val_loss: 507.8605\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 580.5615 - val_loss: 426.0028\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 462.6560 - val_loss: 364.8751\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 416.6711 - val_loss: 317.3134\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 336.0482 - val_loss: 282.2098\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 279.3526 - val_loss: 251.4346\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 299.8360 - val_loss: 224.9198\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.7518 - val_loss: 206.1115\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.6307 - val_loss: 187.9755\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.4449 - val_loss: 174.2634\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.5919 - val_loss: 161.7160\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.8317 - val_loss: 152.1998\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.8922 - val_loss: 144.1927\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.7396 - val_loss: 137.2237\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.9931 - val_loss: 131.1806\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.8749 - val_loss: 126.1365\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.2388 - val_loss: 126.4152\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.3753 - val_loss: 119.9742\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.5609 - val_loss: 115.7306\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.2826 - val_loss: 113.9997\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.0651 - val_loss: 110.9072\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.3083 - val_loss: 108.1612\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.4590 - val_loss: 107.1997\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.8364 - val_loss: 103.4099\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2175 - val_loss: 102.0588\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.8724 - val_loss: 100.9935\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 106.9190 - val_loss: 99.7694\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.2206 - val_loss: 98.4122\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.2635 - val_loss: 100.1375\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.0144 - val_loss: 97.9221\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.3158 - val_loss: 94.1982\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.9240 - val_loss: 93.4833\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.8260 - val_loss: 94.4512\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 98.2341 - val_loss: 93.2765\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.2606 - val_loss: 91.6888\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.9952 - val_loss: 91.2545\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.1906 - val_loss: 90.4614\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.0918 - val_loss: 92.2538\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.8835 - val_loss: 91.9250\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.2225 - val_loss: 96.8304\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.3732 - val_loss: 89.6945\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.2743 - val_loss: 89.6474\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.1817 - val_loss: 88.6410\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8351 - val_loss: 91.8204\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.1890 - val_loss: 88.3825\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.0342 - val_loss: 90.3393\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.3832 - val_loss: 91.2891\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.7569 - val_loss: 88.9506\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.6569 - val_loss: 87.7752\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  32  :  104.11725591324637\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  33 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 48014.9745 - val_loss: 22424.4531\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 16654.3203 - val_loss: 4496.4399\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2736.7489 - val_loss: 406.7854\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 352.1823 - val_loss: 383.1732\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 420.6297 - val_loss: 323.7625\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 323.7839 - val_loss: 299.2516\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 321.3972 - val_loss: 294.4298\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.0864 - val_loss: 284.7087\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.2971 - val_loss: 277.3056\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.7327 - val_loss: 271.0829\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 323.6855 - val_loss: 262.8185\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 281.9252 - val_loss: 256.4088\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 265.7645 - val_loss: 250.6503\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 278.3989 - val_loss: 244.5231\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 269.9224 - val_loss: 239.1809\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.8857 - val_loss: 232.0098\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.2874 - val_loss: 227.2418\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.0374 - val_loss: 221.3484\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.7046 - val_loss: 217.3286\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.5099 - val_loss: 211.8684\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.4825 - val_loss: 207.9290\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 213.8843 - val_loss: 204.3133\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 224.7790 - val_loss: 199.1159\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.9755 - val_loss: 196.0273\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.4709 - val_loss: 192.1263\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.8699 - val_loss: 188.4511\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.3196 - val_loss: 185.9710\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 193.1990 - val_loss: 182.4865\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.8621 - val_loss: 180.0519\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.1499 - val_loss: 177.6973\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.2544 - val_loss: 175.2153\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.7113 - val_loss: 172.5809\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.9129 - val_loss: 170.3222\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.7960 - val_loss: 169.0382\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.1035 - val_loss: 166.1973\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.0118 - val_loss: 164.7856\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 179.3354 - val_loss: 163.5558\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.4632 - val_loss: 161.2210\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.5941 - val_loss: 159.5933\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.3529 - val_loss: 158.9482\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.0657 - val_loss: 156.7532\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165.5284 - val_loss: 156.3250\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.5333 - val_loss: 154.1290\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.6748 - val_loss: 153.3957\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.5820 - val_loss: 151.8503\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 167.4086 - val_loss: 151.3586\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.7684 - val_loss: 150.2623\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.4026 - val_loss: 148.7254\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.8408 - val_loss: 149.0334\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.8660 - val_loss: 146.9635\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  33  :  186.34239173917868\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  34 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 86896.7978 - val_loss: 46382.1289\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 36793.7142 - val_loss: 13412.0820\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9895.2332 - val_loss: 2905.8965\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2752.3186 - val_loss: 2692.5576\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2477.8270 - val_loss: 2330.4075\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2369.3282 - val_loss: 2125.8887\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2302.9220 - val_loss: 1976.4926\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2019.2483 - val_loss: 1840.5852\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1970.9009 - val_loss: 1716.3540\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1732.8685 - val_loss: 1599.5258\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1609.1849 - val_loss: 1491.3667\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1557.2239 - val_loss: 1395.2443\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1360.9638 - val_loss: 1309.9346\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1201.8181 - val_loss: 1232.2378\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1263.4571 - val_loss: 1157.5623\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1110.7887 - val_loss: 1092.3243\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1118.8330 - val_loss: 1031.2678\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1064.6789 - val_loss: 977.7390\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1054.8073 - val_loss: 925.9720\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 889.7313 - val_loss: 881.6702\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 933.1369 - val_loss: 839.1998\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 936.9815 - val_loss: 798.7853\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 833.7069 - val_loss: 764.5519\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 775.4235 - val_loss: 729.6149\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 744.7216 - val_loss: 698.2961\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 761.6464 - val_loss: 671.1517\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 786.1757 - val_loss: 642.6410\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 758.3982 - val_loss: 616.0988\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 603.4917 - val_loss: 593.8785\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 647.3143 - val_loss: 569.6254\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 624.0896 - val_loss: 548.0355\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 627.5606 - val_loss: 529.0361\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 594.0768 - val_loss: 509.2230\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 548.5857 - val_loss: 490.6454\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 516.2452 - val_loss: 475.0532\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 487.9636 - val_loss: 458.9095\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 473.5318 - val_loss: 443.8351\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 434.3125 - val_loss: 429.2168\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 414.8887 - val_loss: 416.5168\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 434.4915 - val_loss: 402.1624\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 447.7883 - val_loss: 389.5934\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 427.3870 - val_loss: 378.8601\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 449.7314 - val_loss: 366.8394\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 394.4950 - val_loss: 355.4489\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 418.1678 - val_loss: 345.3640\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 384.3487 - val_loss: 335.7159\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 377.8649 - val_loss: 326.0505\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 345.6364 - val_loss: 316.0242\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.9536 - val_loss: 308.3720\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 334.7850 - val_loss: 298.0615\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  34  :  375.7738708430132\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  35 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 21ms/step - loss: 1296.5097 - val_loss: 664.6354\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 734.9616 - val_loss: 432.7199\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 460.4274 - val_loss: 336.7632\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 359.0863 - val_loss: 292.8348\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 375.2424 - val_loss: 272.8615\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 304.5642 - val_loss: 258.0630\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.4906 - val_loss: 251.6850\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 252.9837 - val_loss: 245.8373\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 266.9499 - val_loss: 241.7724\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.4171 - val_loss: 238.3599\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.2838 - val_loss: 233.0495\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 274.8478 - val_loss: 226.5162\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 260.6359 - val_loss: 221.7526\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.4776 - val_loss: 218.7714\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.0565 - val_loss: 217.6267\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.4644 - val_loss: 211.5173\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.3956 - val_loss: 208.8710\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.4632 - val_loss: 206.4315\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 254.8301 - val_loss: 202.4359\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.8417 - val_loss: 202.7432\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 226.5343 - val_loss: 197.9971\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.3098 - val_loss: 194.0363\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.2662 - val_loss: 190.9441\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.5166 - val_loss: 195.9285\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.5696 - val_loss: 188.5490\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.5228 - val_loss: 194.3285\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.0804 - val_loss: 184.0277\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.6430 - val_loss: 178.6864\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 190.2843 - val_loss: 175.6050\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.6448 - val_loss: 177.0975\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.1096 - val_loss: 170.6669\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.0013 - val_loss: 167.9717\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.2645 - val_loss: 164.2445\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.2197 - val_loss: 162.9509\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.5269 - val_loss: 164.0887\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.3262 - val_loss: 157.6263\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.1975 - val_loss: 154.1715\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.7574 - val_loss: 177.2655\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.9840 - val_loss: 151.4187\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.4884 - val_loss: 145.1941\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.1273 - val_loss: 140.4583\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.3733 - val_loss: 138.3898\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 153.1514 - val_loss: 142.6072\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.3966 - val_loss: 134.6283\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.2732 - val_loss: 129.0892\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.4110 - val_loss: 125.2928\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.1393 - val_loss: 124.7740\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.7391 - val_loss: 121.0084\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.0885 - val_loss: 115.8587\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.4805 - val_loss: 112.4926\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  35  :  148.28016809052318\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  36 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 21ms/step - loss: 317160.4062 - val_loss: 202620.7812\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178081.7371 - val_loss: 114381.3359\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 101211.1783 - val_loss: 66476.2891\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 59071.6797 - val_loss: 39421.9219\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 35159.0230 - val_loss: 23161.2070\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20332.6616 - val_loss: 13037.5400\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11445.1368 - val_loss: 6833.8945\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5771.9147 - val_loss: 3285.3997\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2819.1935 - val_loss: 1465.8988\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1241.8663 - val_loss: 666.9434\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 609.9233 - val_loss: 369.8937\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 343.1569 - val_loss: 281.0250\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.8884 - val_loss: 258.0660\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 251.8816 - val_loss: 251.4718\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.2892 - val_loss: 248.9451\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 246.9257 - val_loss: 247.0751\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.8772 - val_loss: 244.9263\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.1129 - val_loss: 243.0113\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.0490 - val_loss: 241.2066\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.7107 - val_loss: 239.0194\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.3697 - val_loss: 237.0938\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.7787 - val_loss: 235.2503\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.8094 - val_loss: 233.1898\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.7017 - val_loss: 231.3752\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.6490 - val_loss: 229.5199\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.2825 - val_loss: 228.0016\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 242.5587 - val_loss: 226.3730\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 230.5217 - val_loss: 225.0495\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.7654 - val_loss: 223.3034\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 233.3192 - val_loss: 221.9471\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.9695 - val_loss: 220.5027\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.9461 - val_loss: 219.1116\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.4412 - val_loss: 217.9107\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 233.6321 - val_loss: 216.6131\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 224.7527 - val_loss: 215.3489\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.9704 - val_loss: 213.8267\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.7377 - val_loss: 212.6319\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.5036 - val_loss: 211.4019\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 239.7647 - val_loss: 210.2265\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.4398 - val_loss: 208.9117\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 224.4400 - val_loss: 207.5564\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 213.5912 - val_loss: 206.3963\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.7416 - val_loss: 205.1701\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.3906 - val_loss: 204.1890\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.3114 - val_loss: 202.5610\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 229.1942 - val_loss: 201.3624\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.2000 - val_loss: 200.0086\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.5324 - val_loss: 198.6140\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 213.0813 - val_loss: 197.4550\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 205.2691 - val_loss: 195.9776\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  36  :  192.59986480393803\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  37 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 70351.5122 - val_loss: 45167.0352\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 38330.2764 - val_loss: 25351.8711\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 22790.7219 - val_loss: 15012.7383\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 14208.3220 - val_loss: 9448.1279\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8313.2582 - val_loss: 6295.2300\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5376.5070 - val_loss: 4331.5215\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3826.2053 - val_loss: 3066.0383\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2830.0493 - val_loss: 2212.8274\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2026.1618 - val_loss: 1629.0443\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1613.3534 - val_loss: 1243.2264\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1171.5174 - val_loss: 1009.3421\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 845.0300 - val_loss: 877.0074\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 799.7803 - val_loss: 795.4631\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 777.4085 - val_loss: 741.8714\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 692.4646 - val_loss: 697.9160\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 664.1643 - val_loss: 659.4718\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 574.3198 - val_loss: 628.3787\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 553.5799 - val_loss: 598.6396\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 521.7489 - val_loss: 573.4634\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 494.5003 - val_loss: 548.5095\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 520.4081 - val_loss: 526.2283\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 462.5266 - val_loss: 505.9912\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 449.8995 - val_loss: 484.8845\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 493.8786 - val_loss: 467.3554\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 412.1041 - val_loss: 453.0143\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 418.1025 - val_loss: 440.5110\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 369.7478 - val_loss: 426.6552\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 409.8312 - val_loss: 415.0016\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 420.1796 - val_loss: 403.9027\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 336.0717 - val_loss: 396.6180\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 382.7939 - val_loss: 387.6325\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 378.5427 - val_loss: 377.4863\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 354.3975 - val_loss: 367.5301\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 341.2587 - val_loss: 359.8772\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 340.2717 - val_loss: 351.4738\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 353.7614 - val_loss: 342.2525\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 321.1247 - val_loss: 334.7413\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 316.1268 - val_loss: 325.5443\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 309.3277 - val_loss: 317.5941\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 303.2873 - val_loss: 308.9070\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 282.6596 - val_loss: 299.7773\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.7488 - val_loss: 286.5915\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.0711 - val_loss: 268.5116\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.0085 - val_loss: 253.7048\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.1350 - val_loss: 247.2089\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 244.4842 - val_loss: 240.1913\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.7000 - val_loss: 233.5515\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.9460 - val_loss: 229.0636\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 210.7396 - val_loss: 224.4857\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.9761 - val_loss: 219.7404\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  37  :  239.3093416988021\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  38 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 2461.0436 - val_loss: 1274.2506\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1168.6268 - val_loss: 886.6364\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 906.6317 - val_loss: 668.3876\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 826.6832 - val_loss: 499.9738\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 534.6682 - val_loss: 389.2505\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 380.8038 - val_loss: 310.5195\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 304.4727 - val_loss: 259.2818\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 283.1275 - val_loss: 232.4812\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.9818 - val_loss: 212.1056\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.7348 - val_loss: 201.1042\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.4208 - val_loss: 204.5555\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.8836 - val_loss: 186.4917\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.8964 - val_loss: 182.8340\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.2409 - val_loss: 180.8173\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.3308 - val_loss: 176.4208\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.8921 - val_loss: 176.4364\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 161.3983 - val_loss: 178.6676\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.4727 - val_loss: 170.4037\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.6914 - val_loss: 168.2608\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.4281 - val_loss: 173.4731\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.3700 - val_loss: 164.9352\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.0644 - val_loss: 167.3305\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 161.9756 - val_loss: 167.8226\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.3753 - val_loss: 163.3405\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.8918 - val_loss: 159.6642\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.6272 - val_loss: 162.3284\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.8625 - val_loss: 164.0833\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.0124 - val_loss: 154.2399\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.3388 - val_loss: 152.5238\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.1981 - val_loss: 161.0424\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.4834 - val_loss: 164.7364\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.0124 - val_loss: 152.9162\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 149.1696 - val_loss: 149.1394\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.3019 - val_loss: 144.9256\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.7715 - val_loss: 142.5401\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.7703 - val_loss: 140.6236\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.6209 - val_loss: 141.5349\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.2109 - val_loss: 144.6346\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.3175 - val_loss: 138.0487\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.1517 - val_loss: 135.4584\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.4608 - val_loss: 138.8496\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.5033 - val_loss: 132.7399\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.0293 - val_loss: 136.2466\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.2579 - val_loss: 133.9250\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.4390 - val_loss: 130.3875\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.3673 - val_loss: 127.7854\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.6494 - val_loss: 126.4481\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.6768 - val_loss: 126.1531\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.9097 - val_loss: 131.0801\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.0827 - val_loss: 123.0419\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  38  :  153.37394895489814\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  39 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 42969.1000 - val_loss: 20742.2559\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 17896.1228 - val_loss: 6545.9844\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5579.5815 - val_loss: 3974.1042\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4098.0931 - val_loss: 3416.4521\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 3444.8316 - val_loss: 3056.9048\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3286.3404 - val_loss: 2814.0615\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2629.1511 - val_loss: 2615.7595\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2559.6784 - val_loss: 2434.2505\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2328.8014 - val_loss: 2264.8979\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2330.0984 - val_loss: 2113.4292\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2233.9063 - val_loss: 1988.4486\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2001.8909 - val_loss: 1864.4774\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1946.8870 - val_loss: 1744.0266\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1637.0427 - val_loss: 1643.8420\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1763.8510 - val_loss: 1553.2521\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1595.1668 - val_loss: 1461.3873\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1406.0761 - val_loss: 1381.8549\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1289.0223 - val_loss: 1308.3597\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1260.4807 - val_loss: 1241.4595\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1308.3501 - val_loss: 1179.6235\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1195.8671 - val_loss: 1116.9650\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1266.3075 - val_loss: 1064.3707\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1007.7768 - val_loss: 1012.8834\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1113.4666 - val_loss: 968.4462\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 977.3521 - val_loss: 923.7335\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 929.3345 - val_loss: 883.2529\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 901.0313 - val_loss: 847.8390\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 811.7545 - val_loss: 811.5469\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 827.5906 - val_loss: 776.2919\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 763.6056 - val_loss: 746.0771\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 765.8972 - val_loss: 719.4214\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 698.5908 - val_loss: 689.0203\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 695.5965 - val_loss: 663.5424\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 670.1351 - val_loss: 638.4826\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 602.2844 - val_loss: 616.1261\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 600.3098 - val_loss: 593.1006\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 640.3919 - val_loss: 572.3532\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 574.6375 - val_loss: 551.0991\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 599.0517 - val_loss: 531.5684\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 554.3745 - val_loss: 515.2561\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 558.3534 - val_loss: 496.3250\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 481.5089 - val_loss: 479.9465\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 515.1895 - val_loss: 462.8407\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 478.8325 - val_loss: 445.9020\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 431.6737 - val_loss: 431.8256\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 419.5072 - val_loss: 416.8075\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 385.9466 - val_loss: 404.2740\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 394.5539 - val_loss: 392.9222\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 388.7185 - val_loss: 379.2020\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 362.1076 - val_loss: 368.1246\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  39  :  356.50372573593097\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  40 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 10490.1754 - val_loss: 953.1606\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 581.6137 - val_loss: 556.4570\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 510.3012 - val_loss: 273.1862\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.2061 - val_loss: 252.5859\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 293.4664 - val_loss: 239.0454\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 257.2754 - val_loss: 238.2221\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.4994 - val_loss: 232.9162\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 256.3982 - val_loss: 230.6046\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.7907 - val_loss: 229.8099\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.7131 - val_loss: 225.1638\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.6343 - val_loss: 225.6492\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.4856 - val_loss: 220.5683\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.8539 - val_loss: 219.1609\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.2393 - val_loss: 216.4187\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.2275 - val_loss: 214.9520\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.0629 - val_loss: 212.3192\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.2457 - val_loss: 212.8582\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.2935 - val_loss: 208.6389\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.2201 - val_loss: 206.7944\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.7762 - val_loss: 204.4751\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.2133 - val_loss: 203.7497\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.1541 - val_loss: 200.9346\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.4226 - val_loss: 199.4484\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.7728 - val_loss: 196.9528\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.0236 - val_loss: 195.0461\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.0564 - val_loss: 193.2856\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.0538 - val_loss: 192.4516\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.3611 - val_loss: 189.5963\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.3166 - val_loss: 188.8616\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.8571 - val_loss: 186.2798\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.2377 - val_loss: 184.3294\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.5317 - val_loss: 183.4262\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.1324 - val_loss: 180.9037\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.6748 - val_loss: 182.1593\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.0324 - val_loss: 176.5939\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.4674 - val_loss: 174.5836\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.4867 - val_loss: 172.5377\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 168.5646 - val_loss: 170.7207\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.2748 - val_loss: 168.9913\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.9143 - val_loss: 167.1420\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.8656 - val_loss: 164.8764\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.4612 - val_loss: 163.0540\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.7354 - val_loss: 161.2796\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.0475 - val_loss: 161.2064\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.1881 - val_loss: 157.2132\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.7825 - val_loss: 155.7031\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.5594 - val_loss: 153.9657\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.9136 - val_loss: 153.9863\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.2017 - val_loss: 149.6088\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.3341 - val_loss: 147.6628\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  40  :  160.98670072913083\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  41 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 153642.3143 - val_loss: 74578.2969\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 65477.9715 - val_loss: 27961.5410\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 23771.1328 - val_loss: 8657.4834\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7008.2312 - val_loss: 4558.2168\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4391.9088 - val_loss: 4059.7400\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4016.8020 - val_loss: 3389.6104\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3127.1391 - val_loss: 2863.4260\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2902.3289 - val_loss: 2418.5266\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2527.6287 - val_loss: 2023.1814\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2137.9178 - val_loss: 1671.8221\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1715.3037 - val_loss: 1388.1747\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1397.4534 - val_loss: 1158.9786\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1149.4107 - val_loss: 1001.7646\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1143.2241 - val_loss: 889.3427\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 907.3126 - val_loss: 800.7074\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 789.4791 - val_loss: 725.6968\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 778.1059 - val_loss: 659.2193\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 679.3210 - val_loss: 599.6912\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 609.3417 - val_loss: 550.4493\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 596.5823 - val_loss: 501.1124\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 498.8085 - val_loss: 461.5606\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 482.7893 - val_loss: 423.3206\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 437.9335 - val_loss: 391.2747\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 395.9963 - val_loss: 364.2773\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 375.2542 - val_loss: 338.3786\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 329.8645 - val_loss: 317.6831\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 336.1334 - val_loss: 299.1346\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 332.2226 - val_loss: 283.4344\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 294.7141 - val_loss: 269.6983\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 276.2190 - val_loss: 257.7924\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 251.7029 - val_loss: 247.5362\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.6292 - val_loss: 238.7305\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.5857 - val_loss: 231.1269\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.5721 - val_loss: 224.2298\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.2393 - val_loss: 218.2436\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.0379 - val_loss: 213.0569\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.1384 - val_loss: 208.7042\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.4604 - val_loss: 204.5050\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.6104 - val_loss: 200.8520\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.3959 - val_loss: 197.7065\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.0299 - val_loss: 194.1374\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 196.7464 - val_loss: 191.3472\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.6705 - val_loss: 188.6317\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.7660 - val_loss: 186.5496\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.6211 - val_loss: 183.6632\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.7755 - val_loss: 181.5607\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.0298 - val_loss: 179.3538\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.0237 - val_loss: 177.2285\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.9361 - val_loss: 175.2975\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 173.5888 - val_loss: 173.3991\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  41  :  207.5212682038402\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  42 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 9429.2365 - val_loss: 806.5368\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1244.0312 - val_loss: 766.6324\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 805.6229 - val_loss: 700.1413\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 734.4563 - val_loss: 603.8627\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 658.1346 - val_loss: 574.8651\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 669.7516 - val_loss: 540.1002\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 607.6870 - val_loss: 510.0120\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 527.2042 - val_loss: 485.5116\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 507.7811 - val_loss: 456.4554\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 520.3394 - val_loss: 437.1037\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 453.6994 - val_loss: 412.2838\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 383.1226 - val_loss: 401.3320\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 386.6333 - val_loss: 376.7067\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 355.9651 - val_loss: 360.8970\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 363.9403 - val_loss: 346.1509\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 354.4240 - val_loss: 335.2178\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 327.9745 - val_loss: 320.9199\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 325.4782 - val_loss: 309.9038\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.9831 - val_loss: 297.9044\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 289.0714 - val_loss: 288.1641\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.5162 - val_loss: 278.7737\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 265.2042 - val_loss: 270.8691\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.0295 - val_loss: 266.2765\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.1321 - val_loss: 256.3461\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.5027 - val_loss: 248.2510\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.1088 - val_loss: 247.9597\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.1061 - val_loss: 235.6179\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 254.3636 - val_loss: 233.2342\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 220.7113 - val_loss: 232.8475\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.8292 - val_loss: 217.6001\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.5703 - val_loss: 211.1564\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.8506 - val_loss: 205.7640\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 205.7597 - val_loss: 199.0159\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.0374 - val_loss: 193.7666\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.8296 - val_loss: 189.2906\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.3420 - val_loss: 184.3199\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.2443 - val_loss: 186.6855\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.6521 - val_loss: 176.0800\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.9864 - val_loss: 174.0594\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 164.3474 - val_loss: 172.8060\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.5828 - val_loss: 174.4235\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.3852 - val_loss: 160.4274\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.8415 - val_loss: 157.8551\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.2749 - val_loss: 154.1781\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.9888 - val_loss: 152.5916\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.3096 - val_loss: 149.8489\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 126.3313 - val_loss: 145.1091\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.2782 - val_loss: 142.6771\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.7741 - val_loss: 139.5571\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.2113 - val_loss: 137.1406\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  42  :  138.45395078839266\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  43 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 17127.6967 - val_loss: 4388.0781\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3860.4516 - val_loss: 2481.9214\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 2221.7755 - val_loss: 1817.5391\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1660.5113 - val_loss: 1258.0055\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1148.6095 - val_loss: 929.2877\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 834.8503 - val_loss: 733.2944\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 747.3215 - val_loss: 642.7391\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 658.3768 - val_loss: 572.0652\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 610.8459 - val_loss: 519.7988\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 528.1192 - val_loss: 477.3518\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 491.8200 - val_loss: 441.7021\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 432.8590 - val_loss: 402.8709\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 394.6232 - val_loss: 370.2746\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 396.9134 - val_loss: 351.0479\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 347.3941 - val_loss: 313.4309\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 314.6124 - val_loss: 293.4200\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 281.0150 - val_loss: 270.0570\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.4543 - val_loss: 254.3977\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 230.8518 - val_loss: 237.5083\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 234.4917 - val_loss: 222.2504\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 214.2401 - val_loss: 210.7491\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.3874 - val_loss: 198.0835\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.9170 - val_loss: 192.8821\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.7553 - val_loss: 179.0216\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.6183 - val_loss: 171.0282\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.1842 - val_loss: 168.3496\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.8483 - val_loss: 156.7919\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.3719 - val_loss: 152.3275\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.1723 - val_loss: 145.9807\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.2781 - val_loss: 140.3752\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.2725 - val_loss: 134.7994\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.5845 - val_loss: 130.0860\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.7573 - val_loss: 126.6447\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.7685 - val_loss: 132.9577\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.3663 - val_loss: 139.3846\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.1910 - val_loss: 130.3781\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.6903 - val_loss: 125.0056\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.7565 - val_loss: 113.9504\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.3329 - val_loss: 109.7731\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.2373 - val_loss: 109.8734\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 115.7765 - val_loss: 105.7947\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 107.8439 - val_loss: 106.6106\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.1103 - val_loss: 100.9288\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.2877 - val_loss: 99.3077\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.7333 - val_loss: 98.5233\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.7772 - val_loss: 97.7109\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 96.0484 - val_loss: 95.6653\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.5597 - val_loss: 94.7179\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.9160 - val_loss: 92.7036\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.1419 - val_loss: 92.1755\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  43  :  101.95083293350584\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  44 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 234353.8621 - val_loss: 99005.4219\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77697.3242 - val_loss: 21927.9180\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 17558.2941 - val_loss: 3735.5046\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4046.9088 - val_loss: 2174.1382\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2372.4037 - val_loss: 2134.0898\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2775.1458 - val_loss: 1928.4813\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2034.3379 - val_loss: 1822.4508\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2200.9938 - val_loss: 1762.3760\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1952.6410 - val_loss: 1715.9915\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2429.3685 - val_loss: 1671.1652\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2113.8072 - val_loss: 1624.0697\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2169.1720 - val_loss: 1584.8276\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1953.9359 - val_loss: 1546.8856\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1752.9146 - val_loss: 1514.1284\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1607.7564 - val_loss: 1476.8560\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1880.7143 - val_loss: 1441.5935\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1967.8501 - val_loss: 1408.2906\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1558.0867 - val_loss: 1376.6627\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1700.0152 - val_loss: 1344.5826\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1716.6510 - val_loss: 1313.8239\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1365.8213 - val_loss: 1283.4843\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1407.6922 - val_loss: 1255.2065\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1441.0903 - val_loss: 1225.3320\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1391.5277 - val_loss: 1195.3535\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1403.9576 - val_loss: 1170.6909\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1271.7537 - val_loss: 1142.0308\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1290.9983 - val_loss: 1115.3149\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1178.8428 - val_loss: 1091.6158\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1105.9761 - val_loss: 1065.2544\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1203.0161 - val_loss: 1040.6055\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1155.7047 - val_loss: 1015.3582\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1272.5833 - val_loss: 991.6287\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1215.3485 - val_loss: 968.1375\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1142.0678 - val_loss: 947.0765\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1197.7023 - val_loss: 922.6229\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1014.4537 - val_loss: 904.0481\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1025.8160 - val_loss: 879.7746\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1016.5247 - val_loss: 858.7766\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 922.8496 - val_loss: 838.8214\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 993.0055 - val_loss: 817.5890\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 931.1854 - val_loss: 799.5422\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 865.4154 - val_loss: 779.6679\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 924.1522 - val_loss: 760.0505\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 804.0150 - val_loss: 744.2930\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 819.3606 - val_loss: 724.8553\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 785.0834 - val_loss: 706.3651\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 765.9371 - val_loss: 689.2936\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 764.6456 - val_loss: 673.7451\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 774.4604 - val_loss: 655.8141\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 727.9637 - val_loss: 640.5053\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  44  :  791.0978572862231\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  45 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 10355.7033 - val_loss: 1223.9585\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 972.0615 - val_loss: 904.8683\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 654.9209 - val_loss: 526.7115\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 520.7147 - val_loss: 513.0290\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 530.5425 - val_loss: 498.1636\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 501.6404 - val_loss: 479.7742\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 495.1776 - val_loss: 462.7148\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 462.4014 - val_loss: 444.6819\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 458.0996 - val_loss: 427.3633\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 499.4301 - val_loss: 410.6803\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 424.6900 - val_loss: 395.0709\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 394.8256 - val_loss: 382.0414\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 389.9858 - val_loss: 368.5415\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 402.3272 - val_loss: 353.7284\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 380.8158 - val_loss: 341.5973\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 359.4767 - val_loss: 329.3393\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 342.9441 - val_loss: 319.3893\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 346.3000 - val_loss: 307.7316\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 333.5107 - val_loss: 297.5525\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 320.3221 - val_loss: 289.2426\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 297.0820 - val_loss: 279.6021\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 293.0809 - val_loss: 271.5790\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.9278 - val_loss: 262.7294\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 279.6174 - val_loss: 255.7564\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 276.7309 - val_loss: 248.3897\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.0035 - val_loss: 240.4164\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 289.9471 - val_loss: 233.6359\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.3031 - val_loss: 226.2574\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 233.1113 - val_loss: 221.0354\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 233.1245 - val_loss: 214.3300\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 270.7313 - val_loss: 209.0450\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.9207 - val_loss: 203.2206\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.6253 - val_loss: 198.1284\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.4788 - val_loss: 192.2602\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.3999 - val_loss: 188.8596\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.1906 - val_loss: 183.3543\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 214.0954 - val_loss: 181.7791\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.5763 - val_loss: 175.7366\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.2653 - val_loss: 168.9924\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.3384 - val_loss: 164.9060\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 189.8106 - val_loss: 161.0508\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.9223 - val_loss: 161.5490\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.4301 - val_loss: 153.5636\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.8802 - val_loss: 154.0437\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.1604 - val_loss: 147.2888\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 161.5662 - val_loss: 143.8605\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.8652 - val_loss: 142.3616\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.1935 - val_loss: 138.3285\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.1344 - val_loss: 134.5381\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.5355 - val_loss: 131.8569\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  45  :  147.74072734202545\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  46 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 36495.3110 - val_loss: 5408.7534\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3564.5053 - val_loss: 2081.1416\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2304.5125 - val_loss: 1539.5978\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1601.6689 - val_loss: 1342.1810\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1323.7733 - val_loss: 1142.7863\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1282.0052 - val_loss: 1003.2201\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1132.4606 - val_loss: 886.6233\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 929.0137 - val_loss: 780.8549\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 792.2507 - val_loss: 693.1776\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 703.2342 - val_loss: 616.8826\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 633.3740 - val_loss: 553.4845\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 537.7452 - val_loss: 495.2820\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 500.1809 - val_loss: 447.8685\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 479.0200 - val_loss: 405.5359\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 450.7288 - val_loss: 369.1843\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361.5879 - val_loss: 339.2552\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 324.6099 - val_loss: 312.6916\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 323.7373 - val_loss: 289.9103\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 295.4754 - val_loss: 272.3846\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 286.4844 - val_loss: 254.2899\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 261.2806 - val_loss: 240.3825\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.7376 - val_loss: 229.4419\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.3183 - val_loss: 220.7907\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.8397 - val_loss: 213.1674\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.5532 - val_loss: 209.2218\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 224.3995 - val_loss: 203.2149\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.0942 - val_loss: 197.7966\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.8155 - val_loss: 193.9295\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.7063 - val_loss: 190.5873\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.3046 - val_loss: 187.4395\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.0382 - val_loss: 184.5979\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.4898 - val_loss: 182.3026\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.8575 - val_loss: 180.6364\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.7333 - val_loss: 176.8329\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.3336 - val_loss: 174.9653\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.7351 - val_loss: 172.2990\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.2217 - val_loss: 170.3233\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.5816 - val_loss: 169.2483\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.0928 - val_loss: 165.9118\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 156.8874 - val_loss: 163.6135\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.3005 - val_loss: 162.0497\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.6904 - val_loss: 168.5577\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.4241 - val_loss: 161.2030\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 163.2269 - val_loss: 155.4566\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.5300 - val_loss: 154.4234\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.3939 - val_loss: 152.0704\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.8325 - val_loss: 150.7846\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.9766 - val_loss: 148.6737\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.0273 - val_loss: 147.0800\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.8575 - val_loss: 145.4222\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  46  :  170.42839166922283\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  47 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 346837.2022 - val_loss: 175124.5938\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134111.0317 - val_loss: 52620.4531\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 36898.3659 - val_loss: 10156.6084\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6832.8018 - val_loss: 2226.6675\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2102.4809 - val_loss: 1902.0182\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2069.3825 - val_loss: 1841.0348\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2094.7216 - val_loss: 1791.3654\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1940.4426 - val_loss: 1763.3491\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1996.2890 - val_loss: 1725.1019\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1951.7943 - val_loss: 1675.6957\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1679.3524 - val_loss: 1632.2655\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1714.3604 - val_loss: 1590.5175\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1830.1022 - val_loss: 1545.1333\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1664.7346 - val_loss: 1507.1608\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1691.1768 - val_loss: 1462.7814\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1512.8914 - val_loss: 1422.2595\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1486.9235 - val_loss: 1380.8491\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1475.8775 - val_loss: 1344.7738\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1379.8626 - val_loss: 1305.0360\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1419.2141 - val_loss: 1267.7458\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1236.5561 - val_loss: 1233.8942\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1253.5031 - val_loss: 1200.8424\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1249.6276 - val_loss: 1167.1639\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1108.7876 - val_loss: 1135.0956\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1242.9509 - val_loss: 1107.1140\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1169.8907 - val_loss: 1072.7657\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1153.7303 - val_loss: 1047.2827\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1189.0470 - val_loss: 1022.1103\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1027.3048 - val_loss: 990.9980\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 955.3372 - val_loss: 969.6415\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1002.4746 - val_loss: 948.0752\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 905.9465 - val_loss: 922.2579\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 999.1290 - val_loss: 900.2635\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 937.2406 - val_loss: 873.4587\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 904.1958 - val_loss: 856.9743\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 873.3339 - val_loss: 833.5259\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 787.3272 - val_loss: 814.8378\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 775.2816 - val_loss: 798.5938\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 829.7525 - val_loss: 780.3907\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 794.1949 - val_loss: 762.4065\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 801.1019 - val_loss: 746.7360\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 721.7430 - val_loss: 731.8988\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 686.2963 - val_loss: 717.6454\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 747.0401 - val_loss: 701.8558\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 730.1329 - val_loss: 690.3143\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 657.8632 - val_loss: 676.5563\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 736.9544 - val_loss: 665.2809\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 675.5191 - val_loss: 651.1956\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 616.5245 - val_loss: 641.2684\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 604.0267 - val_loss: 630.1707\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  47  :  673.4135170647652\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  48 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 3586.6510 - val_loss: 863.0416\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 961.9514 - val_loss: 591.6037\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 526.9893 - val_loss: 583.2112\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 536.4067 - val_loss: 536.1664\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 562.1220 - val_loss: 510.4297\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 521.7829 - val_loss: 473.6967\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 447.1029 - val_loss: 448.1549\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 457.2464 - val_loss: 420.0629\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 418.0031 - val_loss: 394.8182\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 383.1926 - val_loss: 377.8896\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 410.5534 - val_loss: 352.1395\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 343.6253 - val_loss: 333.6353\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 347.7790 - val_loss: 315.2989\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 314.4074 - val_loss: 300.6977\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 307.4989 - val_loss: 283.8649\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 274.0488 - val_loss: 280.3480\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.3443 - val_loss: 262.2202\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 276.5312 - val_loss: 247.4275\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 263.3513 - val_loss: 236.9476\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.3028 - val_loss: 227.3477\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.6624 - val_loss: 219.1988\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 220.0307 - val_loss: 214.6626\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.7814 - val_loss: 204.0905\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.9906 - val_loss: 209.3215\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.8788 - val_loss: 197.4864\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 205.3868 - val_loss: 190.6684\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.6058 - val_loss: 180.6590\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.0171 - val_loss: 175.8703\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.1740 - val_loss: 177.8535\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.0279 - val_loss: 167.1920\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.6089 - val_loss: 164.7712\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.5433 - val_loss: 160.1456\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.2455 - val_loss: 160.0295\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 175.2480 - val_loss: 158.1807\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.6952 - val_loss: 153.3034\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 150.4582 - val_loss: 149.5274\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.2039 - val_loss: 148.4663\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.6839 - val_loss: 144.4486\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.7949 - val_loss: 146.4286\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.3185 - val_loss: 143.3813\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.2151 - val_loss: 138.8784\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.1322 - val_loss: 137.1410\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.5309 - val_loss: 149.3158\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.3708 - val_loss: 134.8029\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.0148 - val_loss: 133.4636\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.1008 - val_loss: 135.5743\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.1795 - val_loss: 132.9788\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.8128 - val_loss: 129.6603\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.2278 - val_loss: 128.7993\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 124.2172 - val_loss: 128.2991\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  48  :  153.0388400663672\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  49 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 28542.6634 - val_loss: 17449.2070\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 15616.0645 - val_loss: 8722.8555\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8267.1064 - val_loss: 5002.2949\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5022.2059 - val_loss: 3284.7073\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2586.7376 - val_loss: 1057.7496\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1109.5210 - val_loss: 908.0388\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 877.9771 - val_loss: 682.6955\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 678.1550 - val_loss: 585.6202\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 559.9863 - val_loss: 514.3717\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 506.2974 - val_loss: 455.5592\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 449.4905 - val_loss: 408.1778\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 381.2027 - val_loss: 368.8991\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 370.2640 - val_loss: 331.6771\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 326.8033 - val_loss: 296.8019\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 294.7794 - val_loss: 256.8433\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 233.2565 - val_loss: 219.0784\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.7409 - val_loss: 177.7333\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 178.9773 - val_loss: 160.6656\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.3462 - val_loss: 148.5697\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.3811 - val_loss: 139.9457\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 155.8745 - val_loss: 134.0825\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.5968 - val_loss: 128.3667\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.7103 - val_loss: 123.2742\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.5387 - val_loss: 119.5968\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.9706 - val_loss: 115.3535\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.8670 - val_loss: 111.8003\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.5668 - val_loss: 108.8902\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.1465 - val_loss: 106.9978\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 104.6857 - val_loss: 103.7247\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 107.4906 - val_loss: 102.0138\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.7008 - val_loss: 101.4917\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.1618 - val_loss: 98.4851\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 111.9042 - val_loss: 99.9176\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.9400 - val_loss: 95.5154\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.5488 - val_loss: 95.9546\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.0957 - val_loss: 93.7939\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.5846 - val_loss: 92.7521\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.2169 - val_loss: 91.7551\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.4332 - val_loss: 95.3583\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 94.9792 - val_loss: 89.8491\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 95.6922 - val_loss: 90.8877\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.9452 - val_loss: 89.6413\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.8917 - val_loss: 87.7518\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.4596 - val_loss: 87.6322\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 95.7222 - val_loss: 87.1305\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.7926 - val_loss: 86.4131\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.6922 - val_loss: 85.4198\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 75.9791 - val_loss: 86.5335\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.4410 - val_loss: 83.5432\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.7787 - val_loss: 83.2523\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  49  :  95.64376504126923\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  50 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 644963.0662 - val_loss: 402393.0000\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 341849.1397 - val_loss: 206205.2344\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173919.5441 - val_loss: 104383.4531\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85552.3667 - val_loss: 51803.7031\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 42833.0230 - val_loss: 24332.5820\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 19899.2883 - val_loss: 10561.7578\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 8396.9788 - val_loss: 4252.4990\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3385.4751 - val_loss: 1874.5317\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1512.4286 - val_loss: 1188.7684\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1061.1094 - val_loss: 1056.3074\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 939.4379 - val_loss: 1026.4733\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 894.3327 - val_loss: 1007.9522\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 848.2624 - val_loss: 989.8216\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 981.0196 - val_loss: 971.3776\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 806.7190 - val_loss: 954.3450\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 835.2129 - val_loss: 936.1868\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 761.3685 - val_loss: 918.6923\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 798.2468 - val_loss: 901.3189\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 794.2552 - val_loss: 885.8697\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 812.5767 - val_loss: 869.1039\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 781.0326 - val_loss: 853.8975\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 735.6910 - val_loss: 837.7593\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 756.8901 - val_loss: 822.4442\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 719.4867 - val_loss: 808.0761\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 760.7121 - val_loss: 793.3157\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 689.3349 - val_loss: 777.9290\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 692.9666 - val_loss: 763.2604\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 607.3855 - val_loss: 748.1815\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 610.8914 - val_loss: 734.6354\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 660.0621 - val_loss: 720.2119\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 695.6511 - val_loss: 707.5139\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 626.8592 - val_loss: 693.9300\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 672.7818 - val_loss: 681.5502\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 626.8487 - val_loss: 669.3931\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 632.0160 - val_loss: 658.0963\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 593.0751 - val_loss: 647.1489\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 604.8459 - val_loss: 636.4192\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 576.5219 - val_loss: 625.4172\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 581.9539 - val_loss: 615.0750\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 552.0577 - val_loss: 605.0533\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 515.4106 - val_loss: 594.2252\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 542.9531 - val_loss: 583.9813\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 508.8892 - val_loss: 573.6764\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 486.0238 - val_loss: 563.9671\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 502.8892 - val_loss: 554.6881\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 464.9645 - val_loss: 544.5023\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 505.7627 - val_loss: 536.8577\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 449.1370 - val_loss: 525.0613\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 468.6074 - val_loss: 515.0228\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 479.0905 - val_loss: 503.4690\n",
            "\n",
            "\n",
            "Mean Squared Error for Training Model #  50  :  549.5409382779706\n",
            "\n",
            "\n",
            "Total Execution Time :  0:04:20.124936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9eMv66aCn11",
        "outputId": "153729b0-1866-47a5-b091-a929139823a8"
      },
      "source": [
        "# Calculate the Mean of the MSE of 50 models\n",
        "mean_of_mse = stats.mean(list_of_mse)\n",
        "\n",
        "# Calculate the Standard Deviation of the MSE of 50 models\n",
        "std_of_mse = stats.stdev(list_of_mse)\n",
        "\n",
        "# Print the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nMean of the MSE of 50 Models : ' , str(mean_of_mse))\n",
        "print('Standard Deviation of MSE of 50 Models : ' , str(std_of_mse))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean of the MSE of 50 Models :  212.12918204304935\n",
            "Standard Deviation of MSE of 50 Models :  136.03460413795105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HH29k-mCn17"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHmB-6SvCn18"
      },
      "source": [
        "# <font color = blue> END OF PART A </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3443yq8ICn19"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2TJvQBaJG1d"
      },
      "source": [
        "# <font color = blue> PART B : BASELINE MODEL WITH NORMALIZED FEATURES </font>\r\n",
        "\r\n",
        "\r\n",
        "In this part, all the tasks from <b>PART A</b> are performed, but this time the values for the features (X) will be normalized using the formula `X - µ / σ`\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7vPPHLGCn2E"
      },
      "source": [
        "## <font color = darkorange>Task 1 : Train and Test the Baseline Model with Normalized Features</font>\n",
        "\n",
        "In order to train and test the the baseline model with normalized features, the following steps are performed :\n",
        "<ol>\n",
        "    <li>Normalize the features (X)</li>\n",
        "    <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "    <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "    <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "    <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmW0qu_bCn2H"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Normalize the features (X) </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KzLsPEHCn2I"
      },
      "source": [
        "X = X - X.mean() / X.std()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yO0ZvnQCn2J"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Randomly split the data into <i>X_train, X_test, Y_train, Y_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfGEgsE5Cn2L"
      },
      "source": [
        "# Creating X_train, X_test, Y_train and Y_test sets\n",
        "X_train, X_test, Y_train, Y_test = data_split()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1srULkGlCn2M"
      },
      "source": [
        "### <font color = #2980B9> Step 3 : Train the model using <i>X_train, Y_train</i> using 50 epochs </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK0M47urCn2M"
      },
      "source": [
        "<b>Note </b> : Since the regression model has already been created using `def regression_model` in <b>TASK 1</b> and there are no changes being made to it, hence there is no need to write the code for the model again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKU5NivsCn2W",
        "outputId": "0130a2bd-70a1-4de0-f598-2a9b83604d3c"
      },
      "source": [
        "model = regression_model()\n",
        "\n",
        "# Fit the model on the train set\n",
        "model.fit(X_train, Y_train, validation_split=0.3, epochs=50)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 5194.8498 - val_loss: 2465.0786\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2623.0342 - val_loss: 1860.1479\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1919.7544 - val_loss: 1509.5568\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1582.6834 - val_loss: 1219.0430\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1207.4204 - val_loss: 975.2711\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 957.2397 - val_loss: 786.6439\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 805.4368 - val_loss: 632.8056\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 668.1673 - val_loss: 479.7115\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 437.1839 - val_loss: 345.4590\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.9752 - val_loss: 248.2606\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.1840 - val_loss: 194.1391\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.0174 - val_loss: 173.2299\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 208.9798 - val_loss: 163.7307\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.9971 - val_loss: 157.9197\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.8872 - val_loss: 154.2991\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.5812 - val_loss: 152.0506\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.9707 - val_loss: 148.7568\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.4967 - val_loss: 146.6441\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.4109 - val_loss: 145.9901\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.0197 - val_loss: 144.1235\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.6685 - val_loss: 142.2429\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.6851 - val_loss: 141.5415\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.8821 - val_loss: 141.1302\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.1515 - val_loss: 139.3393\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.7402 - val_loss: 137.8030\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.8651 - val_loss: 138.6651\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.7026 - val_loss: 137.3398\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.3858 - val_loss: 136.1418\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.6013 - val_loss: 136.8401\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.0595 - val_loss: 136.1539\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.1787 - val_loss: 133.4717\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.3777 - val_loss: 133.0690\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.8697 - val_loss: 132.1697\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6401 - val_loss: 131.5326\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.3429 - val_loss: 131.1175\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.7925 - val_loss: 130.9201\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.6065 - val_loss: 129.5687\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.7362 - val_loss: 128.8612\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.8749 - val_loss: 128.5152\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.5865 - val_loss: 130.1861\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.8442 - val_loss: 127.3523\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2294 - val_loss: 126.6306\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.9605 - val_loss: 126.3275\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.1937 - val_loss: 126.6381\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.0336 - val_loss: 128.6309\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.8874 - val_loss: 125.0164\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0617 - val_loss: 128.5510\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.3528 - val_loss: 123.7056\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.3746 - val_loss: 125.3257\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.1375 - val_loss: 122.6326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56d0d45c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8gEU-xaCn2X"
      },
      "source": [
        "### <font color = #2980B9> Step 4 : Get the predictions on the X_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHbb23HhCn2b"
      },
      "source": [
        "# Store the predictions in a variable Y_Predicted\n",
        "Y_predicted = predict()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAray5RiCn2b"
      },
      "source": [
        "### <font color = #2980B9> Step 5 : Compute the <i>mean squared error</i> on the test set using sklearn </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKrj5wmKCn2c",
        "outputId": "3796856c-81fe-4c3b-cd71-3e3bbfb8a9f7"
      },
      "source": [
        "# Calculate the mean square error\n",
        "\n",
        "mse = calculate_mse()\n",
        "print('Mean Square Error (MSE) of the Baseline Model with Normalized Features is : ' , str(mse))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Square Error (MSE) of the Baseline Model with Normalized Features is :  114.34176469410498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4vheQQ4Cn2c"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcTcQwvxCn2d"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worzyPVyCn2d"
      },
      "source": [
        "## <font color = darkorange>Task 2 : Create 50 Models and Calculate the <i>µ</i> & <i>σ</i> of their MSE Errors with new Features</font>\n",
        "\n",
        "In order to train 50 models with new features (normalized features) and calulate the mean (µ) and standard deviation (σ) of their mean square errors (MSE) the following steps are performed :\n",
        "<ol>\n",
        "    <li>Create an empty list <code>list_of_mse</code> to store the mean square error of each of the models</li>\n",
        "    <li>Define a for loop and perform each of the following steps in the loop</li>\n",
        "        <ol>\n",
        "        <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "        <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "        <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "        <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "        <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "    </ol>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbtoTG6aCn2d"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Creating the <i>list_of_mse</i> list</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kj1TrWUCn2e"
      },
      "source": [
        "# Create the empty lists\n",
        "list_of_mse = []"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0w24AkcCn2e"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Creating 50 Models, Calculating The MSE for Each and <i>µ</i> & <i>σ</i> of the 50 MSE Values in <i>list_of_mse</i> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sgp2b_4Cn2f",
        "outputId": "00207f9f-a79e-4550-d22f-89029b437869"
      },
      "source": [
        "# Create the for loop to split the data, create, compile & fit model, evaluate & nake predictions, caluclate mse and store\n",
        "# in list_of_mse\n",
        "\n",
        "start_time = datetime.now() # Starting time of the for loop execution\n",
        "\n",
        "for i in range(50) :\n",
        "    # Split the data into train and test set\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "    \n",
        "    # Create and compile the regression model using the function regression_model as defined in TASK 1\n",
        "    model = regression_model()\n",
        "\n",
        "    # Fit the model on the train set\n",
        "    print('\\n\\n\\nTraining Model # ' , i+1 , '\\n\\n') # Print the Model Number that is being trained\n",
        "    model.fit(X_train, Y_train, validation_split=0.3, epochs=50)\n",
        "    print('\\n')\n",
        "    \n",
        "    # Make prediction on the test set\n",
        "    Y_predicted = model.predict(X_test)\n",
        "    \n",
        "    # Calculate the mean square error\n",
        "    mse = mean_squared_error(Y_test, Y_predicted)\n",
        "    \n",
        "    # Add the mse to the list_of_mse list\n",
        "    list_of_mse.append(mse)\n",
        "\n",
        "end_time = datetime.now() # Ending time of the for loop execution\n",
        "\n",
        "# Print time taken for fitting 50 models and calucating the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nTotal Execution Time : ' , format(end_time - start_time))\n",
        "    "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.9152 - val_loss: 197.8741\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.1715 - val_loss: 192.7168\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.3052 - val_loss: 190.5627\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.5647 - val_loss: 185.8490\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.3163 - val_loss: 182.0447\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.1079 - val_loss: 181.1352\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 158.3681 - val_loss: 173.1487\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.8530 - val_loss: 180.7898\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.3584 - val_loss: 166.8634\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155.2354 - val_loss: 164.5845\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.2972 - val_loss: 162.1283\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.0052 - val_loss: 163.7517\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.1997 - val_loss: 164.0195\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 147.8441 - val_loss: 171.6323\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  5 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 25737.4062 - val_loss: 10817.7842\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8796.2370 - val_loss: 4041.6511\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3714.1298 - val_loss: 2140.5825\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1883.8976 - val_loss: 1491.4274\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1384.9211 - val_loss: 1135.0659\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 966.8665 - val_loss: 941.4000\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 857.3202 - val_loss: 825.1517\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 699.0431 - val_loss: 759.2076\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 608.5426 - val_loss: 711.8354\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 617.8659 - val_loss: 679.4583\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 612.0847 - val_loss: 652.4759\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 544.7567 - val_loss: 629.5528\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 592.7895 - val_loss: 610.1063\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 550.4515 - val_loss: 592.2542\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 545.3632 - val_loss: 572.5282\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 558.7231 - val_loss: 555.0803\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 486.3289 - val_loss: 536.9260\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 444.1117 - val_loss: 519.9759\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 468.8282 - val_loss: 502.8658\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 449.1905 - val_loss: 489.9735\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 449.7952 - val_loss: 477.0677\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 420.3499 - val_loss: 465.5480\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 397.4712 - val_loss: 454.9122\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 432.7348 - val_loss: 443.3089\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 358.4806 - val_loss: 433.9047\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 354.7307 - val_loss: 427.4539\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 381.9255 - val_loss: 419.9412\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 364.5421 - val_loss: 414.7891\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 361.0135 - val_loss: 408.5796\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 361.2509 - val_loss: 401.0331\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 347.1946 - val_loss: 397.1931\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 349.9106 - val_loss: 390.6968\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 324.6296 - val_loss: 384.1775\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 331.3965 - val_loss: 381.3088\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 325.7267 - val_loss: 373.9532\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 338.8970 - val_loss: 368.4489\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 342.3257 - val_loss: 362.6168\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 282.5235 - val_loss: 355.4911\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 276.3303 - val_loss: 354.2284\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 293.1338 - val_loss: 345.9576\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 272.2426 - val_loss: 341.0044\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 269.8990 - val_loss: 335.2881\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263.0622 - val_loss: 330.6320\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.1869 - val_loss: 326.6966\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.1931 - val_loss: 320.1466\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 270.6112 - val_loss: 317.1021\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 250.3370 - val_loss: 312.1316\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 246.2183 - val_loss: 305.8818\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 245.4879 - val_loss: 303.3982\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.1957 - val_loss: 295.8835\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  6 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 2559.5263 - val_loss: 798.1205\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 693.2427 - val_loss: 348.5688\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 311.0676 - val_loss: 317.6221\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 319.3289 - val_loss: 298.6849\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 264.2259 - val_loss: 287.4590\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.6351 - val_loss: 274.3469\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 282.5787 - val_loss: 264.2199\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.7551 - val_loss: 251.8068\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 216.5758 - val_loss: 240.8854\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.0092 - val_loss: 233.5698\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 220.4692 - val_loss: 223.7024\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 204.9279 - val_loss: 216.4934\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 180.4048 - val_loss: 208.5243\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 193.0627 - val_loss: 199.9439\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.3218 - val_loss: 196.8410\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168.6038 - val_loss: 181.8687\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.9372 - val_loss: 177.6751\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.5719 - val_loss: 173.8780\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.0321 - val_loss: 165.4667\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 136.2655 - val_loss: 164.9485\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.3037 - val_loss: 158.8457\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.9385 - val_loss: 154.3549\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.6817 - val_loss: 150.0452\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.2494 - val_loss: 151.2948\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.6090 - val_loss: 145.6826\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 126.3047 - val_loss: 144.7920\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.9212 - val_loss: 142.0659\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.1755 - val_loss: 137.3484\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.3308 - val_loss: 140.7183\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2967 - val_loss: 135.3818\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.0886 - val_loss: 130.4991\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.6523 - val_loss: 130.0294\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.4468 - val_loss: 126.9140\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.5959 - val_loss: 127.4499\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.4602 - val_loss: 127.8692\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.6692 - val_loss: 124.3088\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.0201 - val_loss: 120.5471\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 93.6183 - val_loss: 122.1555\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.5726 - val_loss: 118.1493\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9820 - val_loss: 120.1765\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.2786 - val_loss: 117.8105\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.7878 - val_loss: 117.4384\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.2858 - val_loss: 116.0481\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.7618 - val_loss: 115.0364\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.7772 - val_loss: 114.8454\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.5770 - val_loss: 115.6068\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.5842 - val_loss: 113.3029\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.5872 - val_loss: 112.4649\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.3142 - val_loss: 112.4030\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.4224 - val_loss: 115.4776\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  7 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 148420.7381 - val_loss: 83846.8047\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68126.0625 - val_loss: 36714.5859\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 28016.6768 - val_loss: 13359.9883\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8815.1421 - val_loss: 3948.6780\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2209.0211 - val_loss: 1721.5231\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1381.4705 - val_loss: 1479.4479\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1216.0941 - val_loss: 1400.2710\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1195.2231 - val_loss: 1345.0913\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1104.5594 - val_loss: 1267.2976\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 980.6741 - val_loss: 1189.9452\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 974.6332 - val_loss: 1113.9746\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 970.1484 - val_loss: 1037.6581\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 827.5022 - val_loss: 980.4354\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 790.2181 - val_loss: 912.1185\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 729.0936 - val_loss: 860.3431\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 660.7627 - val_loss: 801.1970\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 634.2805 - val_loss: 757.2040\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 627.3478 - val_loss: 707.0981\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 591.9897 - val_loss: 669.3458\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 521.1396 - val_loss: 627.6545\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 491.8247 - val_loss: 589.0463\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 468.3303 - val_loss: 554.7239\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 451.2484 - val_loss: 512.0995\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 406.9942 - val_loss: 463.2607\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 358.6489 - val_loss: 424.3235\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 345.8737 - val_loss: 401.8998\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 295.4685 - val_loss: 368.7511\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 330.0810 - val_loss: 345.7476\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.0274 - val_loss: 320.0939\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.2430 - val_loss: 300.8356\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 241.7075 - val_loss: 282.5200\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.7317 - val_loss: 269.9671\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 242.3037 - val_loss: 253.9546\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 227.2427 - val_loss: 240.7667\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.3852 - val_loss: 229.8553\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 203.5265 - val_loss: 219.8331\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.3105 - val_loss: 211.2243\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 190.1285 - val_loss: 202.3652\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.9159 - val_loss: 192.9911\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.1493 - val_loss: 184.8362\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.7323 - val_loss: 180.1105\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.9035 - val_loss: 173.0710\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.1962 - val_loss: 166.8688\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.0230 - val_loss: 163.7332\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 178.9427 - val_loss: 157.8446\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 164.6591 - val_loss: 154.8246\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.2669 - val_loss: 151.3539\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 162.4754 - val_loss: 150.1532\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 167.7134 - val_loss: 147.2952\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.6624 - val_loss: 145.0089\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  8 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 22ms/step - loss: 136334.8842 - val_loss: 79316.9609\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 64752.9368 - val_loss: 34403.6289\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 28719.5202 - val_loss: 13706.1592\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10802.5547 - val_loss: 5433.8560\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4535.6985 - val_loss: 2514.9473\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2033.3408 - val_loss: 1625.1465\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1484.9042 - val_loss: 1344.0548\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1372.3478 - val_loss: 1252.8644\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1210.6884 - val_loss: 1205.5554\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1181.7312 - val_loss: 1171.7184\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1203.2356 - val_loss: 1143.5640\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1075.4528 - val_loss: 1118.9960\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1034.6694 - val_loss: 1093.8461\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1129.5507 - val_loss: 1069.9015\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1086.0675 - val_loss: 1045.4302\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1061.4421 - val_loss: 1020.8875\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1056.8769 - val_loss: 996.4733\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 992.6839 - val_loss: 972.7046\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1023.6045 - val_loss: 948.1694\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 953.6057 - val_loss: 924.3755\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 910.0802 - val_loss: 899.4592\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 922.1947 - val_loss: 873.3627\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 824.4512 - val_loss: 848.3329\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 907.9781 - val_loss: 820.7321\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 798.3286 - val_loss: 794.0351\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 877.0436 - val_loss: 766.9383\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 832.2009 - val_loss: 739.9583\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 745.9575 - val_loss: 713.3898\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 666.9116 - val_loss: 688.5504\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 725.9457 - val_loss: 662.8084\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 734.7725 - val_loss: 637.6649\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 676.3147 - val_loss: 614.8977\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 669.6529 - val_loss: 594.9531\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 687.5295 - val_loss: 574.9013\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 586.7696 - val_loss: 557.2823\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 585.0233 - val_loss: 540.0702\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 604.2502 - val_loss: 523.7334\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 579.9623 - val_loss: 506.7372\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 562.0560 - val_loss: 492.2716\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 609.4334 - val_loss: 477.3142\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 504.7060 - val_loss: 465.8338\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 525.9889 - val_loss: 452.6993\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 510.2858 - val_loss: 437.1962\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 484.4425 - val_loss: 427.2247\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 480.4916 - val_loss: 414.2667\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 470.6139 - val_loss: 402.5284\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 444.2583 - val_loss: 391.1813\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 440.4987 - val_loss: 381.2857\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 421.0663 - val_loss: 371.6441\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 423.9404 - val_loss: 361.7668\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  9 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 5528.5257 - val_loss: 4089.6816\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3734.5599 - val_loss: 2692.0371\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2539.6020 - val_loss: 1932.3635\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1754.5973 - val_loss: 1455.8577\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1467.5738 - val_loss: 1141.9480\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1113.9702 - val_loss: 937.9840\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 915.0585 - val_loss: 794.5885\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 749.3149 - val_loss: 683.4250\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 598.0032 - val_loss: 603.3267\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 533.3151 - val_loss: 538.5337\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 530.3971 - val_loss: 483.9364\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 503.2093 - val_loss: 441.6994\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 438.1921 - val_loss: 407.6907\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 416.4342 - val_loss: 379.6349\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 388.6177 - val_loss: 357.4948\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 390.7654 - val_loss: 337.1827\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 320.4804 - val_loss: 321.5769\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 320.2011 - val_loss: 307.8667\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.1289 - val_loss: 298.1208\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 270.4763 - val_loss: 289.0634\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 299.8918 - val_loss: 279.1464\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.6503 - val_loss: 273.2154\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 279.8773 - val_loss: 267.4202\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.3478 - val_loss: 262.5469\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.6862 - val_loss: 258.7149\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.7087 - val_loss: 256.1565\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.9699 - val_loss: 254.6443\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 246.3329 - val_loss: 250.6292\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 266.0269 - val_loss: 248.2992\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.0064 - val_loss: 249.0849\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 255.0456 - val_loss: 246.6572\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.6389 - val_loss: 244.2508\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 224.5309 - val_loss: 242.4487\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.9554 - val_loss: 242.2946\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 241.5502 - val_loss: 241.2823\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 251.1339 - val_loss: 243.1941\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.1516 - val_loss: 244.0782\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.5918 - val_loss: 243.0166\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.5297 - val_loss: 239.6679\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.1973 - val_loss: 238.0442\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 240.8018 - val_loss: 239.2275\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.6412 - val_loss: 237.7147\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.5381 - val_loss: 235.8173\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.9158 - val_loss: 235.1367\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 213.9291 - val_loss: 234.1355\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.1663 - val_loss: 236.3304\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.3515 - val_loss: 232.4076\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.6380 - val_loss: 230.9998\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.5298 - val_loss: 229.8787\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 230.9871 - val_loss: 229.0979\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  10 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 6214.6150 - val_loss: 872.8594\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 685.3775 - val_loss: 530.1042\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 466.3522 - val_loss: 379.6505\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 298.0382 - val_loss: 333.5210\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 292.2236 - val_loss: 298.2104\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.9511 - val_loss: 275.6159\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.4934 - val_loss: 254.5603\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.4449 - val_loss: 239.2075\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.9879 - val_loss: 223.4216\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.1124 - val_loss: 212.0940\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.3677 - val_loss: 199.1507\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.5227 - val_loss: 191.4902\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.2414 - val_loss: 182.8495\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.7431 - val_loss: 174.8794\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.1565 - val_loss: 169.0367\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.4766 - val_loss: 165.0323\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.4823 - val_loss: 157.0346\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.5373 - val_loss: 153.1335\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.7121 - val_loss: 149.5173\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 135.8716 - val_loss: 144.2201\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.4757 - val_loss: 143.9578\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.3967 - val_loss: 137.6118\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.8571 - val_loss: 133.6845\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.3897 - val_loss: 131.0536\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.4586 - val_loss: 127.0885\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.5579 - val_loss: 125.3766\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.4939 - val_loss: 122.6402\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5191 - val_loss: 119.6119\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.4471 - val_loss: 117.2068\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.5918 - val_loss: 114.2471\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.3888 - val_loss: 112.5737\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 117.7979 - val_loss: 111.0493\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.1428 - val_loss: 113.6998\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.3992 - val_loss: 108.3205\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.6466 - val_loss: 105.4881\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.9988 - val_loss: 103.8773\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.6841 - val_loss: 102.7128\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.4462 - val_loss: 101.2508\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 105.5193 - val_loss: 100.2805\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 98.5670 - val_loss: 101.2180\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 106.5665 - val_loss: 98.1370\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.6168 - val_loss: 97.1505\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.3859 - val_loss: 95.8118\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.9881 - val_loss: 95.2753\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.3845 - val_loss: 96.2986\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.2837 - val_loss: 95.2366\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.1267 - val_loss: 96.1090\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.1005 - val_loss: 93.1300\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.3915 - val_loss: 92.9300\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.3453 - val_loss: 94.2850\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  11 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 3198.0387 - val_loss: 1616.8163\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1501.4895 - val_loss: 1128.3807\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1117.0529 - val_loss: 905.7253\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 821.1315 - val_loss: 788.5206\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 736.4027 - val_loss: 680.0538\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 563.2199 - val_loss: 609.8497\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 548.4415 - val_loss: 554.2974\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 453.6510 - val_loss: 510.4583\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 471.1564 - val_loss: 468.0935\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 433.0216 - val_loss: 436.8737\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 402.9021 - val_loss: 411.2302\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 380.4862 - val_loss: 390.2925\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 364.7931 - val_loss: 367.4549\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.2612 - val_loss: 348.7691\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 327.8548 - val_loss: 332.6731\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.2735 - val_loss: 320.6418\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.1289 - val_loss: 314.2784\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.3424 - val_loss: 294.0970\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.5969 - val_loss: 279.1933\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.5003 - val_loss: 270.8878\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.8526 - val_loss: 259.6011\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.7598 - val_loss: 247.6789\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 221.2584 - val_loss: 241.9974\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 232.6672 - val_loss: 241.8179\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 213.8090 - val_loss: 223.2618\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.9409 - val_loss: 224.4883\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.7947 - val_loss: 208.3713\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.2550 - val_loss: 207.8916\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.5878 - val_loss: 197.2159\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.1517 - val_loss: 190.3074\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.4232 - val_loss: 184.5856\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.9135 - val_loss: 182.8404\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.3871 - val_loss: 175.9010\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.6818 - val_loss: 172.6883\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.4907 - val_loss: 167.2839\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 171.3562 - val_loss: 165.4338\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.9578 - val_loss: 160.5308\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.7688 - val_loss: 157.6554\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.3722 - val_loss: 155.0747\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145.2241 - val_loss: 161.1575\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.9474 - val_loss: 162.3553\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163.9654 - val_loss: 148.6737\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.4437 - val_loss: 144.7254\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.3402 - val_loss: 141.7264\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153.2739 - val_loss: 139.6777\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.2876 - val_loss: 140.4797\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159.2142 - val_loss: 135.6393\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.0744 - val_loss: 133.9508\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.0614 - val_loss: 133.6700\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.5564 - val_loss: 130.6963\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  12 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 494.1673 - val_loss: 479.6598\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 400.3281 - val_loss: 437.4038\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 364.1278 - val_loss: 398.2832\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 357.5709 - val_loss: 373.8297\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 332.0324 - val_loss: 346.6609\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 301.0948 - val_loss: 341.6866\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 283.3008 - val_loss: 316.0843\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.7684 - val_loss: 309.4094\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.8174 - val_loss: 293.5076\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 270.8570 - val_loss: 283.8452\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 234.7870 - val_loss: 271.9902\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.9825 - val_loss: 260.0627\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.6643 - val_loss: 253.7555\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 232.6434 - val_loss: 241.9618\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.7055 - val_loss: 235.0493\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.8838 - val_loss: 225.9513\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.3180 - val_loss: 219.5246\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.6975 - val_loss: 212.1987\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 194.7126 - val_loss: 203.3220\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.1481 - val_loss: 201.7168\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.6607 - val_loss: 191.0305\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.0712 - val_loss: 189.8115\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.7006 - val_loss: 179.3967\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.7470 - val_loss: 176.3929\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.1121 - val_loss: 169.8832\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 148.7819 - val_loss: 166.4029\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.6775 - val_loss: 159.7363\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.8197 - val_loss: 158.5527\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.4462 - val_loss: 152.4685\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.8070 - val_loss: 147.9641\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.8157 - val_loss: 146.7988\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.9125 - val_loss: 144.9471\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.5771 - val_loss: 140.4014\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.9641 - val_loss: 138.6376\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3008 - val_loss: 133.9206\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.2223 - val_loss: 134.7342\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.3358 - val_loss: 131.8153\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.7450 - val_loss: 133.1643\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3012 - val_loss: 131.7812\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.9573 - val_loss: 129.3896\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.8163 - val_loss: 125.4618\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.0882 - val_loss: 125.6478\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.5515 - val_loss: 128.6751\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.1930 - val_loss: 129.4136\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.1941 - val_loss: 123.8729\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.1070 - val_loss: 122.4883\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.9528 - val_loss: 128.1649\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.0643 - val_loss: 125.6281\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5960 - val_loss: 122.4022\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.2194 - val_loss: 126.7795\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  13 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 63633.2891 - val_loss: 33201.1016\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 28322.0257 - val_loss: 10515.3994\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9237.2117 - val_loss: 3521.4868\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3716.8411 - val_loss: 2860.2891\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2647.0558 - val_loss: 2245.3733\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2151.8478 - val_loss: 1685.5546\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1670.2719 - val_loss: 1393.4752\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1290.9587 - val_loss: 1186.1639\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 1111.4746 - val_loss: 1018.2735\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 879.0004 - val_loss: 877.2844\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 762.4984 - val_loss: 752.5692\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 705.1028 - val_loss: 660.3345\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 607.0955 - val_loss: 574.9687\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 528.9112 - val_loss: 523.1641\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 543.5776 - val_loss: 461.0658\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 386.8189 - val_loss: 422.1663\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 386.9898 - val_loss: 373.9275\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 349.2786 - val_loss: 355.8799\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 340.4139 - val_loss: 345.4316\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.8989 - val_loss: 299.8543\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 287.7362 - val_loss: 283.2427\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 248.3855 - val_loss: 268.2351\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.7457 - val_loss: 256.8839\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219.8617 - val_loss: 264.2866\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.6622 - val_loss: 232.4940\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.1015 - val_loss: 224.2487\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.6094 - val_loss: 215.1104\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 181.5833 - val_loss: 207.5859\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.7177 - val_loss: 199.3261\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.5263 - val_loss: 195.3515\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 179.7599 - val_loss: 204.7841\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.9517 - val_loss: 184.7187\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.0905 - val_loss: 179.4946\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 152.5298 - val_loss: 182.9371\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.0513 - val_loss: 168.1586\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.4828 - val_loss: 164.1346\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.6745 - val_loss: 162.7993\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.6181 - val_loss: 156.4762\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.5682 - val_loss: 153.7494\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.5425 - val_loss: 150.2154\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.5965 - val_loss: 152.7358\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.8206 - val_loss: 152.5359\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.6150 - val_loss: 142.5118\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.5776 - val_loss: 144.7243\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4193 - val_loss: 140.5109\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.0756 - val_loss: 135.9139\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.4444 - val_loss: 138.7717\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.7229 - val_loss: 133.6125\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.9114 - val_loss: 131.8254\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.8961 - val_loss: 131.6265\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  14 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 107703.4462 - val_loss: 78997.3828\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73394.6273 - val_loss: 53851.7266\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 50180.8955 - val_loss: 37230.0586\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 34350.9400 - val_loss: 24231.8164\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20982.1568 - val_loss: 10949.7051\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8062.9886 - val_loss: 3030.4150\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2276.1138 - val_loss: 1655.5250\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1555.7211 - val_loss: 1451.9487\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1391.5536 - val_loss: 1237.2371\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1131.6514 - val_loss: 1121.2673\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 993.6545 - val_loss: 1031.3604\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 932.6016 - val_loss: 952.6381\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 859.8712 - val_loss: 886.6367\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 845.5717 - val_loss: 824.1591\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 734.9583 - val_loss: 770.7217\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 728.5331 - val_loss: 723.6622\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 681.7288 - val_loss: 681.2431\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 634.5224 - val_loss: 646.1050\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 611.8313 - val_loss: 612.4282\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 562.1945 - val_loss: 585.2247\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 539.4606 - val_loss: 558.4530\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 519.9500 - val_loss: 535.5029\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 504.9156 - val_loss: 512.6010\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 449.7803 - val_loss: 492.0849\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 434.9621 - val_loss: 472.8495\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 466.1941 - val_loss: 455.1268\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 444.0590 - val_loss: 439.6482\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 384.2700 - val_loss: 425.2931\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 366.2871 - val_loss: 411.7664\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 389.3367 - val_loss: 398.8035\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.6056 - val_loss: 387.1362\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 388.7898 - val_loss: 376.6749\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 372.2761 - val_loss: 366.4812\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 335.9659 - val_loss: 358.8139\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.8767 - val_loss: 349.0617\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 324.8625 - val_loss: 341.2540\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 327.5896 - val_loss: 334.3987\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 288.7652 - val_loss: 328.4060\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 305.1104 - val_loss: 321.6987\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 299.0217 - val_loss: 316.2031\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.6172 - val_loss: 310.8415\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 270.3658 - val_loss: 306.1869\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.7979 - val_loss: 301.4797\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.8615 - val_loss: 297.7863\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 261.5353 - val_loss: 294.0563\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.8335 - val_loss: 290.5198\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 249.4432 - val_loss: 287.1808\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.3232 - val_loss: 284.4648\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280.7042 - val_loss: 281.8998\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.8487 - val_loss: 280.4761\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  15 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 10693.8991 - val_loss: 775.6647\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 479.5836 - val_loss: 422.9038\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 380.9604 - val_loss: 264.4615\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.3254 - val_loss: 276.5059\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.6641 - val_loss: 249.2317\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.9519 - val_loss: 244.1760\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.3430 - val_loss: 239.4870\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 225.6450 - val_loss: 235.6738\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.5459 - val_loss: 230.0519\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.7818 - val_loss: 226.0192\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.8885 - val_loss: 221.7145\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.7948 - val_loss: 214.8893\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.4187 - val_loss: 210.1200\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.4531 - val_loss: 208.9927\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.0211 - val_loss: 201.5425\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.5628 - val_loss: 197.2743\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.7306 - val_loss: 194.2292\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.7909 - val_loss: 191.8673\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.7861 - val_loss: 185.1169\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.5002 - val_loss: 181.8062\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.6969 - val_loss: 178.1620\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.0574 - val_loss: 176.1135\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.0465 - val_loss: 170.4689\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.6647 - val_loss: 172.4157\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.2925 - val_loss: 163.4384\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.8443 - val_loss: 165.6323\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 160.1420 - val_loss: 159.7740\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.7404 - val_loss: 159.6288\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.0063 - val_loss: 156.3209\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.5096 - val_loss: 152.3556\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.6568 - val_loss: 152.8554\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.6133 - val_loss: 146.6437\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.8460 - val_loss: 148.6131\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 151.0734 - val_loss: 144.1613\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.0992 - val_loss: 141.1992\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.6121 - val_loss: 141.7687\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.9404 - val_loss: 137.2847\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.6398 - val_loss: 135.1291\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.5159 - val_loss: 136.3680\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.3106 - val_loss: 134.0210\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146.3546 - val_loss: 130.7789\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.3947 - val_loss: 128.0885\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.1562 - val_loss: 129.5010\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.8846 - val_loss: 133.2461\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141.8482 - val_loss: 123.4763\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.7342 - val_loss: 126.3136\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.3321 - val_loss: 122.6368\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.6208 - val_loss: 121.1054\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.9416 - val_loss: 121.3250\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 139.0880 - val_loss: 116.8974\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  16 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 64583.4642 - val_loss: 18071.6191\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12187.0630 - val_loss: 1579.9390\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1453.2680 - val_loss: 1599.5839\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1431.8749 - val_loss: 1233.9978\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1183.6022 - val_loss: 1145.1293\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1145.1632 - val_loss: 1082.9363\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 952.6408 - val_loss: 1018.4585\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1054.7528 - val_loss: 957.7882\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 933.3785 - val_loss: 908.7717\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 856.8358 - val_loss: 849.9095\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 917.4173 - val_loss: 799.2918\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 801.0395 - val_loss: 752.4203\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 785.8323 - val_loss: 708.5380\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 772.4611 - val_loss: 667.3117\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 709.4097 - val_loss: 629.5288\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 660.1293 - val_loss: 596.3611\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 627.7536 - val_loss: 560.5925\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 578.4481 - val_loss: 530.6203\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 562.0604 - val_loss: 503.7858\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 496.5538 - val_loss: 474.4874\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 497.3400 - val_loss: 449.1663\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 480.0271 - val_loss: 426.8630\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 452.7088 - val_loss: 406.8946\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 481.3281 - val_loss: 388.1381\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 384.8520 - val_loss: 371.6537\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 375.4871 - val_loss: 355.6952\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 368.7744 - val_loss: 340.9508\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 363.9253 - val_loss: 327.4971\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 345.8217 - val_loss: 314.6511\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.6693 - val_loss: 302.9681\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 343.1585 - val_loss: 291.2079\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 332.1994 - val_loss: 280.7639\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.3644 - val_loss: 271.6960\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 274.9494 - val_loss: 262.1339\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 284.0688 - val_loss: 253.2524\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.6011 - val_loss: 245.6214\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.2575 - val_loss: 237.4464\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.5241 - val_loss: 230.1930\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.6352 - val_loss: 224.4027\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.6168 - val_loss: 217.2091\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.6944 - val_loss: 211.4614\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.9988 - val_loss: 206.2363\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.9965 - val_loss: 201.2498\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.4074 - val_loss: 198.3306\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.5643 - val_loss: 192.4386\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.6525 - val_loss: 188.3824\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.2570 - val_loss: 184.3724\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 199.4254 - val_loss: 180.8661\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 197.1082 - val_loss: 177.5068\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.3912 - val_loss: 174.6312\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  17 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 197617.4522 - val_loss: 92343.1953\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67163.1158 - val_loss: 23602.8242\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 15955.9811 - val_loss: 4485.1396\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3280.3595 - val_loss: 2330.8735\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2620.4714 - val_loss: 2285.0452\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2376.3711 - val_loss: 2207.3528\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2450.4733 - val_loss: 2188.8091\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2270.0690 - val_loss: 2118.3594\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2173.5290 - val_loss: 2061.2649\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2098.9755 - val_loss: 1985.3843\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2171.2133 - val_loss: 1910.8190\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1928.7216 - val_loss: 1853.2740\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1974.0260 - val_loss: 1793.2343\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1920.2991 - val_loss: 1730.5327\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1759.3597 - val_loss: 1672.3612\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1778.9371 - val_loss: 1611.1348\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1610.9680 - val_loss: 1545.2559\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1676.9922 - val_loss: 1490.8271\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1464.1149 - val_loss: 1441.8555\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1466.1868 - val_loss: 1384.5962\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1394.9550 - val_loss: 1338.7571\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1412.3795 - val_loss: 1288.2189\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1209.4807 - val_loss: 1238.1010\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1270.0348 - val_loss: 1187.5739\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1197.6940 - val_loss: 1150.4254\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1107.2165 - val_loss: 1111.7784\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1107.8223 - val_loss: 1080.9182\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1045.9998 - val_loss: 1025.8020\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 930.4921 - val_loss: 990.0820\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 923.1306 - val_loss: 964.2350\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 872.9182 - val_loss: 927.1420\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 888.5087 - val_loss: 900.3591\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 891.7380 - val_loss: 860.2084\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 824.1074 - val_loss: 834.6234\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 857.4653 - val_loss: 807.6724\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 773.8876 - val_loss: 775.1719\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 725.1089 - val_loss: 756.5660\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 761.8438 - val_loss: 727.7738\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 656.0759 - val_loss: 708.7350\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 643.7300 - val_loss: 683.0461\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 653.7412 - val_loss: 659.4897\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 635.8910 - val_loss: 640.4077\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 583.3576 - val_loss: 620.5807\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 592.5293 - val_loss: 602.8603\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 558.4138 - val_loss: 587.3141\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 519.6059 - val_loss: 569.4913\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 482.9382 - val_loss: 549.1470\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 483.2867 - val_loss: 537.4332\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 460.0261 - val_loss: 519.6125\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 401.4187 - val_loss: 506.0427\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  18 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 2863.0730 - val_loss: 1893.8975\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1931.5422 - val_loss: 1551.3816\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1708.3997 - val_loss: 1264.5294\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1189.6823 - val_loss: 1026.8013\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1007.5491 - val_loss: 832.1854\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 736.3415 - val_loss: 666.4039\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 594.1313 - val_loss: 535.6701\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 477.2657 - val_loss: 440.5900\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 431.3737 - val_loss: 375.0174\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 333.5565 - val_loss: 328.7749\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 316.8646 - val_loss: 292.6298\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 290.9413 - val_loss: 264.6890\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233.4671 - val_loss: 243.6209\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.9819 - val_loss: 228.4522\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.0274 - val_loss: 215.3405\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205.4053 - val_loss: 198.2922\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.6156 - val_loss: 188.0907\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.1831 - val_loss: 177.8010\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.7892 - val_loss: 169.4482\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.0308 - val_loss: 161.8798\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.9684 - val_loss: 154.7548\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.5838 - val_loss: 155.6610\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 141.5872 - val_loss: 142.8191\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.7487 - val_loss: 138.4070\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.7140 - val_loss: 139.1778\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.5527 - val_loss: 140.7800\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.3591 - val_loss: 127.9102\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.0981 - val_loss: 125.7253\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.3482 - val_loss: 122.9230\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.6734 - val_loss: 122.4458\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.3127 - val_loss: 120.0158\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.8395 - val_loss: 117.9331\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.0840 - val_loss: 118.3279\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.7520 - val_loss: 115.3321\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 116.7643 - val_loss: 114.0592\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.1791 - val_loss: 117.7057\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.9825 - val_loss: 114.6325\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.7874 - val_loss: 115.7319\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.7027 - val_loss: 110.8475\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.4964 - val_loss: 110.6970\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.9360 - val_loss: 109.3810\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.7046 - val_loss: 112.8761\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.9880 - val_loss: 112.9418\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9886 - val_loss: 109.0467\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.4952 - val_loss: 107.8015\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5737 - val_loss: 108.0657\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.3889 - val_loss: 108.4382\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.7644 - val_loss: 107.6478\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.2119 - val_loss: 109.8410\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.6455 - val_loss: 108.2186\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  19 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 4874.8957 - val_loss: 2553.1416\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2509.3173 - val_loss: 1892.8661\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1585.7913 - val_loss: 1411.8414\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1317.8473 - val_loss: 1066.2760\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1119.6828 - val_loss: 792.6041\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 820.3828 - val_loss: 614.4822\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 610.8009 - val_loss: 501.0881\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 550.2302 - val_loss: 430.1661\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 420.3638 - val_loss: 375.5279\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.7148 - val_loss: 336.5820\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 329.8010 - val_loss: 315.6656\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 315.9461 - val_loss: 296.7889\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.4300 - val_loss: 282.0736\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.8492 - val_loss: 270.1046\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.5678 - val_loss: 258.7832\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.0488 - val_loss: 252.9375\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.2630 - val_loss: 237.9027\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.3334 - val_loss: 218.3339\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.6024 - val_loss: 201.0953\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.2299 - val_loss: 188.3566\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.1406 - val_loss: 173.8151\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.6760 - val_loss: 161.3160\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.1024 - val_loss: 152.7124\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.3597 - val_loss: 144.7215\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.2475 - val_loss: 139.2852\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.2685 - val_loss: 132.4217\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.9738 - val_loss: 131.3796\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 133.2406 - val_loss: 123.0108\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.6494 - val_loss: 123.5789\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.5324 - val_loss: 116.5933\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.8139 - val_loss: 114.5690\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.1669 - val_loss: 111.0320\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.9769 - val_loss: 110.0115\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.0520 - val_loss: 107.5528\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8058 - val_loss: 106.3662\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.0158 - val_loss: 103.3437\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.9811 - val_loss: 102.2033\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.6347 - val_loss: 103.7718\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.9725 - val_loss: 103.6818\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.6632 - val_loss: 99.2988\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.3934 - val_loss: 98.9732\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.3217 - val_loss: 96.4566\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.1148 - val_loss: 95.4638\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.0631 - val_loss: 95.9282\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.9314 - val_loss: 92.9836\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.4320 - val_loss: 93.0216\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 112.7826 - val_loss: 93.6478\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.1222 - val_loss: 94.9123\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.0617 - val_loss: 96.6846\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.8255 - val_loss: 95.5418\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  20 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 71463.1641 - val_loss: 51918.3672\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 43467.6409 - val_loss: 33949.2852\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 28551.2459 - val_loss: 23719.5020\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 20131.0929 - val_loss: 17331.1152\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 14963.5213 - val_loss: 13050.2988\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10810.4747 - val_loss: 10016.4951\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8136.5573 - val_loss: 7610.8042\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6153.6070 - val_loss: 5723.4526\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4311.9706 - val_loss: 4225.2803\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3011.0551 - val_loss: 3083.0547\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2070.1400 - val_loss: 2253.5889\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1625.3487 - val_loss: 1743.6714\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1453.4066 - val_loss: 1441.5439\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1116.6975 - val_loss: 1264.3074\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1048.4540 - val_loss: 1146.6248\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 886.9725 - val_loss: 1049.8092\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 867.3214 - val_loss: 969.2657\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 754.7765 - val_loss: 898.6144\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 700.4527 - val_loss: 838.6721\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 664.5068 - val_loss: 789.3051\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 709.3756 - val_loss: 731.7888\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 616.8741 - val_loss: 683.5750\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 528.1797 - val_loss: 640.1580\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 494.8597 - val_loss: 608.5742\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 491.4315 - val_loss: 575.2219\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 430.1235 - val_loss: 550.5696\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 445.7713 - val_loss: 526.1890\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 446.4068 - val_loss: 506.9619\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 369.9227 - val_loss: 487.5400\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 355.0685 - val_loss: 474.3870\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 342.4797 - val_loss: 458.8626\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 346.9385 - val_loss: 446.2548\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 340.4298 - val_loss: 435.8297\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 317.9735 - val_loss: 426.1845\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 306.1657 - val_loss: 415.0221\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 354.0709 - val_loss: 407.0591\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 333.0914 - val_loss: 398.4982\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 323.5531 - val_loss: 390.8955\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 285.7539 - val_loss: 385.0972\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 316.4217 - val_loss: 376.2523\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 331.4358 - val_loss: 369.5359\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 282.9384 - val_loss: 363.2667\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.3430 - val_loss: 356.7861\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.9426 - val_loss: 351.2664\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 281.8477 - val_loss: 346.8385\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.6303 - val_loss: 340.3778\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.7715 - val_loss: 336.4350\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.0518 - val_loss: 330.2177\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.2681 - val_loss: 326.3183\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.2208 - val_loss: 321.9258\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  21 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 129352.4793 - val_loss: 90300.8125\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81119.6517 - val_loss: 59033.4922\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 53979.8311 - val_loss: 39731.6875\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 36022.3169 - val_loss: 24395.5996\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 19902.1985 - val_loss: 7809.8525\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 5400.1420 - val_loss: 1738.2269\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1360.7811 - val_loss: 1467.5319\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1439.2501 - val_loss: 1059.8038\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 925.9498 - val_loss: 886.0450\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 791.1683 - val_loss: 757.7527\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 690.2150 - val_loss: 658.1470\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 518.0248 - val_loss: 579.2549\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 473.5564 - val_loss: 512.6964\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 453.5884 - val_loss: 457.2121\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 366.0439 - val_loss: 413.9482\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 368.9021 - val_loss: 379.0736\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 318.1883 - val_loss: 348.7037\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 287.7348 - val_loss: 324.1100\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.8976 - val_loss: 303.0677\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.2155 - val_loss: 284.4937\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.2506 - val_loss: 267.7082\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.1543 - val_loss: 254.2648\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.6274 - val_loss: 243.1554\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.6229 - val_loss: 234.4725\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 170.9023 - val_loss: 224.4653\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.2950 - val_loss: 217.3873\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.8273 - val_loss: 211.0557\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.0454 - val_loss: 204.8411\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.1522 - val_loss: 200.0670\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.8128 - val_loss: 195.0504\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.4286 - val_loss: 191.1374\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.7818 - val_loss: 188.3515\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.5840 - val_loss: 184.1021\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.4453 - val_loss: 180.8691\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.7617 - val_loss: 178.7056\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.1843 - val_loss: 175.1227\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.4675 - val_loss: 173.5274\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.3007 - val_loss: 170.9324\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 130.9037 - val_loss: 168.6669\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.2701 - val_loss: 167.4358\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.7853 - val_loss: 164.2858\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.4173 - val_loss: 162.9436\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6933 - val_loss: 161.8708\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.5693 - val_loss: 159.9792\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 138.2848 - val_loss: 157.9864\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.9570 - val_loss: 156.1053\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.7826 - val_loss: 154.9350\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.9586 - val_loss: 154.3506\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.3647 - val_loss: 153.0668\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.5199 - val_loss: 151.3306\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  22 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 21516.9507 - val_loss: 6696.0278\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4649.3964 - val_loss: 832.8293\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 555.5864 - val_loss: 558.6399\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 456.4645 - val_loss: 537.9132\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 442.4637 - val_loss: 495.2575\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 418.2164 - val_loss: 489.5145\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 405.0481 - val_loss: 475.2194\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 397.9063 - val_loss: 464.9131\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 401.6541 - val_loss: 453.5996\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 366.2511 - val_loss: 443.4857\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 365.9410 - val_loss: 433.1187\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.4748 - val_loss: 422.3183\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 344.3638 - val_loss: 412.8133\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 358.1054 - val_loss: 402.0362\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 347.8034 - val_loss: 392.0301\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 319.3089 - val_loss: 382.9876\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 319.6181 - val_loss: 373.4247\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.8744 - val_loss: 364.6094\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 297.2426 - val_loss: 355.2549\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 313.1668 - val_loss: 346.6764\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 277.1405 - val_loss: 338.5363\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 301.7154 - val_loss: 330.1705\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 283.6204 - val_loss: 322.5124\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.4451 - val_loss: 314.9159\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.5177 - val_loss: 307.9261\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 275.7727 - val_loss: 300.7912\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 249.2641 - val_loss: 293.8615\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.1146 - val_loss: 287.4431\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.7869 - val_loss: 280.8447\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.8564 - val_loss: 275.1410\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.2352 - val_loss: 268.6601\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 205.6242 - val_loss: 263.1476\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 206.9981 - val_loss: 257.7672\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.3935 - val_loss: 252.6082\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.2959 - val_loss: 247.3582\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.0849 - val_loss: 241.7609\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.1593 - val_loss: 237.1436\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.0493 - val_loss: 232.4077\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 193.7869 - val_loss: 227.6964\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.8932 - val_loss: 223.5255\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.8046 - val_loss: 218.8291\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 191.5730 - val_loss: 215.2392\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.5204 - val_loss: 210.8108\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.2057 - val_loss: 207.9004\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 184.7507 - val_loss: 203.0658\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.4111 - val_loss: 199.3618\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.0374 - val_loss: 196.4405\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.4110 - val_loss: 193.1431\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.0198 - val_loss: 189.4507\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.3835 - val_loss: 186.4772\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  23 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 32068.9521 - val_loss: 14234.7539\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11449.8226 - val_loss: 4386.8525\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3491.2009 - val_loss: 1396.2925\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1182.3865 - val_loss: 1081.8713\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 940.7878 - val_loss: 1046.2798\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 850.4901 - val_loss: 923.0862\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 748.1096 - val_loss: 837.7397\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 766.4168 - val_loss: 771.3132\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 772.4602 - val_loss: 716.8839\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 737.3428 - val_loss: 667.2112\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 691.5964 - val_loss: 623.0452\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 575.6691 - val_loss: 588.2873\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 625.6143 - val_loss: 553.2411\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 576.8715 - val_loss: 528.7971\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 576.2713 - val_loss: 508.3396\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 547.5167 - val_loss: 481.8911\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 495.9879 - val_loss: 461.8562\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 446.9854 - val_loss: 440.5660\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 430.9932 - val_loss: 422.5010\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 439.6249 - val_loss: 398.2939\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.7240 - val_loss: 386.1204\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 385.6836 - val_loss: 366.4686\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 373.2228 - val_loss: 348.4962\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 368.2729 - val_loss: 338.3416\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 335.2167 - val_loss: 324.3992\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 331.4364 - val_loss: 305.2675\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 324.3377 - val_loss: 294.4109\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 337.2441 - val_loss: 286.3973\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.4562 - val_loss: 270.3833\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.5291 - val_loss: 265.4457\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 284.1487 - val_loss: 252.4055\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.1407 - val_loss: 245.0107\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 244.2432 - val_loss: 232.3864\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.1835 - val_loss: 226.3878\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.3229 - val_loss: 217.6636\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.8812 - val_loss: 212.1031\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.2170 - val_loss: 205.8147\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.1868 - val_loss: 196.3284\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.5622 - val_loss: 193.9570\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.0012 - val_loss: 187.2316\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.6006 - val_loss: 180.0701\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.9219 - val_loss: 176.5608\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.7941 - val_loss: 170.6289\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.3965 - val_loss: 167.7188\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.4020 - val_loss: 161.7797\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.0129 - val_loss: 158.4832\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.0850 - val_loss: 153.1353\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.2278 - val_loss: 148.6537\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.7125 - val_loss: 139.9894\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.5060 - val_loss: 134.8364\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  24 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 87085.8828 - val_loss: 40179.3359\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 33136.2345 - val_loss: 13909.0176\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11508.7499 - val_loss: 4621.7949\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3658.2570 - val_loss: 1858.4941\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1514.2931 - val_loss: 1143.9523\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 974.8329 - val_loss: 957.9000\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 802.2486 - val_loss: 864.9844\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 755.5611 - val_loss: 800.8278\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 713.7977 - val_loss: 749.7977\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 640.2347 - val_loss: 705.6702\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 633.0922 - val_loss: 661.7383\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 541.3356 - val_loss: 610.7183\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 578.1462 - val_loss: 552.4769\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 590.8905 - val_loss: 499.4478\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 495.9860 - val_loss: 460.2359\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 431.2802 - val_loss: 428.7724\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 468.7749 - val_loss: 405.9261\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 388.0742 - val_loss: 380.5025\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 378.7214 - val_loss: 359.2429\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 402.3643 - val_loss: 341.0241\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 353.5568 - val_loss: 325.1110\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 320.4158 - val_loss: 309.6463\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 354.5942 - val_loss: 296.2794\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 311.5958 - val_loss: 286.7747\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 338.5001 - val_loss: 276.2790\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 291.3523 - val_loss: 268.5146\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.5802 - val_loss: 259.2240\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 270.4261 - val_loss: 252.4480\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 283.5868 - val_loss: 246.4890\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.1563 - val_loss: 241.1511\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.8653 - val_loss: 235.8295\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.7045 - val_loss: 231.5001\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.2734 - val_loss: 226.8056\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.6425 - val_loss: 223.0975\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.9270 - val_loss: 219.3866\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 246.3271 - val_loss: 215.9260\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.2741 - val_loss: 212.6057\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.1228 - val_loss: 209.5097\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 237.5448 - val_loss: 206.5192\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.5473 - val_loss: 202.4427\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.2428 - val_loss: 199.7162\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.7957 - val_loss: 196.2720\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.1572 - val_loss: 193.4076\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 220.6268 - val_loss: 191.0390\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.4004 - val_loss: 188.5904\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.0433 - val_loss: 186.4983\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.5425 - val_loss: 183.8807\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.1846 - val_loss: 182.3531\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 209.6438 - val_loss: 179.8576\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 194.7376 - val_loss: 178.0130\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  25 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 50822.2213 - val_loss: 21934.8066\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 17172.4086 - val_loss: 6843.4800\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4980.6485 - val_loss: 1908.4305\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1575.3919 - val_loss: 965.4754\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 918.8226 - val_loss: 768.6678\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 727.0082 - val_loss: 656.4768\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 599.1822 - val_loss: 570.3007\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 572.0850 - val_loss: 489.6656\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 434.3002 - val_loss: 418.4395\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 407.8381 - val_loss: 362.8279\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 401.2224 - val_loss: 316.9383\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 343.9269 - val_loss: 286.6371\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 313.5233 - val_loss: 257.2649\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 305.1074 - val_loss: 236.5367\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.2797 - val_loss: 220.2659\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.2297 - val_loss: 208.9476\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.4892 - val_loss: 196.4498\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.6342 - val_loss: 187.6163\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.2244 - val_loss: 181.6520\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.5373 - val_loss: 177.1585\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 233.0440 - val_loss: 172.7904\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 209.3651 - val_loss: 169.8261\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.4295 - val_loss: 167.3705\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 194.7105 - val_loss: 165.0717\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.4058 - val_loss: 164.0152\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.5392 - val_loss: 161.0534\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 206.9911 - val_loss: 160.0512\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.1606 - val_loss: 157.8727\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.8959 - val_loss: 156.2229\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.6665 - val_loss: 154.5629\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.5021 - val_loss: 153.7840\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.1869 - val_loss: 152.1386\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.6824 - val_loss: 150.8738\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.6016 - val_loss: 150.1632\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.0691 - val_loss: 149.2333\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.6836 - val_loss: 148.0805\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.8579 - val_loss: 147.0351\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.9644 - val_loss: 146.4047\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.0039 - val_loss: 145.3676\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.3560 - val_loss: 144.4122\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.7686 - val_loss: 144.0997\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 168.2966 - val_loss: 143.0054\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.5262 - val_loss: 142.2189\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.9383 - val_loss: 141.2643\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 174.8241 - val_loss: 140.7957\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.6760 - val_loss: 140.1248\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 157.4520 - val_loss: 139.7178\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.3799 - val_loss: 140.5037\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 173.3124 - val_loss: 137.9917\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.4964 - val_loss: 137.3969\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  26 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 58079.9212 - val_loss: 18379.4453\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 11647.4046 - val_loss: 2355.4780\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 1633.0950 - val_loss: 1249.9137\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1348.2276 - val_loss: 1228.7892\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1321.5976 - val_loss: 1146.8704\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1174.4427 - val_loss: 1130.4929\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1168.9524 - val_loss: 1064.7788\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1144.9873 - val_loss: 1012.6778\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1031.9206 - val_loss: 951.8525\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1017.6205 - val_loss: 881.4160\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 899.5933 - val_loss: 803.6353\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 865.4848 - val_loss: 737.3979\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 720.3761 - val_loss: 686.3837\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 683.0633 - val_loss: 629.1490\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 637.5301 - val_loss: 584.6002\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 566.0491 - val_loss: 542.5139\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 496.7386 - val_loss: 504.1255\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 495.7564 - val_loss: 474.8756\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 502.3873 - val_loss: 437.3907\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 415.3639 - val_loss: 408.0082\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 401.6439 - val_loss: 385.6774\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 391.5876 - val_loss: 363.5458\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 345.9276 - val_loss: 343.2353\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 350.1434 - val_loss: 323.0528\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 341.0482 - val_loss: 308.4581\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.3408 - val_loss: 292.1476\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.0380 - val_loss: 278.1726\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 278.6067 - val_loss: 265.3508\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 261.3969 - val_loss: 258.7582\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.3421 - val_loss: 242.2881\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.8719 - val_loss: 238.1877\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.0354 - val_loss: 227.4539\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.1311 - val_loss: 217.6384\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.5143 - val_loss: 210.1634\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.6856 - val_loss: 202.3023\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.1889 - val_loss: 197.1650\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.1405 - val_loss: 190.8402\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.2393 - val_loss: 185.8209\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.8319 - val_loss: 181.8648\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.3709 - val_loss: 176.3454\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.3211 - val_loss: 173.0094\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.2197 - val_loss: 169.2234\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.6828 - val_loss: 166.1889\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.3282 - val_loss: 161.2122\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.0673 - val_loss: 159.1926\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.7295 - val_loss: 154.6725\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 168.2024 - val_loss: 154.3291\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.4056 - val_loss: 152.9548\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.0129 - val_loss: 147.6845\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.1392 - val_loss: 146.9044\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  27 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 21251.8755 - val_loss: 12754.5176\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10527.7003 - val_loss: 5364.5923\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4119.3180 - val_loss: 1315.6561\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1149.0155 - val_loss: 737.5574\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 753.7377 - val_loss: 692.3706\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 644.8088 - val_loss: 531.6541\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 509.0784 - val_loss: 491.0573\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 532.1215 - val_loss: 466.6367\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 476.7558 - val_loss: 439.6388\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 475.4061 - val_loss: 417.7750\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 401.3777 - val_loss: 401.3404\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 388.8765 - val_loss: 386.7516\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 360.6536 - val_loss: 375.4016\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 409.8823 - val_loss: 364.2995\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 359.6908 - val_loss: 353.1989\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 334.6732 - val_loss: 348.7177\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 356.9667 - val_loss: 338.4775\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.2828 - val_loss: 336.3024\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 322.5441 - val_loss: 326.3612\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 301.6605 - val_loss: 321.9501\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 315.4242 - val_loss: 316.6943\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339.1805 - val_loss: 311.5432\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 323.5390 - val_loss: 307.4660\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 317.1271 - val_loss: 306.9391\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 316.5844 - val_loss: 298.1524\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 312.8725 - val_loss: 296.6957\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 330.1111 - val_loss: 291.9456\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 283.0700 - val_loss: 289.9139\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.4641 - val_loss: 282.1142\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.9373 - val_loss: 280.1507\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.0326 - val_loss: 272.8629\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.5472 - val_loss: 267.8291\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 273.3466 - val_loss: 253.8006\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.3072 - val_loss: 243.5482\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.0358 - val_loss: 210.4756\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 230.0508 - val_loss: 194.3799\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 205.7011 - val_loss: 182.7262\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 215.8575 - val_loss: 166.7312\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.2846 - val_loss: 157.6024\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.5871 - val_loss: 149.5080\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.5916 - val_loss: 144.3279\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.2503 - val_loss: 138.8760\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.5749 - val_loss: 135.8055\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.6303 - val_loss: 135.6934\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.1844 - val_loss: 130.8412\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 159.2502 - val_loss: 127.7298\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.5899 - val_loss: 126.6594\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.5124 - val_loss: 123.8873\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.3242 - val_loss: 123.6402\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.4582 - val_loss: 121.5698\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  28 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 185548.8097 - val_loss: 125105.1641\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111966.0988 - val_loss: 75640.6641\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 67888.1427 - val_loss: 45079.2773\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 39176.5751 - val_loss: 24876.0117\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 20476.1143 - val_loss: 10934.8379\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8693.6680 - val_loss: 3429.3721\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2393.9765 - val_loss: 671.8649\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 756.6561 - val_loss: 630.6005\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 702.3000 - val_loss: 551.3162\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 589.2631 - val_loss: 523.0337\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 597.0534 - val_loss: 490.5312\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 497.0686 - val_loss: 459.9391\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 499.9768 - val_loss: 433.6763\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 430.7092 - val_loss: 409.6562\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 418.9823 - val_loss: 384.5782\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 353.8448 - val_loss: 362.0777\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 368.8800 - val_loss: 341.7970\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 341.4210 - val_loss: 325.7911\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 312.4657 - val_loss: 307.8518\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 286.4369 - val_loss: 290.7568\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.7958 - val_loss: 274.2540\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.0409 - val_loss: 261.0613\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.5241 - val_loss: 251.2425\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.8649 - val_loss: 241.2357\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.1927 - val_loss: 233.4371\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 237.7353 - val_loss: 225.9772\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.7229 - val_loss: 221.4053\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.5598 - val_loss: 216.7113\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.6207 - val_loss: 211.5193\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.4302 - val_loss: 209.4483\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.2950 - val_loss: 205.1729\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 202.6622 - val_loss: 204.4688\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.6194 - val_loss: 198.9630\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.2215 - val_loss: 199.4887\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.7188 - val_loss: 193.5390\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.4577 - val_loss: 192.0971\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.7644 - val_loss: 190.9196\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.0594 - val_loss: 187.2473\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.3673 - val_loss: 189.5338\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.1844 - val_loss: 183.9225\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.0975 - val_loss: 183.2058\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.1607 - val_loss: 183.3110\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.1460 - val_loss: 179.1941\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.6454 - val_loss: 179.3187\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.4930 - val_loss: 176.4062\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.5489 - val_loss: 176.6673\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.3637 - val_loss: 173.4057\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.0178 - val_loss: 174.7007\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0818 - val_loss: 172.0746\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.9688 - val_loss: 171.2787\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  29 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 2841.6467 - val_loss: 837.6302\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 832.3698 - val_loss: 826.8974\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 804.1485 - val_loss: 698.7609\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 645.6290 - val_loss: 646.9951\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 681.5250 - val_loss: 601.9248\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 594.9253 - val_loss: 556.7229\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 586.7034 - val_loss: 515.3288\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 522.7163 - val_loss: 480.5863\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 480.9660 - val_loss: 444.0002\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 423.2295 - val_loss: 413.3812\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 387.4429 - val_loss: 385.2883\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 364.5564 - val_loss: 359.2690\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361.3185 - val_loss: 328.0714\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 353.5959 - val_loss: 291.9031\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.8649 - val_loss: 261.7911\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 279.3654 - val_loss: 237.5456\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.2737 - val_loss: 216.8251\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.8009 - val_loss: 199.9275\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 209.7192 - val_loss: 186.9150\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.3435 - val_loss: 173.5904\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.0568 - val_loss: 159.2946\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 177.9416 - val_loss: 150.5759\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.8878 - val_loss: 141.9295\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.2431 - val_loss: 134.7711\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 149.6145 - val_loss: 128.6004\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 142.0160 - val_loss: 123.6656\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.2736 - val_loss: 120.3567\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.7900 - val_loss: 116.9731\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9786 - val_loss: 113.9326\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.8145 - val_loss: 116.4145\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.0361 - val_loss: 109.9999\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.2078 - val_loss: 109.5370\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.8157 - val_loss: 108.5181\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.4639 - val_loss: 110.3159\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.7004 - val_loss: 107.7283\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.8339 - val_loss: 112.2124\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.7357 - val_loss: 103.1531\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.7224 - val_loss: 104.0471\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.6886 - val_loss: 113.6521\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.3546 - val_loss: 99.9450\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.8576 - val_loss: 100.6945\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 111.9212 - val_loss: 103.9052\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.2604 - val_loss: 98.1921\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.9586 - val_loss: 100.1772\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.5481 - val_loss: 100.7170\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.0703 - val_loss: 99.8148\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.0396 - val_loss: 98.7200\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 111.5129 - val_loss: 97.1324\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.8775 - val_loss: 97.8978\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.5089 - val_loss: 99.5345\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  30 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 136404.3074 - val_loss: 71268.4297\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 66415.4619 - val_loss: 28306.4062\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 26096.7649 - val_loss: 9098.3262\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9882.6953 - val_loss: 4635.3633\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 5250.1508 - val_loss: 4493.3140\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4516.0690 - val_loss: 3968.6455\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3935.9038 - val_loss: 3461.5579\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3829.3153 - val_loss: 3057.1282\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3490.0688 - val_loss: 2730.9583\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3068.6761 - val_loss: 2494.7920\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2617.9160 - val_loss: 2256.9797\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2612.0402 - val_loss: 2015.0963\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2010.8805 - val_loss: 1851.3489\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2064.1745 - val_loss: 1690.4645\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 1729.8765 - val_loss: 1525.5510\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1789.1433 - val_loss: 1414.6387\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1454.3141 - val_loss: 1298.4027\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1362.5789 - val_loss: 1187.4735\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1231.8697 - val_loss: 1110.8779\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1143.5307 - val_loss: 1043.7869\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1140.2814 - val_loss: 945.3891\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1069.6507 - val_loss: 904.0255\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1059.7287 - val_loss: 861.0885\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1013.2208 - val_loss: 791.8591\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 870.5544 - val_loss: 744.6690\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 846.9765 - val_loss: 730.9626\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 855.8400 - val_loss: 671.3128\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 696.7964 - val_loss: 664.9412\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 708.1079 - val_loss: 622.0804\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 640.2053 - val_loss: 610.5532\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 699.8810 - val_loss: 592.7672\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 655.9266 - val_loss: 558.6411\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 574.9642 - val_loss: 537.1653\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 596.7777 - val_loss: 546.6475\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 532.7095 - val_loss: 518.8779\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 585.1755 - val_loss: 504.1845\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 526.7502 - val_loss: 492.5097\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 512.1950 - val_loss: 480.6631\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 515.1167 - val_loss: 471.4691\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 478.5412 - val_loss: 471.2906\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 472.3463 - val_loss: 452.5311\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 503.8568 - val_loss: 453.1855\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 501.0258 - val_loss: 442.0219\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 443.7120 - val_loss: 434.8914\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 455.0075 - val_loss: 428.8311\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 483.0174 - val_loss: 424.4979\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 440.3641 - val_loss: 419.8758\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 476.1732 - val_loss: 420.8560\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 470.7481 - val_loss: 409.5831\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 433.8063 - val_loss: 410.7786\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  31 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 18ms/step - loss: 12577.9378 - val_loss: 3042.7522\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2541.9461 - val_loss: 1778.2988\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1788.4777 - val_loss: 1222.7742\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1186.0189 - val_loss: 856.4152\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 769.3162 - val_loss: 683.3926\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 596.9519 - val_loss: 576.2819\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 524.4997 - val_loss: 507.4069\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 481.0476 - val_loss: 468.9337\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 381.6213 - val_loss: 444.6598\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 355.7528 - val_loss: 425.0017\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 301.9906 - val_loss: 410.7312\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 299.4429 - val_loss: 400.7907\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 316.7825 - val_loss: 393.5095\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 266.3317 - val_loss: 383.0529\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.4436 - val_loss: 375.1047\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 263.1519 - val_loss: 362.5011\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.8264 - val_loss: 358.7693\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 263.9235 - val_loss: 351.8259\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.0717 - val_loss: 345.2656\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.0916 - val_loss: 336.3181\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 247.9843 - val_loss: 329.2409\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.8948 - val_loss: 316.3000\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 237.7797 - val_loss: 313.7528\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.8804 - val_loss: 298.8207\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.9278 - val_loss: 291.9767\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 202.0928 - val_loss: 281.8313\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.1773 - val_loss: 279.5086\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.0958 - val_loss: 270.0981\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.3641 - val_loss: 265.0321\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.1957 - val_loss: 256.7235\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.2112 - val_loss: 259.4997\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.5508 - val_loss: 246.9005\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.6763 - val_loss: 242.0996\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.2498 - val_loss: 241.6454\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.6650 - val_loss: 234.8060\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.3827 - val_loss: 232.7154\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.8174 - val_loss: 227.5161\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.6047 - val_loss: 221.9012\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.2419 - val_loss: 216.9974\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.9301 - val_loss: 212.9537\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.7680 - val_loss: 212.5225\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.6230 - val_loss: 208.0074\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.2479 - val_loss: 206.5484\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.6520 - val_loss: 200.8022\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.6313 - val_loss: 198.8550\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.9256 - val_loss: 197.0449\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 143.7704 - val_loss: 191.0170\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.6033 - val_loss: 192.6717\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 157.2266 - val_loss: 188.4074\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.8240 - val_loss: 189.9171\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  32 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 25ms/step - loss: 4364.3933 - val_loss: 1794.4453\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1542.1313 - val_loss: 588.4136\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 486.5897 - val_loss: 357.9955\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 293.5134 - val_loss: 349.0540\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 296.5179 - val_loss: 350.6436\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.3182 - val_loss: 347.1555\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 274.0007 - val_loss: 343.8520\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 294.0661 - val_loss: 342.1368\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 320.1363 - val_loss: 339.5498\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 258.2516 - val_loss: 341.2918\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 306.9876 - val_loss: 339.3432\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.9225 - val_loss: 338.7273\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 281.4752 - val_loss: 337.4984\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.6291 - val_loss: 334.9568\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 257.7421 - val_loss: 335.3203\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 280.5371 - val_loss: 332.9888\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 293.4210 - val_loss: 333.4527\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 276.9090 - val_loss: 330.8828\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 286.9702 - val_loss: 330.0034\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 289.4466 - val_loss: 328.3259\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 273.8314 - val_loss: 327.8167\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 269.2081 - val_loss: 326.4155\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 280.5178 - val_loss: 324.5792\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 266.9566 - val_loss: 323.3302\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 274.9231 - val_loss: 321.9680\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 271.1156 - val_loss: 319.2115\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.8337 - val_loss: 319.7635\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.9965 - val_loss: 314.1993\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.3270 - val_loss: 314.5178\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.0092 - val_loss: 310.6867\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 278.7168 - val_loss: 307.9708\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 241.1668 - val_loss: 303.5885\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 256.7481 - val_loss: 294.7597\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.9824 - val_loss: 291.2865\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 269.9780 - val_loss: 280.3047\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.3756 - val_loss: 271.9543\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 237.4362 - val_loss: 268.2007\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.7663 - val_loss: 257.8937\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 232.8826 - val_loss: 249.9733\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.1908 - val_loss: 242.2234\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.2885 - val_loss: 232.3038\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.7229 - val_loss: 222.2930\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.4776 - val_loss: 215.6897\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.2602 - val_loss: 202.4612\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.1097 - val_loss: 194.0652\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 153.1570 - val_loss: 178.3002\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.1705 - val_loss: 164.3426\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 160.2010 - val_loss: 150.1384\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 133.2762 - val_loss: 143.5957\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 133.3680 - val_loss: 132.4747\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  33 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 27ms/step - loss: 9184.7056 - val_loss: 1375.3984\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 890.2474 - val_loss: 1067.9290\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 854.6857 - val_loss: 704.3718\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 565.5772 - val_loss: 633.4598\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 482.4580 - val_loss: 544.9531\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 404.3213 - val_loss: 465.2640\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 372.2248 - val_loss: 408.5695\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 289.8957 - val_loss: 359.3156\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 298.9594 - val_loss: 319.8066\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 301.3104 - val_loss: 289.7318\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 252.8554 - val_loss: 269.9145\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 220.6877 - val_loss: 247.5688\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 218.9232 - val_loss: 231.6407\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 189.1827 - val_loss: 220.5839\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 192.4616 - val_loss: 210.6987\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 175.2717 - val_loss: 203.3748\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 169.1088 - val_loss: 195.4328\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 168.3087 - val_loss: 189.6494\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 156.2797 - val_loss: 185.7332\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 158.1286 - val_loss: 185.5618\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 145.9791 - val_loss: 178.6051\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 142.1583 - val_loss: 174.2736\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 139.5395 - val_loss: 171.7710\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.3075 - val_loss: 167.4389\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.1014 - val_loss: 163.3726\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.5323 - val_loss: 157.5860\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 140.9495 - val_loss: 153.9295\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.6471 - val_loss: 150.6479\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.8813 - val_loss: 149.1830\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.6117 - val_loss: 144.2550\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.8089 - val_loss: 141.7164\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.6833 - val_loss: 139.0736\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 116.7138 - val_loss: 135.9117\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.9498 - val_loss: 134.1985\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.5878 - val_loss: 131.2953\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.5592 - val_loss: 133.0990\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.8552 - val_loss: 127.2824\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.4093 - val_loss: 125.6035\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.7617 - val_loss: 124.2513\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.4865 - val_loss: 121.7497\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.6939 - val_loss: 121.5532\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.6329 - val_loss: 117.8896\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.3431 - val_loss: 115.7738\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.8527 - val_loss: 115.1380\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.6847 - val_loss: 112.2838\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.4208 - val_loss: 110.1758\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.3240 - val_loss: 118.8615\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 100.4077 - val_loss: 109.4503\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.6385 - val_loss: 108.5588\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.8462 - val_loss: 110.5759\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  34 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 825.7916 - val_loss: 629.4184\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 537.6567 - val_loss: 446.3996\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 417.8819 - val_loss: 361.7346\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 352.2860 - val_loss: 326.8044\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 316.2071 - val_loss: 288.3924\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 301.9189 - val_loss: 277.5818\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 281.9502 - val_loss: 270.5907\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 256.4015 - val_loss: 259.1470\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.3492 - val_loss: 244.3380\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 241.1512 - val_loss: 232.9805\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.3527 - val_loss: 230.2084\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.4088 - val_loss: 218.4383\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.0595 - val_loss: 216.0351\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 209.1956 - val_loss: 207.6419\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.8655 - val_loss: 205.2216\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 194.6408 - val_loss: 198.2545\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 205.8889 - val_loss: 217.4234\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.8547 - val_loss: 189.3420\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.4333 - val_loss: 186.9905\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.3379 - val_loss: 179.3035\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.7484 - val_loss: 176.0186\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.0497 - val_loss: 185.1349\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.8571 - val_loss: 177.2760\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.0483 - val_loss: 168.8387\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.3555 - val_loss: 166.5998\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.4989 - val_loss: 160.7011\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.1265 - val_loss: 159.3372\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.6630 - val_loss: 163.9341\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.9338 - val_loss: 154.7001\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.8969 - val_loss: 154.4759\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.0215 - val_loss: 154.7829\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.2529 - val_loss: 150.6967\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 144.3158 - val_loss: 149.1704\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.9067 - val_loss: 155.8536\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.4454 - val_loss: 149.2019\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.2520 - val_loss: 152.0079\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.2390 - val_loss: 146.2745\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.0695 - val_loss: 144.5881\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.0443 - val_loss: 144.2522\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.5598 - val_loss: 146.7570\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.6121 - val_loss: 145.5440\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.9795 - val_loss: 145.3790\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 138.7571 - val_loss: 150.2828\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.5416 - val_loss: 144.5152\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.9829 - val_loss: 142.4539\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.8858 - val_loss: 144.5712\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.6245 - val_loss: 147.0110\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 128.8069 - val_loss: 147.4373\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.0501 - val_loss: 141.8802\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 120.6132 - val_loss: 140.9896\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  35 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 13228.2061 - val_loss: 1425.1140\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1051.3424 - val_loss: 969.2540\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 750.9955 - val_loss: 618.3723\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 554.9856 - val_loss: 526.2016\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 452.4396 - val_loss: 500.9867\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 484.9448 - val_loss: 479.0587\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 479.3857 - val_loss: 457.2974\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 444.7195 - val_loss: 434.1922\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 376.4357 - val_loss: 414.9064\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 357.9582 - val_loss: 391.5510\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 370.7931 - val_loss: 365.0925\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 324.4948 - val_loss: 343.2741\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 330.5074 - val_loss: 312.9851\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 297.4755 - val_loss: 288.0523\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 291.5419 - val_loss: 259.2946\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 249.5275 - val_loss: 237.9701\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.4891 - val_loss: 214.3186\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.8445 - val_loss: 198.0032\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.5973 - val_loss: 184.4044\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.0952 - val_loss: 172.1122\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.9862 - val_loss: 160.5425\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.1445 - val_loss: 151.9040\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.2635 - val_loss: 145.2375\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.2493 - val_loss: 139.2702\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.0784 - val_loss: 145.0762\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 150.5187 - val_loss: 131.0528\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.2914 - val_loss: 138.4765\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.1458 - val_loss: 125.1743\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.8164 - val_loss: 125.5649\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.2769 - val_loss: 127.3802\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.1180 - val_loss: 122.4481\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.1874 - val_loss: 120.2921\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.5606 - val_loss: 119.1296\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.7176 - val_loss: 119.5448\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.4174 - val_loss: 120.4350\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.1249 - val_loss: 117.7156\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.8734 - val_loss: 118.1295\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.6128 - val_loss: 117.5361\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.9286 - val_loss: 118.9025\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.8191 - val_loss: 118.7042\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.8445 - val_loss: 121.9451\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 129.7515 - val_loss: 117.3131\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.8626 - val_loss: 119.9661\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.3109 - val_loss: 115.4710\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.4076 - val_loss: 117.3561\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 120.4143 - val_loss: 115.1190\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.3706 - val_loss: 132.5396\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.9471 - val_loss: 114.3252\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 94.4364 - val_loss: 114.7359\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.4748 - val_loss: 117.4799\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  36 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 2198.3484 - val_loss: 784.1227\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 841.0453 - val_loss: 675.0135\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 671.0332 - val_loss: 489.9522\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 476.0953 - val_loss: 440.2536\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 384.9938 - val_loss: 366.4215\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 314.9593 - val_loss: 317.6582\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.7971 - val_loss: 266.6810\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 223.2131 - val_loss: 255.0809\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.7326 - val_loss: 208.0208\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.8864 - val_loss: 179.1882\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.8444 - val_loss: 150.8129\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.0620 - val_loss: 140.0714\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.9116 - val_loss: 134.3410\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.9950 - val_loss: 121.8388\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.0393 - val_loss: 116.6549\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.6966 - val_loss: 120.3157\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.8140 - val_loss: 111.0933\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.1315 - val_loss: 118.7620\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.8012 - val_loss: 110.8249\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.3863 - val_loss: 107.0789\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.4886 - val_loss: 101.3689\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.3956 - val_loss: 101.0709\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.9824 - val_loss: 99.7252\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.7563 - val_loss: 101.2435\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.0498 - val_loss: 97.2182\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 94.1939 - val_loss: 102.7114\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.3969 - val_loss: 96.9457\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.1818 - val_loss: 96.3893\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.2523 - val_loss: 95.8106\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.8257 - val_loss: 94.6016\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.7194 - val_loss: 100.0191\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.5999 - val_loss: 98.0784\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.3942 - val_loss: 95.0536\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.2198 - val_loss: 98.9355\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.2075 - val_loss: 95.5732\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 77.7454 - val_loss: 94.8428\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.1961 - val_loss: 92.8050\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.8064 - val_loss: 91.9323\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 76.8291 - val_loss: 101.5425\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 73.0113 - val_loss: 96.9546\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 72.4867 - val_loss: 89.8967\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 80.9845 - val_loss: 93.9453\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.0646 - val_loss: 115.3211\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.2319 - val_loss: 88.8835\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 77.6765 - val_loss: 95.5328\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.8377 - val_loss: 88.7448\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 73.8515 - val_loss: 90.0152\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 68.2152 - val_loss: 95.6494\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.6299 - val_loss: 90.1480\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.6520 - val_loss: 98.0302\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  37 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 7453.0020 - val_loss: 3258.9114\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3411.0188 - val_loss: 2548.3767\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2454.8076 - val_loss: 2041.5118\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1965.2317 - val_loss: 1610.3756\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1614.4271 - val_loss: 1301.2848\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1229.3197 - val_loss: 1057.4482\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1030.0752 - val_loss: 884.6957\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 870.4916 - val_loss: 757.5776\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 742.1279 - val_loss: 666.1325\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 682.7225 - val_loss: 603.7996\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 611.7141 - val_loss: 556.6982\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 507.6941 - val_loss: 521.5494\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 482.1178 - val_loss: 490.9105\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 492.0651 - val_loss: 463.7320\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 426.0073 - val_loss: 444.1038\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 372.9518 - val_loss: 418.0172\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 384.7237 - val_loss: 393.8819\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 325.3788 - val_loss: 380.2933\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 304.9033 - val_loss: 350.4798\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 298.6926 - val_loss: 328.7816\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.8986 - val_loss: 309.6063\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.1192 - val_loss: 295.1902\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 246.5681 - val_loss: 291.4701\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 256.3420 - val_loss: 268.6535\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 234.6648 - val_loss: 240.9219\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.1174 - val_loss: 227.4395\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.7196 - val_loss: 212.9110\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.2526 - val_loss: 209.1892\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.5681 - val_loss: 189.8043\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.4353 - val_loss: 176.2177\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.8988 - val_loss: 165.4798\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.8434 - val_loss: 156.4201\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.6920 - val_loss: 150.4367\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 140.0092 - val_loss: 144.4056\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.5386 - val_loss: 146.1121\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.7791 - val_loss: 133.4638\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.1764 - val_loss: 126.4193\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.0969 - val_loss: 122.8012\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.5109 - val_loss: 127.6741\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.4790 - val_loss: 127.3570\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.1933 - val_loss: 128.1696\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.5928 - val_loss: 124.2612\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.6989 - val_loss: 118.2136\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.0631 - val_loss: 108.5324\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.7376 - val_loss: 110.6748\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.9966 - val_loss: 107.8771\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.9267 - val_loss: 114.9505\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.4144 - val_loss: 106.2570\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.6716 - val_loss: 112.6549\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 115.5773 - val_loss: 110.9498\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  38 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 36436.1505 - val_loss: 10604.9033\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8196.3295 - val_loss: 8565.1055\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6223.7410 - val_loss: 5967.4268\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4103.9587 - val_loss: 4208.7134\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3005.0135 - val_loss: 3077.0068\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2424.0436 - val_loss: 2242.2705\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1710.5028 - val_loss: 1641.0985\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1433.2847 - val_loss: 1207.6584\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1006.4376 - val_loss: 904.9251\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 788.4894 - val_loss: 678.4165\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 565.9179 - val_loss: 542.1226\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 517.0149 - val_loss: 443.3426\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 389.7324 - val_loss: 379.7616\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 370.7608 - val_loss: 333.2843\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 336.2023 - val_loss: 302.8970\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.8674 - val_loss: 276.4416\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 306.0966 - val_loss: 256.5994\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.8146 - val_loss: 240.6603\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.3579 - val_loss: 228.2589\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.3782 - val_loss: 216.4537\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.7883 - val_loss: 206.2061\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.6588 - val_loss: 201.4807\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 209.3509 - val_loss: 191.6610\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.4803 - val_loss: 184.5897\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.8775 - val_loss: 177.7261\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.5024 - val_loss: 172.1696\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 174.4542 - val_loss: 167.5160\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.4356 - val_loss: 163.6181\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.0372 - val_loss: 160.9154\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.2084 - val_loss: 156.2254\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 150.1963 - val_loss: 153.5103\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.3535 - val_loss: 150.6180\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.5385 - val_loss: 147.4645\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.3146 - val_loss: 145.6180\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.7323 - val_loss: 143.8628\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.6238 - val_loss: 142.0189\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.5661 - val_loss: 138.9120\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.1000 - val_loss: 138.2713\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.2966 - val_loss: 137.8317\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.2490 - val_loss: 133.0249\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.7242 - val_loss: 133.7110\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.8381 - val_loss: 132.4087\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.8025 - val_loss: 130.6957\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.1177 - val_loss: 128.1619\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.0953 - val_loss: 129.8235\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.3254 - val_loss: 126.2534\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.2633 - val_loss: 130.1968\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.7174 - val_loss: 124.3236\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.2912 - val_loss: 124.8287\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.3099 - val_loss: 123.2422\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  39 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 4376.5421 - val_loss: 3220.1799\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2600.2257 - val_loss: 1601.0735\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1285.7599 - val_loss: 760.6263\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 713.9579 - val_loss: 584.7549\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 556.8179 - val_loss: 485.8761\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 479.2818 - val_loss: 426.5338\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 386.1745 - val_loss: 385.4359\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 395.9157 - val_loss: 358.4435\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 359.5114 - val_loss: 338.8734\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.8746 - val_loss: 320.5950\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 292.2135 - val_loss: 305.7157\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 293.9303 - val_loss: 288.4099\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.1438 - val_loss: 279.2629\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.2403 - val_loss: 270.4123\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.2399 - val_loss: 263.0442\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 247.4133 - val_loss: 256.2979\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.1160 - val_loss: 251.4784\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.6446 - val_loss: 247.7781\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 229.5266 - val_loss: 241.9686\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.0298 - val_loss: 237.4054\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.0890 - val_loss: 234.3463\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.1644 - val_loss: 230.6859\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.3769 - val_loss: 228.2571\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.7490 - val_loss: 223.9781\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.0841 - val_loss: 221.5594\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.6702 - val_loss: 216.8290\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.4083 - val_loss: 213.5891\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.9730 - val_loss: 210.9794\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.4989 - val_loss: 208.5708\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.4365 - val_loss: 204.4984\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.1991 - val_loss: 201.3998\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.1169 - val_loss: 199.4501\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.4501 - val_loss: 196.0699\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.7273 - val_loss: 192.6567\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.5451 - val_loss: 190.6349\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 170.7213 - val_loss: 186.5341\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.0375 - val_loss: 183.7979\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.4922 - val_loss: 179.3218\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.9028 - val_loss: 174.8782\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.2693 - val_loss: 172.6938\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.7448 - val_loss: 166.2350\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.0357 - val_loss: 162.6006\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.0614 - val_loss: 157.2446\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 126.1065 - val_loss: 153.3728\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.4266 - val_loss: 148.6067\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 121.2743 - val_loss: 144.3506\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.1513 - val_loss: 140.2775\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.4044 - val_loss: 137.0163\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.4174 - val_loss: 132.5294\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.9505 - val_loss: 128.2888\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  40 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 123054.1020 - val_loss: 69011.8672\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 58491.6494 - val_loss: 28989.5293\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 23916.2402 - val_loss: 11219.5273\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9414.8154 - val_loss: 4400.3042\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4286.5450 - val_loss: 2198.4485\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2360.3301 - val_loss: 1812.0410\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1779.6539 - val_loss: 1756.8744\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1563.8494 - val_loss: 1673.3704\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1575.4191 - val_loss: 1582.2020\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1419.4128 - val_loss: 1487.5922\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1430.9865 - val_loss: 1397.0049\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1410.1555 - val_loss: 1314.2411\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1265.1663 - val_loss: 1246.8102\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 1327.4080 - val_loss: 1189.7360\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1163.4573 - val_loss: 1131.6808\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1096.0063 - val_loss: 1080.1508\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1142.8101 - val_loss: 1029.6804\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1071.2685 - val_loss: 984.4068\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 941.0140 - val_loss: 943.1819\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 922.9331 - val_loss: 906.2952\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 901.5652 - val_loss: 866.2529\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 881.7448 - val_loss: 829.7817\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 837.6290 - val_loss: 797.1363\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 773.9060 - val_loss: 763.1800\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 787.7965 - val_loss: 731.4099\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 793.2405 - val_loss: 705.0688\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 652.6440 - val_loss: 675.0917\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 722.9782 - val_loss: 651.2349\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 657.9186 - val_loss: 625.4712\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 697.4227 - val_loss: 600.3486\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 646.7848 - val_loss: 581.9586\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 562.7473 - val_loss: 556.1940\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 540.6265 - val_loss: 536.3005\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 555.1304 - val_loss: 519.9465\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 510.3091 - val_loss: 501.1561\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 575.8314 - val_loss: 480.4528\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 504.2830 - val_loss: 466.2889\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 432.4473 - val_loss: 447.6643\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 430.4547 - val_loss: 437.7198\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 424.7179 - val_loss: 418.4221\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 399.9238 - val_loss: 405.3528\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 416.7519 - val_loss: 392.2241\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 404.9009 - val_loss: 379.5773\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 394.4440 - val_loss: 368.8637\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 395.1074 - val_loss: 353.9439\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 370.9161 - val_loss: 345.2201\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 353.6936 - val_loss: 332.7501\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 343.1883 - val_loss: 323.9366\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 351.9346 - val_loss: 313.5171\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 305.2041 - val_loss: 303.9160\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  41 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 117772.1103 - val_loss: 27009.3125\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 16426.4309 - val_loss: 2530.9695\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4079.2073 - val_loss: 2942.2329\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3475.2106 - val_loss: 2051.0701\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2809.3760 - val_loss: 1910.5061\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2356.4531 - val_loss: 1720.8605\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2386.7175 - val_loss: 1595.0243\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2259.3966 - val_loss: 1477.0706\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2008.1837 - val_loss: 1376.9150\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1742.1186 - val_loss: 1285.9617\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1491.6376 - val_loss: 1201.8521\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1636.6276 - val_loss: 1126.5352\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1451.9613 - val_loss: 1057.1708\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1408.5968 - val_loss: 991.9805\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1255.5210 - val_loss: 938.0001\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1180.7905 - val_loss: 886.5365\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1141.6102 - val_loss: 837.5853\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1048.5227 - val_loss: 803.6746\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 941.9081 - val_loss: 754.7723\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 852.5232 - val_loss: 719.1808\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 878.2713 - val_loss: 685.4681\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 866.3536 - val_loss: 650.9657\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 833.9344 - val_loss: 622.5501\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 707.7969 - val_loss: 593.8709\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 781.0197 - val_loss: 566.1418\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 635.5416 - val_loss: 545.4225\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 632.3092 - val_loss: 519.7240\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 557.6770 - val_loss: 499.2860\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 571.5445 - val_loss: 479.0763\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 509.9984 - val_loss: 461.4547\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 533.3681 - val_loss: 442.5713\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 470.0017 - val_loss: 427.3145\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 435.6424 - val_loss: 411.7557\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 442.8737 - val_loss: 397.1104\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 431.5452 - val_loss: 384.8227\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 397.4573 - val_loss: 371.0301\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 410.8672 - val_loss: 359.2254\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 399.7522 - val_loss: 347.4491\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 399.2151 - val_loss: 337.1322\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 380.5297 - val_loss: 327.5825\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 358.7255 - val_loss: 317.7495\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 321.1529 - val_loss: 309.3838\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 340.7860 - val_loss: 302.5417\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 353.2995 - val_loss: 293.8956\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.5179 - val_loss: 285.1446\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 317.3173 - val_loss: 278.3101\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 284.5798 - val_loss: 272.9013\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 301.5167 - val_loss: 265.5668\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 293.5359 - val_loss: 259.1349\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 256.7227 - val_loss: 253.8018\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  42 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 22ms/step - loss: 9759.0122 - val_loss: 1389.0145\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1530.0343 - val_loss: 1427.6560\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1167.0981 - val_loss: 1181.7875\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1074.7219 - val_loss: 1083.0782\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 961.3025 - val_loss: 994.9263\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 876.5608 - val_loss: 927.8790\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 827.3638 - val_loss: 854.9941\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 782.3317 - val_loss: 791.7568\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 712.9341 - val_loss: 726.3383\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 717.5843 - val_loss: 670.2883\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 646.9756 - val_loss: 611.9097\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 562.6531 - val_loss: 573.7790\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 588.5226 - val_loss: 522.7368\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 498.4394 - val_loss: 487.0538\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 450.3298 - val_loss: 457.3540\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 445.7080 - val_loss: 416.4684\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 410.5692 - val_loss: 397.6103\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 357.7870 - val_loss: 369.3803\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 331.1055 - val_loss: 346.1261\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 323.2956 - val_loss: 323.3179\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 307.9036 - val_loss: 309.8492\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 300.7837 - val_loss: 288.2938\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 275.8302 - val_loss: 275.1999\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 245.0644 - val_loss: 262.5216\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 227.3661 - val_loss: 252.7166\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 220.6626 - val_loss: 241.8307\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 213.4367 - val_loss: 231.4675\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 242.8976 - val_loss: 221.8485\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.5334 - val_loss: 216.0599\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.3899 - val_loss: 206.9638\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.6254 - val_loss: 201.2647\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.1562 - val_loss: 194.4093\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.5245 - val_loss: 188.9837\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 173.9343 - val_loss: 184.5182\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.3293 - val_loss: 179.5806\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.2204 - val_loss: 177.7271\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.0141 - val_loss: 172.5644\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 152.8694 - val_loss: 169.7083\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.5621 - val_loss: 167.2277\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.9878 - val_loss: 164.3437\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 140.0327 - val_loss: 161.9956\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.8407 - val_loss: 160.0067\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.9241 - val_loss: 159.7973\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.9070 - val_loss: 156.9477\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.4298 - val_loss: 156.2207\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.6052 - val_loss: 154.2116\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.1253 - val_loss: 154.0267\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 129.4800 - val_loss: 155.0234\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.7975 - val_loss: 153.2025\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.6945 - val_loss: 151.6366\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  43 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 24ms/step - loss: 1141628.8971 - val_loss: 843723.5625\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 770414.2353 - val_loss: 572524.3750\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 537327.2555 - val_loss: 397484.0938\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 366561.1710 - val_loss: 283642.9375\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 263555.2619 - val_loss: 206536.1719\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 189412.5855 - val_loss: 151931.3594\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 142203.1369 - val_loss: 111308.2188\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104940.3084 - val_loss: 80294.2734\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 73440.2013 - val_loss: 56187.6406\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 50337.6432 - val_loss: 37594.5195\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 33924.0418 - val_loss: 24272.9473\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 21652.7702 - val_loss: 15454.4570\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 13887.6649 - val_loss: 9788.4609\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8845.3373 - val_loss: 6393.2070\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5528.5563 - val_loss: 4255.5200\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3635.4025 - val_loss: 2837.7324\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2443.2590 - val_loss: 1927.9862\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1569.4103 - val_loss: 1344.1532\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1123.9546 - val_loss: 984.2156\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 774.7971 - val_loss: 772.6562\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 635.3975 - val_loss: 649.8899\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 473.8248 - val_loss: 579.3173\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 441.1289 - val_loss: 530.7144\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 412.9249 - val_loss: 501.2136\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 370.6232 - val_loss: 472.6154\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 372.5592 - val_loss: 448.3875\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 349.6058 - val_loss: 428.4737\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 334.7399 - val_loss: 412.1259\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 315.7506 - val_loss: 392.0858\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 323.2458 - val_loss: 378.0745\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 319.9132 - val_loss: 372.0530\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 305.3975 - val_loss: 355.6161\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 287.7166 - val_loss: 348.3185\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 279.5989 - val_loss: 339.8129\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.4890 - val_loss: 332.0501\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.2099 - val_loss: 326.4575\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 257.7066 - val_loss: 321.7981\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 246.1392 - val_loss: 316.4433\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 251.4043 - val_loss: 313.4499\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.8769 - val_loss: 305.6494\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 249.6599 - val_loss: 304.7274\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.5104 - val_loss: 300.1048\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.0638 - val_loss: 294.7890\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.4713 - val_loss: 295.2896\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 239.3586 - val_loss: 288.4511\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 232.4572 - val_loss: 286.5612\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.0329 - val_loss: 285.9422\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.6937 - val_loss: 287.0847\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 229.1780 - val_loss: 283.9780\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.8416 - val_loss: 287.4292\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  44 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 1365.0161 - val_loss: 511.4329\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 631.0942 - val_loss: 452.4708\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 504.3520 - val_loss: 429.0221\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 458.9056 - val_loss: 391.7609\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 434.8347 - val_loss: 369.7849\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 388.5881 - val_loss: 348.4962\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 406.9221 - val_loss: 332.2625\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 395.1863 - val_loss: 318.4007\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 341.0011 - val_loss: 306.9984\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 348.3066 - val_loss: 296.9315\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 350.8215 - val_loss: 287.5443\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 322.1499 - val_loss: 280.4042\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 335.9836 - val_loss: 272.8264\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 300.2984 - val_loss: 266.0725\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 306.4907 - val_loss: 260.6523\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.5603 - val_loss: 254.9245\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 280.4991 - val_loss: 248.6849\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 280.7943 - val_loss: 243.3742\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 278.8917 - val_loss: 238.2939\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 292.7350 - val_loss: 233.5197\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 249.5933 - val_loss: 233.6699\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.6611 - val_loss: 225.4107\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.2860 - val_loss: 220.6474\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.4626 - val_loss: 218.6556\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.6563 - val_loss: 211.9176\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 234.3694 - val_loss: 206.8677\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.7582 - val_loss: 202.5400\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.0088 - val_loss: 198.2649\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.8490 - val_loss: 194.6993\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 206.0002 - val_loss: 192.6407\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 207.7004 - val_loss: 184.9849\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.0112 - val_loss: 181.7679\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.4177 - val_loss: 176.5175\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 192.5152 - val_loss: 176.1369\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.5010 - val_loss: 168.7009\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.1202 - val_loss: 170.4373\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.1698 - val_loss: 162.4644\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 175.8505 - val_loss: 155.5661\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.7988 - val_loss: 152.9822\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.7671 - val_loss: 148.7452\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 173.6077 - val_loss: 145.3540\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.3529 - val_loss: 144.5498\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 158.7407 - val_loss: 139.9430\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.4689 - val_loss: 140.0130\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.2160 - val_loss: 137.0369\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.3080 - val_loss: 134.0045\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.6533 - val_loss: 130.3926\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 152.6674 - val_loss: 130.6139\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.2812 - val_loss: 130.3803\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 145.5126 - val_loss: 126.1560\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  45 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 237441.5165 - val_loss: 162152.0312\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 140364.7955 - val_loss: 89118.2500\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 74442.5175 - val_loss: 43547.8047\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 36066.3843 - val_loss: 18511.3438\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 13404.3896 - val_loss: 6391.4194\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4483.8151 - val_loss: 1921.8889\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1719.7675 - val_loss: 1602.1809\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1739.3822 - val_loss: 1521.5967\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1557.9019 - val_loss: 1459.2710\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1426.7745 - val_loss: 1401.4054\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1511.2493 - val_loss: 1335.4922\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1439.7478 - val_loss: 1267.9811\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1304.9436 - val_loss: 1203.9244\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1142.3012 - val_loss: 1148.1744\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1116.5478 - val_loss: 1090.7474\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1084.8814 - val_loss: 1036.2794\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1035.7199 - val_loss: 990.9195\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1039.9408 - val_loss: 944.2002\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 915.7391 - val_loss: 906.5328\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 906.8412 - val_loss: 874.7479\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 796.5261 - val_loss: 842.6137\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 823.1388 - val_loss: 809.8440\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 773.5696 - val_loss: 780.5566\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 855.7073 - val_loss: 751.0858\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 672.1197 - val_loss: 721.8208\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 693.1745 - val_loss: 697.5222\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 711.1293 - val_loss: 667.5773\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 665.9183 - val_loss: 641.4874\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 621.5303 - val_loss: 615.2551\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 604.4660 - val_loss: 589.7151\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 506.2362 - val_loss: 562.8970\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 568.3048 - val_loss: 533.4909\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 485.9594 - val_loss: 506.4589\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 451.8511 - val_loss: 479.0230\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 437.6024 - val_loss: 454.2491\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 445.7139 - val_loss: 430.7029\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 398.3022 - val_loss: 410.5205\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 378.0657 - val_loss: 391.3712\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 346.3718 - val_loss: 374.5786\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 341.0035 - val_loss: 361.5626\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 333.2340 - val_loss: 348.4045\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 294.3709 - val_loss: 337.9085\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 280.8027 - val_loss: 328.7339\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.4671 - val_loss: 320.7904\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 300.0570 - val_loss: 313.7466\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.5897 - val_loss: 308.9003\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.6763 - val_loss: 304.3396\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 241.7151 - val_loss: 299.5116\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.2238 - val_loss: 296.6462\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 254.4169 - val_loss: 292.4427\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  46 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 2224.5462 - val_loss: 1314.1753\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1195.4310 - val_loss: 902.5098\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 756.6584 - val_loss: 661.6362\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 634.9581 - val_loss: 505.9520\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 516.6735 - val_loss: 429.6849\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 410.5245 - val_loss: 380.0981\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 352.1341 - val_loss: 322.8987\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 329.7189 - val_loss: 303.8850\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 324.8608 - val_loss: 253.5327\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 242.3386 - val_loss: 247.6759\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.7296 - val_loss: 209.1154\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.6072 - val_loss: 197.7914\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.8103 - val_loss: 184.4784\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 200.2944 - val_loss: 191.6976\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.9473 - val_loss: 166.6097\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.8003 - val_loss: 172.9803\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.4505 - val_loss: 159.9487\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.2945 - val_loss: 154.5040\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.6176 - val_loss: 152.9825\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.1727 - val_loss: 146.4429\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.5180 - val_loss: 148.1963\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.0395 - val_loss: 153.0498\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.4795 - val_loss: 132.7169\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.0919 - val_loss: 135.2836\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.2466 - val_loss: 137.0834\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.8832 - val_loss: 127.2546\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.3112 - val_loss: 121.0255\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 147.2600 - val_loss: 129.0664\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.3508 - val_loss: 118.4525\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 115.9988 - val_loss: 117.4746\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 111.8555 - val_loss: 115.9764\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.8246 - val_loss: 111.3098\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.7112 - val_loss: 114.7809\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.8012 - val_loss: 110.3012\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.1311 - val_loss: 107.5415\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.0951 - val_loss: 106.2217\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.5613 - val_loss: 106.1360\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.9317 - val_loss: 102.3935\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.4600 - val_loss: 102.8022\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.6196 - val_loss: 106.7283\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.9909 - val_loss: 98.8931\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.6465 - val_loss: 98.4320\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.9958 - val_loss: 95.1663\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.4191 - val_loss: 95.3794\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.5045 - val_loss: 93.0012\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.6778 - val_loss: 90.7443\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.5411 - val_loss: 93.4559\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.7303 - val_loss: 88.2581\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.6721 - val_loss: 88.0735\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.4764 - val_loss: 91.0191\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  47 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 420.8707 - val_loss: 306.7429\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 276.2146 - val_loss: 287.0982\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 289.4647 - val_loss: 271.2354\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 265.1300 - val_loss: 262.6153\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 267.5527 - val_loss: 254.3746\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.4596 - val_loss: 246.6822\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 222.8005 - val_loss: 238.0112\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.9657 - val_loss: 229.6206\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.0911 - val_loss: 222.1391\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.0079 - val_loss: 215.6980\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.8955 - val_loss: 210.3350\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 182.7227 - val_loss: 203.7295\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.7289 - val_loss: 197.7229\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.3065 - val_loss: 193.9885\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.1561 - val_loss: 185.4198\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165.8662 - val_loss: 179.1852\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 152.5512 - val_loss: 173.6050\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.5920 - val_loss: 168.5299\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.5759 - val_loss: 162.3284\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.9249 - val_loss: 154.6441\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 151.1240 - val_loss: 147.9697\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.4008 - val_loss: 142.8877\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 134.2658 - val_loss: 138.1784\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.8787 - val_loss: 131.5215\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 131.3776 - val_loss: 128.6069\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.7822 - val_loss: 130.7042\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.8614 - val_loss: 119.8443\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 104.3113 - val_loss: 117.4550\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 109.8528 - val_loss: 122.0060\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.5632 - val_loss: 111.7399\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 108.3073 - val_loss: 109.1153\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.5290 - val_loss: 107.6356\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.8876 - val_loss: 107.8242\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 104.0953 - val_loss: 104.4068\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.3007 - val_loss: 103.0970\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.3059 - val_loss: 101.8271\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 91.4307 - val_loss: 101.1106\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.4412 - val_loss: 100.4352\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.1526 - val_loss: 107.4988\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 90.8396 - val_loss: 99.6613\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 96.5969 - val_loss: 98.6835\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 90.7494 - val_loss: 102.9942\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 95.7820 - val_loss: 97.6006\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 93.8574 - val_loss: 96.8538\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 90.6836 - val_loss: 103.9247\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 89.9569 - val_loss: 95.1974\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 76.7405 - val_loss: 95.6890\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 91.5915 - val_loss: 96.1795\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 84.4175 - val_loss: 101.1026\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 99.9574 - val_loss: 96.2116\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  48 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 998.4739 - val_loss: 622.7093\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 610.1066 - val_loss: 472.9565\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 461.4183 - val_loss: 381.0294\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 352.3839 - val_loss: 348.5915\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 347.4662 - val_loss: 337.9011\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 316.3288 - val_loss: 342.5980\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 344.2833 - val_loss: 335.6286\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 315.4545 - val_loss: 339.9011\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 338.9073 - val_loss: 333.0188\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 320.8877 - val_loss: 334.9779\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 322.3434 - val_loss: 332.3439\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 321.5326 - val_loss: 334.0825\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 320.4843 - val_loss: 330.9294\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 311.9478 - val_loss: 331.0657\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 314.1802 - val_loss: 328.7950\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 312.1022 - val_loss: 329.0303\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 319.9310 - val_loss: 328.8454\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 327.5180 - val_loss: 327.1386\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 313.2372 - val_loss: 325.9599\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 325.9322 - val_loss: 325.3426\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 310.9257 - val_loss: 322.9068\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 298.4261 - val_loss: 325.0378\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 289.9385 - val_loss: 321.3173\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 314.3007 - val_loss: 320.4792\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 313.1968 - val_loss: 320.2536\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 290.6320 - val_loss: 318.1828\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 306.4550 - val_loss: 320.0702\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 315.5590 - val_loss: 318.7684\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 323.1465 - val_loss: 314.6318\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.3341 - val_loss: 319.1149\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 310.3522 - val_loss: 312.3770\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 310.3992 - val_loss: 315.7422\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 317.1536 - val_loss: 311.5619\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 318.1507 - val_loss: 312.0591\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 295.2952 - val_loss: 311.1299\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 291.7304 - val_loss: 306.9904\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 276.8501 - val_loss: 306.7238\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 299.2352 - val_loss: 308.7939\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 291.8337 - val_loss: 305.1259\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 297.7920 - val_loss: 305.3461\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 280.7158 - val_loss: 301.3961\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 280.0914 - val_loss: 301.7491\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 284.9765 - val_loss: 299.6634\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 295.5268 - val_loss: 299.1169\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 277.6955 - val_loss: 300.0811\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 298.3745 - val_loss: 298.4844\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 256.9492 - val_loss: 295.8402\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 271.7324 - val_loss: 293.0634\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 292.9201 - val_loss: 316.5847\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.6561 - val_loss: 290.9462\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  49 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 171016.6388 - val_loss: 97282.1484\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 79296.0935 - val_loss: 35488.1836\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 25561.8006 - val_loss: 9705.4912\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 7062.0521 - val_loss: 3909.7971\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4015.3518 - val_loss: 3201.2881\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3527.2594 - val_loss: 2884.5522\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3006.8263 - val_loss: 2643.0869\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2605.8116 - val_loss: 2469.9451\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2490.4876 - val_loss: 2296.9890\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 2198.8829 - val_loss: 2132.6772\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2375.9955 - val_loss: 2003.5070\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1953.7963 - val_loss: 1912.0166\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2061.0648 - val_loss: 1805.8717\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1796.9151 - val_loss: 1725.1351\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1830.3077 - val_loss: 1652.9762\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1785.7270 - val_loss: 1576.3109\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1613.2346 - val_loss: 1503.3240\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1556.0495 - val_loss: 1446.7858\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1519.4358 - val_loss: 1387.3759\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1289.5035 - val_loss: 1323.2386\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1288.0244 - val_loss: 1266.1195\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1424.0013 - val_loss: 1212.3901\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1163.0018 - val_loss: 1164.1023\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1197.6949 - val_loss: 1116.8076\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1064.8172 - val_loss: 1068.3733\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1048.9870 - val_loss: 1027.7882\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1038.8746 - val_loss: 983.7059\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 978.3834 - val_loss: 943.7797\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 992.0970 - val_loss: 909.1179\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 924.5471 - val_loss: 868.0661\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 839.9099 - val_loss: 832.1353\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 798.6118 - val_loss: 798.1815\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 801.6573 - val_loss: 761.8224\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 716.6429 - val_loss: 729.9172\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 634.6192 - val_loss: 704.0318\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 682.3077 - val_loss: 671.2571\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 712.8719 - val_loss: 636.7032\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 646.4586 - val_loss: 615.2260\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 592.7388 - val_loss: 583.8497\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 586.4202 - val_loss: 561.8656\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 531.2517 - val_loss: 535.3588\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 469.5731 - val_loss: 512.0063\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 441.4514 - val_loss: 489.8363\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 476.4798 - val_loss: 472.0359\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 433.3906 - val_loss: 446.0776\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 395.2395 - val_loss: 430.9624\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 404.6601 - val_loss: 411.1764\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 384.0384 - val_loss: 395.2722\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 346.5802 - val_loss: 378.3127\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 391.2604 - val_loss: 365.4030\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  50 \n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "16/16 [==============================] - 1s 26ms/step - loss: 7620.4737 - val_loss: 907.6823\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1203.7854 - val_loss: 988.8240\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 927.9838 - val_loss: 675.4259\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 682.4939 - val_loss: 601.7593\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 690.0295 - val_loss: 549.9804\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 564.6888 - val_loss: 478.1674\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 549.1407 - val_loss: 447.3176\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 510.1099 - val_loss: 403.8139\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 424.6024 - val_loss: 378.2336\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 436.4338 - val_loss: 349.9589\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 346.1126 - val_loss: 329.5240\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 340.3609 - val_loss: 310.0284\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 321.4274 - val_loss: 295.3094\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 335.8607 - val_loss: 279.1852\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 308.0035 - val_loss: 275.8578\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 272.2338 - val_loss: 263.9516\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 258.4306 - val_loss: 256.9423\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 283.9801 - val_loss: 254.6087\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 273.3028 - val_loss: 251.1152\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 250.7630 - val_loss: 246.3546\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 232.6036 - val_loss: 246.0661\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 253.7561 - val_loss: 249.4178\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 253.4801 - val_loss: 241.5943\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 234.7986 - val_loss: 240.6300\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 236.7118 - val_loss: 239.2605\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 237.5380 - val_loss: 241.3678\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 237.3334 - val_loss: 237.7631\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 227.6695 - val_loss: 242.7043\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 215.4914 - val_loss: 239.4025\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.9580 - val_loss: 245.5504\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 224.8148 - val_loss: 235.8183\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.0194 - val_loss: 233.7367\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.6387 - val_loss: 233.4609\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 218.1930 - val_loss: 234.3519\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.4637 - val_loss: 232.6030\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 210.7152 - val_loss: 231.0123\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.6207 - val_loss: 233.1563\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 217.2020 - val_loss: 235.0463\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 210.2859 - val_loss: 229.0468\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.4813 - val_loss: 229.5145\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.7568 - val_loss: 229.6205\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.2121 - val_loss: 228.6586\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 206.7622 - val_loss: 225.8320\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.1698 - val_loss: 224.4075\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 216.0843 - val_loss: 223.7799\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.5605 - val_loss: 223.9549\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.6943 - val_loss: 222.9822\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.7857 - val_loss: 227.1522\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.7818 - val_loss: 219.8996\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.0847 - val_loss: 228.5260\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Total Execution Time :  0:04:41.136967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg-AKoeUCn2n",
        "outputId": "b3a36c7e-8d6b-4873-9bd4-38ca1adc35ea"
      },
      "source": [
        "# Calculate the Mean of the MSE of 50 models\n",
        "mean_of_mse = stats.mean(list_of_mse)\n",
        "\n",
        "# Calculate the Standard Deviation of the MSE of 50 models\n",
        "std_of_mse = stats.stdev(list_of_mse)\n",
        "\n",
        "# Print the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nMean of the MSE of 50 Models : ' , str(mean_of_mse))\n",
        "print('Standard Deviation of MSE of 50 Models : ' + str(std_of_mse))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean of the MSE of 50 Models :  184.57305818783047\n",
            "Standard Deviation of MSE of 50 Models : 106.433563706641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixrhpD6nCn2q"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ansxJVAPCn2r"
      },
      "source": [
        "#### <font color = green> Comparision of Mean of MSE with Mean of MSE from PART A </font>\n",
        "<p/>\n",
        "\n",
        "<table style=\"width:20%\">\n",
        "  <tr>\n",
        "    <th>Mean of MSE of PART A</th>\n",
        "    <th>Mean of MSE of PART B</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>212.13</td>\n",
        "    <td>184.57</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "The table above compares the Mean of **MSE for PART A** and **Mean of MSE for PART B**. As can be seen, the value of Mean of MSE of PART B is significantly smaller than that of PART A. The mean squared error tells how close a regression line is to a set of points. The smaller the value, the closer the model is to finding the line of best fit. So the smaller value for PART B shows that the model is slightly closer to finding a line of best fit.\n",
        "\n",
        "To summarize, normalizing the features had a significant effect in reducing the MSE and finding the line of best fit\n",
        "\n",
        "<b>Note</b> : Depending on the data, it may be impossible to get a very small value for MSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lFY29CoCn2r"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmDZrOtICn2s"
      },
      "source": [
        "# <font color = blue> END OF PART B </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoVT002sCn2w"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN4GH0V3Cn2x"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtoLkPPFCn2x"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfpUFBCxCn2y"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1_59DVBCn2y"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfDqKFc8Cn20"
      },
      "source": [
        "# <font color = blue> PART C : BASELINE MODEL WITH 100 EPOCHS </font>\n",
        "\n",
        "\n",
        "In this part, all the tasks from <b>PART B</b> are performed, but this time the number of epochs are increased to 100\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7paP5u4WCn23"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNeaEcxnCn23"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exzKKi2NCn24"
      },
      "source": [
        "## <font color = darkorange>Task 1 : Train and Test the Baseline Model with Normalized Features and 100 epochs</font>\n",
        "\n",
        "In order to train and test the the baseline model with normalized features and 100 epochs, the following steps are performed :\n",
        "<ol>\n",
        "    <li>Normalize the features (X)</li>\n",
        "    <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "    <li>Create a new model with 100 epochs</li>\n",
        "    <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "    <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "    <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "    <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMseyNsaCn25"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Normalize the features (X) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUMQbYZOCn25"
      },
      "source": [
        "<b>Note</b> : As the features (X) have already been normalized the features (X), hence this part is skipped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOfawisxCn25"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Randomly split the data into <i>X_train, X_test, Y_train, Y_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-4KSRbCCn26"
      },
      "source": [
        "# Creating X_train, X_test, Y_train and Y_test sets\n",
        "X_train, X_test, Y_train, Y_test = data_split()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q07BdBvCn27"
      },
      "source": [
        "### <font color = #2980B9> Step 3 : Train the model using <i>X_train, Y_train</i> using 50 epochs </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPs7oWcyCn29"
      },
      "source": [
        "<b>Note </b> : Since the regression model has already been created using `def regression_model` in <b>TASK 1</b> and there are no changes being made to it, hence there is no need to write the code for the model again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEMZk-biCn2-",
        "outputId": "73b2e65f-04c6-43f2-a7fe-899fc173b363"
      },
      "source": [
        "model = regression_model()\n",
        "\n",
        "# Fit the model on the train set\n",
        "model.fit(X_train, Y_train, validation_split=0.3, epochs=100)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 2609.7606 - val_loss: 1461.6296\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1281.3971 - val_loss: 1045.5585\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1038.1613 - val_loss: 867.0037\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 795.5664 - val_loss: 623.7629\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 581.6441 - val_loss: 527.3154\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 433.4206 - val_loss: 436.7346\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 400.3742 - val_loss: 370.1161\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 346.2498 - val_loss: 323.5231\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 269.7308 - val_loss: 296.3152\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 250.1046 - val_loss: 273.3248\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 224.4765 - val_loss: 283.4669\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 251.2048 - val_loss: 248.0787\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 212.8377 - val_loss: 266.2044\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 196.4827 - val_loss: 231.2436\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 194.1860 - val_loss: 219.0038\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 175.7264 - val_loss: 222.0642\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 182.8595 - val_loss: 224.6180\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.5289 - val_loss: 201.1619\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161.7207 - val_loss: 200.6049\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.0369 - val_loss: 191.6234\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 169.1549 - val_loss: 190.3297\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 154.6879 - val_loss: 184.1865\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.9570 - val_loss: 180.8378\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.0613 - val_loss: 184.3392\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 130.9943 - val_loss: 173.5626\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 143.7887 - val_loss: 169.7491\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.1309 - val_loss: 166.6066\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.1155 - val_loss: 164.5907\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 125.4541 - val_loss: 162.7924\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 129.7639 - val_loss: 161.8182\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.1264 - val_loss: 157.7095\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 134.4806 - val_loss: 165.8687\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127.7841 - val_loss: 153.6839\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 137.8055 - val_loss: 163.1525\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 125.2742 - val_loss: 150.7567\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.1237 - val_loss: 149.2212\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.2891 - val_loss: 151.9672\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.2902 - val_loss: 151.2073\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 119.2929 - val_loss: 145.3779\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.6752 - val_loss: 143.4119\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.4417 - val_loss: 141.6487\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.0488 - val_loss: 140.2642\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 124.3246 - val_loss: 139.5971\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.1116 - val_loss: 138.7611\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.7790 - val_loss: 137.9724\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.9045 - val_loss: 135.9750\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.8040 - val_loss: 136.0617\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 113.0983 - val_loss: 134.5961\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.3557 - val_loss: 133.7780\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.3755 - val_loss: 141.3308\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.4292 - val_loss: 135.4005\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 115.0530 - val_loss: 131.8601\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.5604 - val_loss: 131.5226\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.2486 - val_loss: 130.5863\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.2753 - val_loss: 132.2640\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.9459 - val_loss: 135.2690\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113.1503 - val_loss: 129.2097\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.3115 - val_loss: 130.1395\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.3397 - val_loss: 130.0846\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.2901 - val_loss: 131.2038\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.4094 - val_loss: 128.1613\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94.4648 - val_loss: 128.1477\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.2359 - val_loss: 128.5459\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.8491 - val_loss: 136.7120\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.8579 - val_loss: 128.3728\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.2776 - val_loss: 129.9706\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 93.9774 - val_loss: 126.7387\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.8591 - val_loss: 128.3099\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.8637 - val_loss: 126.3504\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 109.5471 - val_loss: 128.8578\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.4368 - val_loss: 127.2942\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.6948 - val_loss: 125.7570\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.6745 - val_loss: 139.2952\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.5816 - val_loss: 125.6666\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.0372 - val_loss: 137.5879\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.4119 - val_loss: 126.9773\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.0237 - val_loss: 125.2811\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.3543 - val_loss: 126.8217\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.0489 - val_loss: 126.6287\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.6614 - val_loss: 125.7482\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 110.4496 - val_loss: 131.7936\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.4198 - val_loss: 124.8800\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.9211 - val_loss: 134.7005\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 114.4638 - val_loss: 126.1854\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.4802 - val_loss: 127.2607\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.5081 - val_loss: 124.9281\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.5349 - val_loss: 134.1108\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.4832 - val_loss: 128.8450\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.6678 - val_loss: 127.1667\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.8771 - val_loss: 124.2381\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.9789 - val_loss: 133.5276\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 103.0697 - val_loss: 131.3571\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.2429 - val_loss: 124.1467\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.4888 - val_loss: 125.2700\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 100.5676 - val_loss: 125.4703\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.0797 - val_loss: 125.9306\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.3819 - val_loss: 123.6801\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.3507 - val_loss: 123.8673\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 96.4539 - val_loss: 125.9279\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 103.6060 - val_loss: 125.3620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56d07a9cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4zmS7U3Cn2_"
      },
      "source": [
        "### <font color = #2980B9> Step 4 : Get the predictions on the X_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aczIgP-rCn3A"
      },
      "source": [
        "# Store the predictions in a variable Y_Predicted\n",
        "Y_predicted = predict()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJgWnYCcCn3A"
      },
      "source": [
        "### <font color = #2980B9> Step 5 : Compute the <i>mean squared error</i> on the test set using sklearn </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teCPVtY3Cn3B",
        "outputId": "457d7675-3d9a-46be-8d98-fb3b73e928c9"
      },
      "source": [
        "# Calculate the mean square error\n",
        "\n",
        "mse = calculate_mse()\n",
        "print('Mean Square Error (MSE) of the Baseline Model with Normalized Features is : ' , str(mse))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Square Error (MSE) of the Baseline Model with Normalized Features is :  114.68615748837777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ny2aUJbCn3C"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63nYZM93Cn3D"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59qUuB_HCn3E"
      },
      "source": [
        "## <font color = darkorange>Task 2 : Create 50 Models and Calculate the <i>µ</i> & <i>σ</i> of their MSE Errors with 100 Epochs</font>\n",
        "\n",
        "In order to train 50 models with new features (normalized features) and calulate the mean (µ) and standard deviation (σ) of their mean square errors (MSE) the following steps are performed :\n",
        "<ol>\n",
        "    <li>Create an empty list <code>list_of_mse</code> to store the mean square error of each of the models</li>\n",
        "    <li>Define a for loop and perform each of the following steps in the loop</li>\n",
        "        <ol>\n",
        "        <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "        <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "        <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "        <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "        <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "    </ol>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImDzHmukCn3F"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Creating the <i>list_of_mse</i> list</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRsWtORVCn3G"
      },
      "source": [
        "# Create the empty lists\n",
        "list_of_mse = []"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwUhSxWcCn3H"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Creating 50 Models, Calculating The MSE for Each and <i>µ</i> & <i>σ</i> of the 50 MSE Values in <i>list_of_mse</i> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPul_U9FCn3I",
        "outputId": "81a8edd2-663f-4e56-86ba-6494a21cc270"
      },
      "source": [
        "# Create the for loop to split the data, create, compile & fit model, evaluate & nake predictions, caluclate mse and store\n",
        "# in list_of_mse\n",
        "\n",
        "start_time = datetime.now() # Starting time of the for loop execution\n",
        "\n",
        "for i in range(50) :\n",
        "    # Split the data into train and test set\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "    \n",
        "    # Create and compile the regression model using the function regression_model as defined in TASK 1\n",
        "    model = regression_model()\n",
        "\n",
        "    # Fit the model on the train set\n",
        "    print('\\n\\n\\nTraining Model # ' , i+1 , '\\n\\n') # Print the Model Number that is being trained\n",
        "    model.fit(X_train, Y_train, validation_split=0.3, epochs=100)\n",
        "    print('\\n')\n",
        "    \n",
        "    # Make prediction on the test set\n",
        "    Y_predicted = model.predict(X_test)\n",
        "    \n",
        "    # Calculate the mean square error\n",
        "    mse = mean_squared_error(Y_test, Y_predicted)\n",
        "    \n",
        "    # Add the mse to the list_of_mse list\n",
        "    list_of_mse.append(mse)\n",
        "\n",
        "end_time = datetime.now() # Ending time of the for loop execution\n",
        "\n",
        "# Print time taken for fitting 50 models and calucating the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nTotal Execution Time : ' , format(end_time - start_time))\n",
        "    "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.2429 - val_loss: 160.9287\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.0198 - val_loss: 160.5157\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  27 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 19407.2869 - val_loss: 10085.4082\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8477.6473 - val_loss: 4508.5571\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3884.2155 - val_loss: 2105.8108\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1757.9859 - val_loss: 1032.5752\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 854.7585 - val_loss: 567.6989\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 576.0744 - val_loss: 395.2064\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 408.8812 - val_loss: 331.5452\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 382.1835 - val_loss: 293.9735\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 307.7162 - val_loss: 270.2671\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 295.8028 - val_loss: 251.4044\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 286.1736 - val_loss: 234.7133\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.9943 - val_loss: 219.9660\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 261.1907 - val_loss: 202.7035\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.4601 - val_loss: 182.0265\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 224.5048 - val_loss: 173.5096\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.9582 - val_loss: 152.4939\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.9873 - val_loss: 139.3803\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.1332 - val_loss: 141.1497\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.2314 - val_loss: 126.1439\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.8519 - val_loss: 122.3899\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.3200 - val_loss: 120.0821\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.8639 - val_loss: 119.4762\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.4568 - val_loss: 117.3216\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.2379 - val_loss: 115.4742\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.5210 - val_loss: 116.2405\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.1270 - val_loss: 115.1001\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.9238 - val_loss: 113.4505\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 95.3385 - val_loss: 113.4759\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.0348 - val_loss: 113.9784\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.1864 - val_loss: 113.4855\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.0224 - val_loss: 112.5459\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.0069 - val_loss: 113.7966\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.0464 - val_loss: 111.9593\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.9074 - val_loss: 113.2325\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.6384 - val_loss: 112.3593\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.6816 - val_loss: 111.8187\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.3759 - val_loss: 114.3676\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.4743 - val_loss: 111.5725\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.1185 - val_loss: 114.4443\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.0821 - val_loss: 111.4037\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.3613 - val_loss: 111.3213\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.8241 - val_loss: 111.2430\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.1444 - val_loss: 110.0781\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.9727 - val_loss: 110.1353\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.0743 - val_loss: 113.2320\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.1871 - val_loss: 111.9814\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.8575 - val_loss: 109.1348\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.6837 - val_loss: 113.8945\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.9493 - val_loss: 110.7326\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.5768 - val_loss: 109.6492\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.1912 - val_loss: 110.5904\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.2563 - val_loss: 108.7314\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.8429 - val_loss: 109.0369\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.5543 - val_loss: 115.6261\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.3392 - val_loss: 109.2791\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.3397 - val_loss: 111.2620\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.1416 - val_loss: 113.3298\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.7718 - val_loss: 107.8219\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 71.0562 - val_loss: 109.2363\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.0238 - val_loss: 108.2594\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.9877 - val_loss: 108.0506\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 83.0632 - val_loss: 107.0421\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.7465 - val_loss: 109.0547\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.8327 - val_loss: 108.8942\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.8093 - val_loss: 108.3619\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.3027 - val_loss: 106.6281\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 80.7819 - val_loss: 106.3809\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.0775 - val_loss: 107.5479\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 78.1816 - val_loss: 106.6814\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 68.3010 - val_loss: 105.7935\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.8839 - val_loss: 108.0918\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.6638 - val_loss: 105.6168\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.1988 - val_loss: 105.3549\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 77.0815 - val_loss: 105.6528\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.6475 - val_loss: 104.8949\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.2299 - val_loss: 105.0947\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.7922 - val_loss: 105.6495\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.5654 - val_loss: 105.6465\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.3462 - val_loss: 104.5078\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 76.0412 - val_loss: 103.8472\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.2740 - val_loss: 106.6470\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.9998 - val_loss: 104.5961\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.8345 - val_loss: 103.3241\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.7167 - val_loss: 104.9941\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.7631 - val_loss: 103.4254\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.5776 - val_loss: 103.3683\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.1668 - val_loss: 104.9156\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.8664 - val_loss: 103.4652\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.1889 - val_loss: 104.7463\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.0129 - val_loss: 109.7308\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.5252 - val_loss: 103.8322\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 70.7570 - val_loss: 102.4812\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.3474 - val_loss: 102.4177\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.8399 - val_loss: 103.9425\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.9258 - val_loss: 102.7848\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.4786 - val_loss: 101.9286\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.2618 - val_loss: 103.6107\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.2901 - val_loss: 102.1072\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.0961 - val_loss: 109.1742\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.5713 - val_loss: 105.6152\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  28 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 18ms/step - loss: 8042.3303 - val_loss: 1857.1031\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1470.2296 - val_loss: 720.8365\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 589.8218 - val_loss: 746.6075\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 680.5290 - val_loss: 634.4518\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 539.3058 - val_loss: 563.1318\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 491.0226 - val_loss: 521.0410\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 394.9761 - val_loss: 471.5339\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 405.0203 - val_loss: 423.9584\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 368.3358 - val_loss: 395.6018\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 327.6788 - val_loss: 356.5096\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 343.2318 - val_loss: 334.3364\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.1560 - val_loss: 312.8169\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.0316 - val_loss: 299.3861\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.6214 - val_loss: 281.8128\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.6637 - val_loss: 269.4743\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.3232 - val_loss: 257.2975\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 210.5476 - val_loss: 245.7302\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 216.2023 - val_loss: 240.6440\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.7409 - val_loss: 225.1492\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.0651 - val_loss: 221.1656\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 202.7770 - val_loss: 213.1241\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.0448 - val_loss: 206.8731\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.2583 - val_loss: 201.6636\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.6425 - val_loss: 197.3814\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.1219 - val_loss: 192.8975\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.6248 - val_loss: 186.1944\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.7139 - val_loss: 188.4181\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.2783 - val_loss: 180.7490\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.8785 - val_loss: 177.7841\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.3709 - val_loss: 176.9618\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.5047 - val_loss: 171.6151\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.1795 - val_loss: 168.4971\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.2250 - val_loss: 174.3080\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.3986 - val_loss: 165.6810\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.9543 - val_loss: 162.7105\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.4381 - val_loss: 168.0170\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.9247 - val_loss: 160.5905\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.3871 - val_loss: 159.2488\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.8661 - val_loss: 161.5840\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.3350 - val_loss: 156.6551\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.6102 - val_loss: 156.7126\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.8979 - val_loss: 154.6108\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.5091 - val_loss: 156.3425\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.3369 - val_loss: 152.0125\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.4301 - val_loss: 151.4603\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.0182 - val_loss: 152.1668\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.8675 - val_loss: 153.4132\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.8644 - val_loss: 150.9874\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.3852 - val_loss: 148.8343\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.1516 - val_loss: 147.1967\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.3256 - val_loss: 148.8128\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.6479 - val_loss: 145.6236\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.1269 - val_loss: 146.3120\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.5004 - val_loss: 144.0332\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.5433 - val_loss: 145.1308\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.5085 - val_loss: 143.0259\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.8228 - val_loss: 147.0222\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.6952 - val_loss: 143.9249\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.8164 - val_loss: 143.1594\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.5371 - val_loss: 139.9245\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.9818 - val_loss: 150.8764\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.2033 - val_loss: 141.1855\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.3313 - val_loss: 141.0070\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.1840 - val_loss: 137.7926\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.5440 - val_loss: 138.5930\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.4875 - val_loss: 142.5228\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.8807 - val_loss: 136.3118\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.2099 - val_loss: 136.1144\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.3100 - val_loss: 135.3556\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 111.9183 - val_loss: 134.8194\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.2902 - val_loss: 133.8546\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.4760 - val_loss: 142.6650\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.2102 - val_loss: 133.5307\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 110.9162 - val_loss: 132.7476\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.4721 - val_loss: 138.1612\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7139 - val_loss: 131.8791\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.9045 - val_loss: 133.7773\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.9218 - val_loss: 130.8097\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.9323 - val_loss: 136.8694\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.2353 - val_loss: 132.1950\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.1528 - val_loss: 130.7214\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.9213 - val_loss: 129.1060\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.4590 - val_loss: 128.5008\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.8396 - val_loss: 134.2178\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.3685 - val_loss: 127.8584\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.6041 - val_loss: 127.8301\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2626 - val_loss: 129.9041\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.1544 - val_loss: 128.2420\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.0137 - val_loss: 133.0386\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.8524 - val_loss: 125.8501\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.7402 - val_loss: 127.7129\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.6963 - val_loss: 128.9353\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.0610 - val_loss: 124.5828\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.1907 - val_loss: 125.3499\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9605 - val_loss: 124.3125\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.7652 - val_loss: 127.3611\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.1770 - val_loss: 124.7939\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.7855 - val_loss: 123.3864\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.4486 - val_loss: 123.0186\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.7838 - val_loss: 123.0298\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  29 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 48075.9660 - val_loss: 20039.3203\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14504.4913 - val_loss: 4502.8394\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3147.8131 - val_loss: 967.7781\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 853.9661 - val_loss: 524.2575\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 587.1797 - val_loss: 483.6777\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 621.9700 - val_loss: 441.3173\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 458.3846 - val_loss: 406.6789\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 452.1975 - val_loss: 378.2582\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 456.5690 - val_loss: 352.8814\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.9687 - val_loss: 329.9214\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 375.1324 - val_loss: 310.9348\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 328.6050 - val_loss: 293.4228\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 362.3649 - val_loss: 278.7786\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 301.0079 - val_loss: 266.7589\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.2725 - val_loss: 256.2280\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.7141 - val_loss: 245.1217\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 287.7497 - val_loss: 235.0769\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.5675 - val_loss: 226.1707\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 270.1307 - val_loss: 217.9208\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.2774 - val_loss: 210.0650\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.9327 - val_loss: 203.2074\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.3563 - val_loss: 196.9293\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 237.4180 - val_loss: 191.0459\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.6466 - val_loss: 185.5658\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.3617 - val_loss: 181.1387\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.8682 - val_loss: 176.7367\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.9200 - val_loss: 172.5674\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.0687 - val_loss: 169.7171\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.3454 - val_loss: 164.8466\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.2991 - val_loss: 162.6004\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.5093 - val_loss: 158.0520\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.2225 - val_loss: 155.6536\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 167.5215 - val_loss: 152.7623\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.0363 - val_loss: 150.2123\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166.1300 - val_loss: 147.0920\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.9372 - val_loss: 144.4300\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.2273 - val_loss: 142.3425\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.8980 - val_loss: 139.2297\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.2436 - val_loss: 137.4251\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.0612 - val_loss: 136.3549\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.7089 - val_loss: 131.9348\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9368 - val_loss: 129.9592\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.9686 - val_loss: 129.6303\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 128.1891 - val_loss: 125.3660\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.4454 - val_loss: 124.2976\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.3488 - val_loss: 121.4248\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.9373 - val_loss: 119.6192\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.0011 - val_loss: 118.3717\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.2763 - val_loss: 114.8544\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.8639 - val_loss: 114.6744\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.3803 - val_loss: 111.9601\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.4056 - val_loss: 109.3204\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.6034 - val_loss: 109.4579\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.7356 - val_loss: 106.0633\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.3938 - val_loss: 104.2842\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5680 - val_loss: 103.0449\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.6068 - val_loss: 100.4279\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.1088 - val_loss: 99.7400\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.1602 - val_loss: 97.3329\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.4200 - val_loss: 95.9132\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.8636 - val_loss: 94.8957\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.3383 - val_loss: 93.4612\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.7882 - val_loss: 91.4912\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.5038 - val_loss: 91.2503\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 87.1875 - val_loss: 89.3756\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.4233 - val_loss: 88.1859\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.3403 - val_loss: 86.3609\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.6714 - val_loss: 85.8571\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.9424 - val_loss: 84.2799\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.8874 - val_loss: 83.3235\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.6190 - val_loss: 82.1454\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.3106 - val_loss: 81.6767\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.8350 - val_loss: 80.0119\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.3775 - val_loss: 79.1636\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 79.0546 - val_loss: 78.6930\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 76.9113 - val_loss: 77.5481\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 71.9746 - val_loss: 77.8920\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.2484 - val_loss: 76.3398\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 73.8518 - val_loss: 76.6877\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 73.1095 - val_loss: 75.1089\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 65.6180 - val_loss: 75.9008\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 64.1257 - val_loss: 74.4939\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 69.4433 - val_loss: 74.5268\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 62.0098 - val_loss: 73.2992\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 72.5999 - val_loss: 72.8476\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 62.8354 - val_loss: 73.2261\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 64.1915 - val_loss: 72.2115\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 60.2365 - val_loss: 72.1718\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 65.8698 - val_loss: 72.2679\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 63.3303 - val_loss: 71.1744\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 62.3810 - val_loss: 71.6523\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 70.2511 - val_loss: 70.7763\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 63.1097 - val_loss: 70.7750\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 62.7617 - val_loss: 71.9701\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 66.4056 - val_loss: 70.3297\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 60.5632 - val_loss: 70.0248\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 60.0175 - val_loss: 70.7170\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 60.1201 - val_loss: 69.7444\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 60.6715 - val_loss: 70.3223\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 57.4797 - val_loss: 69.8936\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  30 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 18ms/step - loss: 293.3974 - val_loss: 227.7438\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.8635 - val_loss: 209.0861\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.7546 - val_loss: 198.9498\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 194.3917 - val_loss: 190.1815\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.0390 - val_loss: 183.6308\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.9797 - val_loss: 175.7308\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 170.3490 - val_loss: 170.2288\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.2969 - val_loss: 164.4383\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.3368 - val_loss: 160.6204\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.4421 - val_loss: 154.6885\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.4336 - val_loss: 150.0052\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.5929 - val_loss: 155.9430\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.6637 - val_loss: 144.1113\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.5359 - val_loss: 139.3536\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.8608 - val_loss: 138.9129\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.2085 - val_loss: 132.1389\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.7725 - val_loss: 129.6690\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.4812 - val_loss: 125.2591\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.8323 - val_loss: 126.2397\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 126.4110 - val_loss: 120.0972\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.1165 - val_loss: 117.6811\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.1577 - val_loss: 116.1873\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.0946 - val_loss: 114.8185\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.3936 - val_loss: 112.1495\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.5861 - val_loss: 113.0883\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.4674 - val_loss: 109.5715\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.3952 - val_loss: 108.1861\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.3542 - val_loss: 113.1803\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.8591 - val_loss: 107.4483\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.0008 - val_loss: 104.8004\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.3004 - val_loss: 103.8969\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.2294 - val_loss: 106.2230\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.6684 - val_loss: 103.7125\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.7604 - val_loss: 105.7772\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.9973 - val_loss: 100.8566\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.3163 - val_loss: 99.9734\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.2919 - val_loss: 98.2417\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 99.1721 - val_loss: 99.2445\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.8421 - val_loss: 101.1553\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.3183 - val_loss: 96.9974\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.1828 - val_loss: 95.8037\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.2578 - val_loss: 93.4439\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.8210 - val_loss: 94.9402\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.0597 - val_loss: 92.0764\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.7455 - val_loss: 90.8656\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.2853 - val_loss: 89.9240\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.3554 - val_loss: 92.1355\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1574 - val_loss: 90.1811\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.3598 - val_loss: 91.5395\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.3725 - val_loss: 89.1285\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.7905 - val_loss: 92.8026\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.4585 - val_loss: 87.7716\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.4330 - val_loss: 86.7120\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.8670 - val_loss: 86.2774\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.0507 - val_loss: 88.2832\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.5859 - val_loss: 86.8842\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.8931 - val_loss: 87.6331\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.4972 - val_loss: 85.9884\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.1203 - val_loss: 84.2709\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.0278 - val_loss: 83.4018\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 95.3939 - val_loss: 82.6811\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1389 - val_loss: 82.4998\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 96.2381 - val_loss: 83.1027\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.5356 - val_loss: 81.4508\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.0643 - val_loss: 81.4343\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.6820 - val_loss: 84.6722\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.5486 - val_loss: 86.7791\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.0130 - val_loss: 80.7573\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.2443 - val_loss: 80.6299\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.5909 - val_loss: 83.4600\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.5163 - val_loss: 84.0377\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.8664 - val_loss: 85.2668\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.1742 - val_loss: 78.5684\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.4694 - val_loss: 82.6963\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.7588 - val_loss: 77.5229\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.0731 - val_loss: 77.2760\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.0681 - val_loss: 80.2217\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.2838 - val_loss: 76.2161\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.4021 - val_loss: 76.2009\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 75.3625 - val_loss: 75.5084\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.3680 - val_loss: 77.3262\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.3191 - val_loss: 83.6966\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.1648 - val_loss: 74.3290\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.9242 - val_loss: 79.1629\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.5048 - val_loss: 76.1250\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.5477 - val_loss: 71.9441\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.8430 - val_loss: 73.2660\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.3564 - val_loss: 71.6696\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.7765 - val_loss: 72.3368\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.4400 - val_loss: 70.8328\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 75.8359 - val_loss: 71.2087\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.6835 - val_loss: 71.1543\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 73.2921 - val_loss: 71.6382\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.9594 - val_loss: 70.6497\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.9398 - val_loss: 69.2189\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 74.0683 - val_loss: 68.9913\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.6149 - val_loss: 68.2732\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.0716 - val_loss: 68.1212\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.2906 - val_loss: 68.0635\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.6571 - val_loss: 66.8513\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  31 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 97940.8819 - val_loss: 54419.0664\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 45011.5873 - val_loss: 21742.1289\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 18037.0582 - val_loss: 10137.0850\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8968.4611 - val_loss: 6113.3442\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5604.5050 - val_loss: 3620.6167\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3256.6742 - val_loss: 2046.3811\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1719.3543 - val_loss: 1116.6382\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1064.8939 - val_loss: 620.3129\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 568.1002 - val_loss: 408.9793\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 421.7057 - val_loss: 332.0951\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 293.2124 - val_loss: 312.5513\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 293.0199 - val_loss: 307.6898\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 305.3140 - val_loss: 305.5248\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 287.5997 - val_loss: 303.1707\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.7747 - val_loss: 300.1826\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 279.5375 - val_loss: 296.8203\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 294.6650 - val_loss: 293.9713\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 279.4312 - val_loss: 291.2494\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.0402 - val_loss: 289.0174\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.5743 - val_loss: 286.7984\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 280.3574 - val_loss: 283.6211\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.5191 - val_loss: 281.1682\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 265.0167 - val_loss: 279.3084\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 256.6374 - val_loss: 276.7702\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.2782 - val_loss: 274.3331\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.9605 - val_loss: 272.0234\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.2987 - val_loss: 269.7594\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.1120 - val_loss: 268.1315\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.2443 - val_loss: 265.7964\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.8055 - val_loss: 264.0062\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.4995 - val_loss: 262.2679\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 245.4207 - val_loss: 259.9572\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.9656 - val_loss: 258.1075\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 249.7078 - val_loss: 256.3268\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.9412 - val_loss: 254.8487\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 229.1965 - val_loss: 252.4126\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.2238 - val_loss: 251.1016\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.6166 - val_loss: 249.7691\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 241.9410 - val_loss: 248.0938\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.0438 - val_loss: 245.8924\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.1098 - val_loss: 244.9204\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.7100 - val_loss: 243.0773\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.0249 - val_loss: 241.6015\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 226.0382 - val_loss: 239.9200\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 239.6926 - val_loss: 238.8984\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.3524 - val_loss: 237.0456\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.4685 - val_loss: 236.1343\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.2843 - val_loss: 234.7915\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.7994 - val_loss: 233.5586\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.6336 - val_loss: 232.0370\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.1986 - val_loss: 231.3039\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.7195 - val_loss: 229.6382\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.8403 - val_loss: 228.4468\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.1198 - val_loss: 226.9493\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.2263 - val_loss: 226.3715\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 225.1873 - val_loss: 224.8279\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.9584 - val_loss: 223.4993\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 229.6807 - val_loss: 222.3861\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.3793 - val_loss: 221.5601\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.4882 - val_loss: 219.8137\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 210.2604 - val_loss: 219.5644\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.3800 - val_loss: 217.6643\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.1418 - val_loss: 216.8533\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.5245 - val_loss: 215.8063\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 220.3629 - val_loss: 214.9752\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.3428 - val_loss: 213.1113\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.0985 - val_loss: 212.4908\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.6034 - val_loss: 211.8578\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.6134 - val_loss: 210.0996\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.6920 - val_loss: 208.9240\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.8090 - val_loss: 208.0694\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.1938 - val_loss: 207.9831\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 220.7155 - val_loss: 206.0134\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.9635 - val_loss: 204.7895\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.9846 - val_loss: 203.9256\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.1824 - val_loss: 203.8775\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 209.5011 - val_loss: 201.9241\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.3798 - val_loss: 201.3036\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.4078 - val_loss: 199.9854\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 203.0290 - val_loss: 199.1597\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.9523 - val_loss: 198.2504\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.2137 - val_loss: 197.8004\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.9813 - val_loss: 196.4409\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.4962 - val_loss: 195.2564\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 209.5155 - val_loss: 194.7460\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.5274 - val_loss: 193.9234\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.6154 - val_loss: 192.5948\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 206.1891 - val_loss: 192.5443\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.0196 - val_loss: 190.8820\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.7057 - val_loss: 190.2469\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.2522 - val_loss: 189.2099\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.3843 - val_loss: 188.8022\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.8145 - val_loss: 187.5263\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.2313 - val_loss: 186.8436\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.4874 - val_loss: 186.1201\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.0118 - val_loss: 185.3136\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.4272 - val_loss: 184.5749\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.2371 - val_loss: 183.4800\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.1382 - val_loss: 183.0515\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.8427 - val_loss: 181.9796\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  32 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 18ms/step - loss: 4485.4517 - val_loss: 1184.4603\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 919.0050 - val_loss: 975.9299\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 792.9302 - val_loss: 761.2836\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 608.9145 - val_loss: 634.4764\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 492.8124 - val_loss: 539.3116\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 486.6325 - val_loss: 499.9920\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 431.8963 - val_loss: 474.0701\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 382.3276 - val_loss: 459.5867\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.6159 - val_loss: 439.5935\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 366.1989 - val_loss: 426.2635\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 316.8136 - val_loss: 415.2973\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.6394 - val_loss: 403.1145\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 303.6552 - val_loss: 391.4577\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 317.1700 - val_loss: 382.8113\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 298.2323 - val_loss: 373.3584\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 295.3980 - val_loss: 364.2678\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.0806 - val_loss: 355.7030\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 275.2471 - val_loss: 348.8834\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 281.4121 - val_loss: 338.7755\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.8595 - val_loss: 331.3737\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.0760 - val_loss: 327.1713\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 271.6377 - val_loss: 317.4788\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.8801 - val_loss: 311.4255\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 262.3264 - val_loss: 305.5429\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 244.8510 - val_loss: 298.1282\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.2834 - val_loss: 293.2024\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.9841 - val_loss: 287.3924\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.3344 - val_loss: 281.8932\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.6554 - val_loss: 276.4259\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.9084 - val_loss: 269.6973\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.7722 - val_loss: 265.6681\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.0905 - val_loss: 260.0818\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.5897 - val_loss: 256.2172\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.6822 - val_loss: 251.1662\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.8991 - val_loss: 247.0252\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.7359 - val_loss: 242.1172\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.4036 - val_loss: 238.2635\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.2223 - val_loss: 234.2465\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 184.7858 - val_loss: 230.7338\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 206.5754 - val_loss: 227.4869\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 192.6880 - val_loss: 222.9119\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 205.2919 - val_loss: 219.8651\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.6353 - val_loss: 215.8927\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.6228 - val_loss: 213.5606\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.2798 - val_loss: 209.7588\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.5399 - val_loss: 208.3378\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.8841 - val_loss: 203.9080\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.7887 - val_loss: 201.3827\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.9643 - val_loss: 198.3452\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 165.4258 - val_loss: 195.8616\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.2483 - val_loss: 193.1754\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.3282 - val_loss: 190.6521\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.2838 - val_loss: 190.9985\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.8267 - val_loss: 186.1758\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.5134 - val_loss: 185.6407\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.9339 - val_loss: 181.7397\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.9667 - val_loss: 180.2853\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.5564 - val_loss: 178.3685\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.3146 - val_loss: 176.0523\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 150.3603 - val_loss: 175.7276\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.2826 - val_loss: 172.2943\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.5707 - val_loss: 170.7139\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.5743 - val_loss: 169.1954\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.6645 - val_loss: 168.0295\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.8805 - val_loss: 167.2606\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.1722 - val_loss: 165.9915\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.8637 - val_loss: 163.7751\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.9128 - val_loss: 162.8580\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.6328 - val_loss: 161.1427\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.1645 - val_loss: 161.1063\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.6628 - val_loss: 160.9883\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.8174 - val_loss: 158.4957\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.7947 - val_loss: 156.9306\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.6308 - val_loss: 155.9391\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.3072 - val_loss: 154.4361\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.4076 - val_loss: 152.4976\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.3595 - val_loss: 151.5611\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.3192 - val_loss: 151.4005\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.9515 - val_loss: 151.1557\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.8438 - val_loss: 151.9371\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 133.4665 - val_loss: 149.1875\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.0150 - val_loss: 147.0706\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.4094 - val_loss: 146.3315\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.6152 - val_loss: 145.7908\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.3601 - val_loss: 145.1046\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.5150 - val_loss: 145.3115\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.7433 - val_loss: 144.8454\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.6259 - val_loss: 143.1071\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.3413 - val_loss: 141.8243\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.5476 - val_loss: 141.2175\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.2659 - val_loss: 140.9795\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.7128 - val_loss: 139.7355\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.2411 - val_loss: 140.0987\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.9048 - val_loss: 138.7400\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.7977 - val_loss: 138.2549\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.3392 - val_loss: 137.8652\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.0895 - val_loss: 136.9116\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.6079 - val_loss: 137.8271\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.7111 - val_loss: 137.1744\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.0618 - val_loss: 135.5754\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  33 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 29ms/step - loss: 58432.8810 - val_loss: 21187.2148\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 13559.5584 - val_loss: 8798.2383\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6504.6377 - val_loss: 7395.1538\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5616.1251 - val_loss: 6474.4385\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4907.4773 - val_loss: 5840.2993\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4895.6998 - val_loss: 5339.5259\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 4349.3996 - val_loss: 4930.0586\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4130.0590 - val_loss: 4561.1196\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3589.3179 - val_loss: 4253.1787\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3541.6348 - val_loss: 3963.0315\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2997.8180 - val_loss: 3719.4766\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2870.5653 - val_loss: 3477.6697\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2738.9870 - val_loss: 3247.3098\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2767.7034 - val_loss: 3059.9314\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2280.1732 - val_loss: 2884.1516\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2543.7434 - val_loss: 2688.4844\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2040.1392 - val_loss: 2553.1814\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1883.9421 - val_loss: 2407.6086\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1974.5125 - val_loss: 2280.7722\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1882.2038 - val_loss: 2154.4397\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1861.6647 - val_loss: 2029.7990\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1552.5396 - val_loss: 1923.8130\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1520.9118 - val_loss: 1821.4839\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1450.8295 - val_loss: 1729.6207\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1420.6062 - val_loss: 1632.8765\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1316.5258 - val_loss: 1556.4126\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1134.0576 - val_loss: 1460.4303\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1180.7656 - val_loss: 1378.8623\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1049.8217 - val_loss: 1290.7427\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1065.5497 - val_loss: 1200.4906\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 899.4765 - val_loss: 1115.5115\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 950.8449 - val_loss: 1025.1189\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 891.4096 - val_loss: 957.0640\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 785.2840 - val_loss: 881.0115\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 655.6733 - val_loss: 814.8837\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 680.8122 - val_loss: 751.0387\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 605.5001 - val_loss: 692.9339\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 576.7221 - val_loss: 646.7922\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 550.4309 - val_loss: 598.3835\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 487.8362 - val_loss: 562.3777\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 484.2945 - val_loss: 525.0985\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 473.1228 - val_loss: 494.4119\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 433.3481 - val_loss: 464.1719\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 422.2103 - val_loss: 439.7190\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 384.9173 - val_loss: 420.8038\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 355.8225 - val_loss: 400.3733\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.5608 - val_loss: 383.3181\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 325.8829 - val_loss: 365.4689\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 331.6414 - val_loss: 350.8266\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 301.9001 - val_loss: 338.3941\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 322.4163 - val_loss: 325.0794\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.7561 - val_loss: 313.2157\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.0735 - val_loss: 301.3574\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.5493 - val_loss: 292.1852\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.8791 - val_loss: 282.7160\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.4156 - val_loss: 274.3832\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.3499 - val_loss: 266.7302\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 260.9304 - val_loss: 257.9408\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 237.0791 - val_loss: 250.2739\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.1173 - val_loss: 242.2603\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.7293 - val_loss: 236.8143\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.4971 - val_loss: 228.3145\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.5633 - val_loss: 222.0138\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.0305 - val_loss: 217.2557\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.2776 - val_loss: 213.4452\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.1628 - val_loss: 211.4534\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.6892 - val_loss: 205.2148\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.9519 - val_loss: 201.0551\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 206.9169 - val_loss: 196.0253\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.6658 - val_loss: 192.6615\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.8519 - val_loss: 189.4998\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.6643 - val_loss: 187.3671\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.1446 - val_loss: 184.5095\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.5511 - val_loss: 180.6356\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.5683 - val_loss: 179.1123\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.3709 - val_loss: 176.0383\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 181.3164 - val_loss: 172.4686\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.2314 - val_loss: 170.9043\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.5302 - val_loss: 168.9872\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.2289 - val_loss: 166.5030\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.8957 - val_loss: 165.1616\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.1096 - val_loss: 163.0230\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.5141 - val_loss: 161.2212\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.7287 - val_loss: 159.9158\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.4752 - val_loss: 159.0378\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.1305 - val_loss: 158.3033\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 178.8486 - val_loss: 158.5935\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.9494 - val_loss: 156.9967\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.4903 - val_loss: 154.2861\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.3278 - val_loss: 154.1215\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.9431 - val_loss: 152.5228\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.8068 - val_loss: 156.2255\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.3061 - val_loss: 164.3073\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.2797 - val_loss: 151.8634\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.0363 - val_loss: 150.6957\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.1417 - val_loss: 147.8104\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.2211 - val_loss: 147.5529\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.2993 - val_loss: 148.9199\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.4880 - val_loss: 145.2617\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.6911 - val_loss: 143.9471\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  34 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 20ms/step - loss: 126571.6576 - val_loss: 80200.8047\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 70003.7472 - val_loss: 44045.8555\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 37070.7649 - val_loss: 23081.9785\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 19457.8974 - val_loss: 11394.6846\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8986.1747 - val_loss: 5056.6948\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3726.1108 - val_loss: 1955.0311\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 1445.2251 - val_loss: 782.5181\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 608.3149 - val_loss: 506.1323\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 402.1266 - val_loss: 466.7074\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 353.8216 - val_loss: 461.6765\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 368.7598 - val_loss: 459.4285\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 361.3842 - val_loss: 457.2632\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.6776 - val_loss: 455.2733\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 333.2804 - val_loss: 452.4165\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 328.8743 - val_loss: 449.9738\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 344.0699 - val_loss: 446.7067\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 352.2340 - val_loss: 443.5515\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.7068 - val_loss: 441.6165\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 323.3735 - val_loss: 438.2153\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 323.0855 - val_loss: 435.7698\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 330.4016 - val_loss: 432.9193\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 322.6322 - val_loss: 428.0189\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 330.8760 - val_loss: 426.2426\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 354.1589 - val_loss: 424.0820\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.1505 - val_loss: 420.3444\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 305.1626 - val_loss: 416.4735\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 328.7785 - val_loss: 414.8992\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 323.3463 - val_loss: 410.3729\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 340.3341 - val_loss: 407.9852\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 310.9824 - val_loss: 405.0688\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 313.2820 - val_loss: 401.9157\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 282.8701 - val_loss: 400.1322\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 307.2228 - val_loss: 396.9622\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.5523 - val_loss: 393.1059\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.0345 - val_loss: 389.5372\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 313.0057 - val_loss: 386.3073\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 317.0452 - val_loss: 385.4934\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 297.1391 - val_loss: 382.2048\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 337.3785 - val_loss: 380.2424\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.8171 - val_loss: 377.1595\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 290.4109 - val_loss: 375.4649\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 310.1735 - val_loss: 371.2400\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 310.3972 - val_loss: 369.3284\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 290.5384 - val_loss: 366.7837\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.2660 - val_loss: 363.7164\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 277.7505 - val_loss: 362.6710\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.8426 - val_loss: 359.7438\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 267.9934 - val_loss: 355.5871\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.2454 - val_loss: 353.5130\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 292.8654 - val_loss: 350.6891\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 322.8404 - val_loss: 347.2363\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.9720 - val_loss: 346.6633\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 273.8392 - val_loss: 341.8939\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.1508 - val_loss: 339.7111\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 245.0308 - val_loss: 336.8112\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.8579 - val_loss: 334.0653\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.6511 - val_loss: 333.6373\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.0799 - val_loss: 328.4421\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.9809 - val_loss: 327.3837\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.7612 - val_loss: 323.9405\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.8036 - val_loss: 321.5661\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 220.5693 - val_loss: 317.4519\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.1764 - val_loss: 317.7897\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 243.4569 - val_loss: 312.9331\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.9372 - val_loss: 313.3625\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.9400 - val_loss: 308.8349\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.6034 - val_loss: 305.3455\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.7992 - val_loss: 304.9175\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.5908 - val_loss: 301.3629\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.6944 - val_loss: 301.1935\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 216.5584 - val_loss: 295.5142\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.7329 - val_loss: 295.7491\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.8269 - val_loss: 291.7051\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.0568 - val_loss: 290.8466\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.8527 - val_loss: 288.3345\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.0404 - val_loss: 285.0248\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.8802 - val_loss: 282.3859\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.1952 - val_loss: 280.5404\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 204.4548 - val_loss: 277.4980\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.8138 - val_loss: 274.3627\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.7372 - val_loss: 271.7534\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 187.6400 - val_loss: 269.5324\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 214.1466 - val_loss: 266.1354\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.2507 - val_loss: 262.6833\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.7132 - val_loss: 261.1577\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 206.2892 - val_loss: 257.4071\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.9893 - val_loss: 256.0442\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.5012 - val_loss: 252.8674\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.0169 - val_loss: 249.1035\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.7583 - val_loss: 246.8133\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.5139 - val_loss: 243.0789\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.2961 - val_loss: 242.7316\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.6318 - val_loss: 239.1979\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.9836 - val_loss: 236.7848\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.2676 - val_loss: 234.5895\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.6112 - val_loss: 231.7453\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.8542 - val_loss: 231.9568\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.1620 - val_loss: 226.9773\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 162.7621 - val_loss: 227.1088\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.4138 - val_loss: 225.2908\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  35 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 8600.9145 - val_loss: 4670.6069\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3890.1138 - val_loss: 2301.8237\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1999.4068 - val_loss: 1135.1028\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 924.2384 - val_loss: 570.9790\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 551.2516 - val_loss: 429.2448\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 488.5670 - val_loss: 396.6104\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 437.4675 - val_loss: 378.0056\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 367.4422 - val_loss: 367.1970\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 370.7465 - val_loss: 359.3105\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 366.1884 - val_loss: 353.3792\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 363.7222 - val_loss: 348.3604\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 341.7653 - val_loss: 344.0390\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 309.5302 - val_loss: 340.4449\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 318.7919 - val_loss: 337.5026\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 347.4809 - val_loss: 333.5325\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 324.6484 - val_loss: 330.5538\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 319.5135 - val_loss: 328.1614\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 341.4773 - val_loss: 324.2921\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 317.3348 - val_loss: 322.1278\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 298.4923 - val_loss: 318.5559\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 329.6968 - val_loss: 315.6197\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 310.7924 - val_loss: 312.9746\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 304.9003 - val_loss: 310.2644\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 322.1026 - val_loss: 306.9444\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 292.7957 - val_loss: 304.4861\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 296.5811 - val_loss: 301.3018\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 325.9576 - val_loss: 298.7870\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.9855 - val_loss: 294.4425\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.1166 - val_loss: 290.3453\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 283.4791 - val_loss: 284.3713\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 283.4126 - val_loss: 278.3166\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 286.5450 - val_loss: 270.5796\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.2872 - val_loss: 263.8651\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 254.8964 - val_loss: 254.3318\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 240.4408 - val_loss: 244.7406\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.2800 - val_loss: 233.5868\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.7275 - val_loss: 222.0739\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.0419 - val_loss: 211.8112\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.5250 - val_loss: 204.4022\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.9885 - val_loss: 191.5663\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.2763 - val_loss: 180.7838\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.9551 - val_loss: 171.1707\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.9306 - val_loss: 162.8355\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.4744 - val_loss: 154.7708\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.5721 - val_loss: 145.9165\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.4381 - val_loss: 138.3565\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 141.6604 - val_loss: 132.1969\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.2367 - val_loss: 126.1921\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.5397 - val_loss: 120.8260\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 113.3363 - val_loss: 116.0851\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.1380 - val_loss: 111.3619\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.7536 - val_loss: 107.3036\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 115.8802 - val_loss: 104.0797\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 112.8819 - val_loss: 102.1114\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.3565 - val_loss: 100.4699\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.7790 - val_loss: 101.7667\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.1209 - val_loss: 94.8719\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.2683 - val_loss: 94.4228\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.6504 - val_loss: 93.6708\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.5110 - val_loss: 90.9313\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.3576 - val_loss: 89.2382\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.6659 - val_loss: 89.2178\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.2058 - val_loss: 87.0761\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.7471 - val_loss: 86.1445\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.2280 - val_loss: 85.5181\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 88.1063 - val_loss: 85.1966\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.7105 - val_loss: 84.2883\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.4634 - val_loss: 85.0319\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.7774 - val_loss: 84.0820\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.7768 - val_loss: 82.1278\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.5852 - val_loss: 81.6084\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.2011 - val_loss: 84.0583\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.5123 - val_loss: 82.8763\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.7804 - val_loss: 81.0173\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.3898 - val_loss: 79.3672\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.0371 - val_loss: 78.3930\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.7292 - val_loss: 77.7811\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.9166 - val_loss: 77.9303\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.9060 - val_loss: 82.3038\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.9982 - val_loss: 76.5852\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.6548 - val_loss: 77.0806\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.7548 - val_loss: 76.0354\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.6780 - val_loss: 77.0324\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.4330 - val_loss: 75.6769\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 80.8399 - val_loss: 75.7239\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.1583 - val_loss: 75.2905\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.2000 - val_loss: 80.2548\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.6753 - val_loss: 74.4279\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.9999 - val_loss: 74.7708\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.7192 - val_loss: 74.7870\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.8614 - val_loss: 73.8921\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.1182 - val_loss: 74.3841\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.2666 - val_loss: 74.1047\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.0222 - val_loss: 73.5136\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.4496 - val_loss: 73.3301\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 71.4310 - val_loss: 74.3883\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.8825 - val_loss: 73.3951\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.8959 - val_loss: 72.9408\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.7651 - val_loss: 73.0867\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.6379 - val_loss: 72.1497\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  36 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 20ms/step - loss: 143139.8511 - val_loss: 68935.8281\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 55821.3996 - val_loss: 22117.1484\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 17930.8184 - val_loss: 4973.7280\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3724.8081 - val_loss: 2016.8784\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1785.7072 - val_loss: 2059.7703\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1688.7982 - val_loss: 1894.4854\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1551.4510 - val_loss: 1742.3092\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1426.3892 - val_loss: 1660.3591\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1416.7653 - val_loss: 1600.1552\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1298.7284 - val_loss: 1549.6000\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1414.3560 - val_loss: 1496.1514\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1308.3385 - val_loss: 1438.9205\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1224.3689 - val_loss: 1390.0264\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1144.5907 - val_loss: 1337.8905\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1204.1522 - val_loss: 1293.3077\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1260.6571 - val_loss: 1255.7283\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1125.2748 - val_loss: 1224.8240\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1096.4660 - val_loss: 1188.6417\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1030.8661 - val_loss: 1147.1624\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1095.2608 - val_loss: 1107.2444\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1019.5330 - val_loss: 1087.9435\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 959.0786 - val_loss: 1045.9053\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 870.8915 - val_loss: 1019.3164\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 821.8276 - val_loss: 987.2027\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 849.7959 - val_loss: 960.7326\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 873.9863 - val_loss: 939.7972\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 774.2452 - val_loss: 904.7421\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 713.8202 - val_loss: 890.2032\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 790.3228 - val_loss: 865.4823\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 726.2448 - val_loss: 841.0284\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 741.9915 - val_loss: 825.0541\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 690.0992 - val_loss: 803.7512\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 680.3391 - val_loss: 786.2090\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 724.0232 - val_loss: 762.5199\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 678.6907 - val_loss: 746.4913\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 617.6661 - val_loss: 737.6440\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 687.8458 - val_loss: 713.5458\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 702.9906 - val_loss: 695.8513\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 641.8584 - val_loss: 685.6904\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 623.2192 - val_loss: 670.3370\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 580.3859 - val_loss: 649.4845\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 573.1031 - val_loss: 639.5513\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 629.5430 - val_loss: 625.1166\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 588.4097 - val_loss: 611.9909\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 579.5409 - val_loss: 599.4841\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 546.2008 - val_loss: 587.7219\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 544.2996 - val_loss: 575.2717\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 531.4317 - val_loss: 566.0109\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 570.6640 - val_loss: 549.9680\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 509.4080 - val_loss: 540.5811\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 536.9239 - val_loss: 532.1797\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 458.3255 - val_loss: 518.3176\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 463.4941 - val_loss: 510.7144\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 500.8295 - val_loss: 498.7842\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 460.4071 - val_loss: 490.7679\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 430.8243 - val_loss: 480.2861\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 407.0803 - val_loss: 473.0192\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 461.4572 - val_loss: 459.6857\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 445.8256 - val_loss: 455.8963\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 420.6963 - val_loss: 444.0708\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 443.9511 - val_loss: 438.3385\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 437.1562 - val_loss: 426.7576\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 411.7157 - val_loss: 420.3929\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 409.0573 - val_loss: 411.1326\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.0663 - val_loss: 403.7603\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 363.6454 - val_loss: 395.5178\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 414.7440 - val_loss: 389.7050\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 357.8597 - val_loss: 380.6288\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 370.7803 - val_loss: 375.4010\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 330.8587 - val_loss: 368.5886\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 341.4773 - val_loss: 361.0687\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 346.1082 - val_loss: 355.7946\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 351.1676 - val_loss: 347.9445\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.9193 - val_loss: 341.6337\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 322.1756 - val_loss: 337.4764\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 318.4490 - val_loss: 329.7766\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 326.0502 - val_loss: 324.9190\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 314.5181 - val_loss: 318.7100\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 315.8997 - val_loss: 315.4888\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.2555 - val_loss: 309.2681\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 321.8212 - val_loss: 303.6909\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 298.9161 - val_loss: 298.9006\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 294.7434 - val_loss: 293.3169\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.4235 - val_loss: 290.2471\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.2793 - val_loss: 284.5749\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 256.1261 - val_loss: 280.2329\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.5203 - val_loss: 275.3679\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 262.4728 - val_loss: 272.2260\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 239.0445 - val_loss: 267.6913\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.4498 - val_loss: 262.0883\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.1608 - val_loss: 259.2586\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 254.2094 - val_loss: 255.1996\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.2507 - val_loss: 250.7755\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 252.0500 - val_loss: 247.4939\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 237.7770 - val_loss: 243.4505\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.9906 - val_loss: 239.9422\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.8863 - val_loss: 235.9149\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 239.6855 - val_loss: 232.6110\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.9916 - val_loss: 229.4930\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.5557 - val_loss: 226.2175\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  37 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 18ms/step - loss: 65334.2585 - val_loss: 16088.4502\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13713.4755 - val_loss: 11982.3906\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 11310.9607 - val_loss: 7172.3501\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6211.2300 - val_loss: 3983.7175\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3628.1889 - val_loss: 2768.1072\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2626.7168 - val_loss: 2231.3118\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2220.1466 - val_loss: 1918.3300\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1761.8993 - val_loss: 1683.1332\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1629.2768 - val_loss: 1492.3274\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1299.4836 - val_loss: 1334.2593\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1195.1094 - val_loss: 1208.1448\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1124.1799 - val_loss: 1082.4067\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1076.3928 - val_loss: 975.7647\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 897.4660 - val_loss: 889.7215\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 831.0077 - val_loss: 809.1841\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 828.1543 - val_loss: 733.9035\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 717.6399 - val_loss: 671.0946\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 668.1397 - val_loss: 617.8652\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 567.2166 - val_loss: 565.4734\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 533.7768 - val_loss: 516.5188\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 470.1656 - val_loss: 470.4577\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 448.7972 - val_loss: 439.3980\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 430.1401 - val_loss: 393.0065\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 389.1692 - val_loss: 364.3878\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 335.8602 - val_loss: 320.7558\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 321.5032 - val_loss: 290.5836\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 269.4358 - val_loss: 271.4002\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.2187 - val_loss: 240.5519\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.7028 - val_loss: 219.7395\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.8386 - val_loss: 196.5225\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.4449 - val_loss: 179.3097\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.7171 - val_loss: 162.1242\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.4107 - val_loss: 154.9917\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.0280 - val_loss: 137.2710\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.1151 - val_loss: 132.6690\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.8643 - val_loss: 129.5298\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.6778 - val_loss: 127.3723\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.9619 - val_loss: 123.3347\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.7883 - val_loss: 120.0980\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.6060 - val_loss: 117.9329\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.8080 - val_loss: 120.6731\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.1601 - val_loss: 115.5319\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 113.3447 - val_loss: 115.2287\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.7022 - val_loss: 114.3243\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2590 - val_loss: 113.4902\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.2656 - val_loss: 115.7015\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.1650 - val_loss: 112.9245\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.8132 - val_loss: 113.6750\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.0864 - val_loss: 114.3586\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.9314 - val_loss: 112.6273\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.1498 - val_loss: 116.1394\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.5786 - val_loss: 122.7785\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.2970 - val_loss: 119.1897\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.7830 - val_loss: 112.5463\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.4033 - val_loss: 111.7612\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.2823 - val_loss: 112.6683\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.8108 - val_loss: 113.0789\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.1734 - val_loss: 110.6269\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.8632 - val_loss: 109.9803\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.3746 - val_loss: 109.4006\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.3529 - val_loss: 109.2462\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.9506 - val_loss: 113.8569\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.2018 - val_loss: 114.8815\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.4717 - val_loss: 109.8276\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.8552 - val_loss: 111.0166\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.7286 - val_loss: 111.7895\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.3743 - val_loss: 118.1222\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 101.0731 - val_loss: 124.8527\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.9643 - val_loss: 108.5091\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.8061 - val_loss: 107.8792\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.7293 - val_loss: 108.5369\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.1129 - val_loss: 110.8208\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.4432 - val_loss: 107.4346\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.1545 - val_loss: 110.5572\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.4668 - val_loss: 108.7726\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.4758 - val_loss: 107.1625\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.2410 - val_loss: 107.4514\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.0837 - val_loss: 111.6661\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 86.1140 - val_loss: 113.8721\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.8707 - val_loss: 106.5125\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.8108 - val_loss: 108.1504\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.7199 - val_loss: 106.4813\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1493 - val_loss: 106.6278\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.7910 - val_loss: 110.0976\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.3273 - val_loss: 105.9379\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.2940 - val_loss: 105.3107\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.6284 - val_loss: 105.3994\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.8923 - val_loss: 105.2173\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.1614 - val_loss: 105.6922\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.7469 - val_loss: 107.3529\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.9530 - val_loss: 114.1646\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.3558 - val_loss: 103.5113\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.2283 - val_loss: 110.2919\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.0764 - val_loss: 106.1357\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.8340 - val_loss: 103.2518\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.1362 - val_loss: 102.3143\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.7833 - val_loss: 103.4990\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.2018 - val_loss: 101.9585\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.9870 - val_loss: 102.1048\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.1215 - val_loss: 118.3277\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  38 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 31ms/step - loss: 6366.8152 - val_loss: 4006.9160\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 3382.1748 - val_loss: 2705.0679\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2292.7485 - val_loss: 1454.3540\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1139.7624 - val_loss: 853.5193\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 774.9995 - val_loss: 638.2549\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 617.6867 - val_loss: 488.4049\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 448.9197 - val_loss: 365.9185\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 368.9630 - val_loss: 292.3951\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.7425 - val_loss: 244.9997\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 241.2385 - val_loss: 222.0903\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.5937 - val_loss: 203.9837\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.6098 - val_loss: 196.9255\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 203.5313 - val_loss: 214.3931\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 193.9425 - val_loss: 194.7035\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.8533 - val_loss: 190.9581\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.9995 - val_loss: 190.3619\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.8391 - val_loss: 190.3656\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.8966 - val_loss: 186.2542\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.7937 - val_loss: 181.4902\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.5036 - val_loss: 179.0242\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.4811 - val_loss: 177.4382\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 167.7954 - val_loss: 176.0186\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.3437 - val_loss: 172.0545\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.1494 - val_loss: 170.6983\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.7503 - val_loss: 168.8635\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.5465 - val_loss: 169.6473\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.9302 - val_loss: 165.0707\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.2555 - val_loss: 164.8544\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.0410 - val_loss: 159.2715\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.1274 - val_loss: 157.1491\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.2554 - val_loss: 154.1796\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.5361 - val_loss: 152.5311\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.1728 - val_loss: 151.2125\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.0270 - val_loss: 148.9283\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.1264 - val_loss: 148.2065\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.1423 - val_loss: 143.7747\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.1447 - val_loss: 142.3499\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.3982 - val_loss: 141.1925\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.4208 - val_loss: 144.0684\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.8734 - val_loss: 139.4660\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.1093 - val_loss: 136.9185\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.5095 - val_loss: 133.6075\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 123.7335 - val_loss: 132.6371\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.8316 - val_loss: 135.6483\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.1924 - val_loss: 131.2176\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.5853 - val_loss: 128.7926\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.9919 - val_loss: 132.1679\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.5061 - val_loss: 129.4123\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.6987 - val_loss: 127.0136\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.4070 - val_loss: 131.0690\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.0235 - val_loss: 132.5953\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.1636 - val_loss: 125.6261\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.1780 - val_loss: 124.7211\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.5856 - val_loss: 129.3739\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.6393 - val_loss: 137.2626\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.5486 - val_loss: 125.0333\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.8580 - val_loss: 125.2712\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.9360 - val_loss: 125.5357\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.2199 - val_loss: 124.1245\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.4204 - val_loss: 123.3454\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.3829 - val_loss: 125.6941\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.9980 - val_loss: 123.0097\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.2893 - val_loss: 126.2481\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.6742 - val_loss: 122.6936\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.1614 - val_loss: 122.8431\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.2141 - val_loss: 123.3207\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 112.7136 - val_loss: 123.2904\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.3181 - val_loss: 126.5301\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.5957 - val_loss: 137.8373\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5052 - val_loss: 121.8790\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.5322 - val_loss: 122.0388\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.4295 - val_loss: 122.0775\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.5473 - val_loss: 122.4553\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.4170 - val_loss: 125.6953\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.9465 - val_loss: 124.0453\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.3870 - val_loss: 123.2474\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.5354 - val_loss: 123.6948\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.0647 - val_loss: 130.7908\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.3849 - val_loss: 121.9139\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.2360 - val_loss: 121.4544\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.4783 - val_loss: 121.4715\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.5476 - val_loss: 121.0116\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.8242 - val_loss: 121.2135\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.1150 - val_loss: 122.0885\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.2575 - val_loss: 120.8654\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.2217 - val_loss: 127.3686\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.1158 - val_loss: 122.4918\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.6083 - val_loss: 121.0545\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 106.5552 - val_loss: 122.5130\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.6481 - val_loss: 120.4824\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7266 - val_loss: 121.4082\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2619 - val_loss: 120.5116\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.1270 - val_loss: 120.2905\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.3802 - val_loss: 120.6961\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.9488 - val_loss: 138.9432\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.8141 - val_loss: 120.0744\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.2972 - val_loss: 137.8199\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9240 - val_loss: 120.8526\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.0773 - val_loss: 121.7769\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.2763 - val_loss: 126.7117\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  39 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 502656.7555 - val_loss: 402569.0312\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 370826.2721 - val_loss: 282895.6250\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258063.8226 - val_loss: 188512.8281\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165639.1903 - val_loss: 113737.1797\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94854.7160 - val_loss: 58722.1055\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 46433.2358 - val_loss: 25328.4238\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 19184.1976 - val_loss: 10162.4922\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 7503.4422 - val_loss: 6509.1401\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 5321.6204 - val_loss: 5887.4712\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5022.2194 - val_loss: 5371.8267\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4755.4972 - val_loss: 4948.1357\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4077.1836 - val_loss: 4548.1626\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3473.2790 - val_loss: 4184.0107\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3424.7057 - val_loss: 3839.9280\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2963.9062 - val_loss: 3534.7576\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2986.6268 - val_loss: 3252.5557\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2617.6562 - val_loss: 3001.6997\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2528.7473 - val_loss: 2779.1584\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2349.6302 - val_loss: 2580.3647\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2145.1968 - val_loss: 2416.0339\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1987.3485 - val_loss: 2268.6746\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2063.7310 - val_loss: 2129.5618\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1747.0255 - val_loss: 2004.0106\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1704.2998 - val_loss: 1897.6312\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1524.3244 - val_loss: 1812.4144\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1510.8333 - val_loss: 1736.3051\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1383.5036 - val_loss: 1674.9583\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1418.7286 - val_loss: 1618.9895\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1447.5160 - val_loss: 1567.9778\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1397.8400 - val_loss: 1528.1035\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1353.3711 - val_loss: 1492.0142\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1269.4618 - val_loss: 1459.9984\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1244.6270 - val_loss: 1432.3632\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1339.0546 - val_loss: 1399.7101\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1233.0827 - val_loss: 1369.3214\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 1132.7032 - val_loss: 1341.4631\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1120.3791 - val_loss: 1314.1429\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1179.6973 - val_loss: 1288.5763\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1086.9949 - val_loss: 1265.8333\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1172.5561 - val_loss: 1245.2814\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1128.7291 - val_loss: 1226.4717\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1109.8158 - val_loss: 1208.0753\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1018.9105 - val_loss: 1190.1910\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1083.8056 - val_loss: 1173.0023\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1111.8853 - val_loss: 1155.3652\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1035.1260 - val_loss: 1140.5604\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 991.8129 - val_loss: 1122.9771\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1010.1650 - val_loss: 1108.0620\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 942.5650 - val_loss: 1092.2701\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 922.8598 - val_loss: 1077.8313\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1014.0052 - val_loss: 1060.9004\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 993.3270 - val_loss: 1047.8044\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 926.2453 - val_loss: 1032.1730\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 947.0688 - val_loss: 1017.5544\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 879.9365 - val_loss: 1005.6770\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 888.8248 - val_loss: 990.4070\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 869.2699 - val_loss: 976.4659\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 824.9991 - val_loss: 963.9976\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 890.6306 - val_loss: 951.0900\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 871.0160 - val_loss: 939.3123\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 820.5178 - val_loss: 927.2896\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 809.2264 - val_loss: 914.9688\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 848.3978 - val_loss: 902.4538\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 850.8628 - val_loss: 892.0251\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 758.0552 - val_loss: 881.8224\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 841.1897 - val_loss: 871.5240\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 800.3911 - val_loss: 860.3077\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 861.5754 - val_loss: 849.1146\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 735.5661 - val_loss: 840.1083\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 743.5387 - val_loss: 830.7386\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 745.6179 - val_loss: 819.5934\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 726.3058 - val_loss: 810.3094\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 724.8333 - val_loss: 800.5201\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 736.6170 - val_loss: 791.0264\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 689.6259 - val_loss: 781.9478\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 693.0793 - val_loss: 772.6979\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 764.8477 - val_loss: 761.8348\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 699.0529 - val_loss: 753.0777\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 647.4896 - val_loss: 745.9684\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 667.8840 - val_loss: 735.9290\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 698.9569 - val_loss: 726.5926\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 702.0304 - val_loss: 717.5376\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 701.7076 - val_loss: 709.5949\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 654.9896 - val_loss: 700.7169\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 676.8463 - val_loss: 691.6601\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 638.7618 - val_loss: 684.0280\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 662.4447 - val_loss: 675.6519\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 635.8060 - val_loss: 667.8409\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 608.1335 - val_loss: 660.3401\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 622.0889 - val_loss: 652.7899\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 633.4279 - val_loss: 645.1998\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 569.4195 - val_loss: 635.9303\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 605.3897 - val_loss: 628.6470\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 609.1556 - val_loss: 620.7829\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 518.6517 - val_loss: 613.9603\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 572.9935 - val_loss: 607.1013\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 633.1811 - val_loss: 599.5961\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 557.1200 - val_loss: 592.9219\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 547.2298 - val_loss: 586.2290\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 542.5196 - val_loss: 579.3052\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  40 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 714938.1875 - val_loss: 529375.0625\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 476830.0643 - val_loss: 338386.8125\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 297863.8217 - val_loss: 200501.5781\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171136.7050 - val_loss: 104341.2812\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87159.3810 - val_loss: 44843.6133\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 34614.4629 - val_loss: 16046.2939\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 12587.6116 - val_loss: 6690.9751\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6040.1162 - val_loss: 4714.7041\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4516.1830 - val_loss: 4284.3740\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3953.0561 - val_loss: 4018.9197\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4237.8579 - val_loss: 3764.3535\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3637.6871 - val_loss: 3537.1086\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3603.9398 - val_loss: 3325.1060\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3144.4600 - val_loss: 3122.9568\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2999.3815 - val_loss: 2941.7327\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2969.4677 - val_loss: 2766.9937\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2751.6018 - val_loss: 2615.2832\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2341.6462 - val_loss: 2475.7522\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2470.7331 - val_loss: 2333.0364\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2311.9659 - val_loss: 2209.5210\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2137.1163 - val_loss: 2094.9917\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2100.6783 - val_loss: 1986.8359\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2008.1596 - val_loss: 1888.6730\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1737.2435 - val_loss: 1794.5190\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1758.6973 - val_loss: 1704.0868\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1701.6298 - val_loss: 1620.8568\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1562.2577 - val_loss: 1544.7140\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1635.3266 - val_loss: 1470.2218\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1413.6758 - val_loss: 1403.9486\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1374.5209 - val_loss: 1340.2974\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1335.0516 - val_loss: 1279.3365\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1160.5194 - val_loss: 1224.1183\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1200.8977 - val_loss: 1169.8087\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1115.7708 - val_loss: 1120.6980\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1138.7695 - val_loss: 1072.8463\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 1071.1564 - val_loss: 1028.4550\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1088.7628 - val_loss: 985.6558\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 981.7521 - val_loss: 947.5217\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 950.6302 - val_loss: 910.8769\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 959.1282 - val_loss: 874.0530\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 828.4061 - val_loss: 841.9976\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 796.4579 - val_loss: 810.7655\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 802.7853 - val_loss: 780.6196\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 806.2183 - val_loss: 752.8473\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 749.8743 - val_loss: 726.9993\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 644.4661 - val_loss: 702.7891\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 651.8838 - val_loss: 679.3798\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 670.0811 - val_loss: 656.9935\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 662.5230 - val_loss: 634.8813\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 619.3765 - val_loss: 614.9525\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 566.0684 - val_loss: 595.9342\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 568.8853 - val_loss: 579.1450\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 541.0196 - val_loss: 560.3414\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 587.6807 - val_loss: 543.6808\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 527.7606 - val_loss: 528.1830\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 520.6805 - val_loss: 513.8513\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 497.4150 - val_loss: 501.8413\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 473.0764 - val_loss: 486.1021\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 497.3176 - val_loss: 473.2486\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 433.3873 - val_loss: 461.5995\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 434.4333 - val_loss: 451.2332\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 425.3511 - val_loss: 438.6649\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 424.1389 - val_loss: 429.7272\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 392.0580 - val_loss: 418.4766\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 413.4197 - val_loss: 409.1925\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 387.5945 - val_loss: 399.7039\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 399.7443 - val_loss: 392.9439\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 404.4362 - val_loss: 382.4654\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 385.8767 - val_loss: 375.1504\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 369.5683 - val_loss: 367.3926\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 361.1921 - val_loss: 360.5297\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 374.0049 - val_loss: 353.1288\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 326.8672 - val_loss: 345.7402\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 345.6621 - val_loss: 341.4749\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 354.9468 - val_loss: 333.0897\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 321.4241 - val_loss: 327.9537\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 293.6063 - val_loss: 322.0070\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 303.4807 - val_loss: 316.3922\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 313.9417 - val_loss: 311.1218\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.6312 - val_loss: 306.9711\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 300.5278 - val_loss: 301.2878\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 271.4525 - val_loss: 296.5685\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.0809 - val_loss: 292.2368\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 282.2999 - val_loss: 288.2739\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 280.6709 - val_loss: 282.7378\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 267.6926 - val_loss: 279.2053\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.0651 - val_loss: 275.3729\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.0893 - val_loss: 270.7477\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 256.3532 - val_loss: 268.3376\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 270.2714 - val_loss: 263.2553\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.5222 - val_loss: 260.2932\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 244.7380 - val_loss: 257.1383\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.9428 - val_loss: 253.1966\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 266.9695 - val_loss: 250.0272\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 255.7739 - val_loss: 247.3394\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 220.1719 - val_loss: 243.3500\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 235.3199 - val_loss: 242.6156\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.9659 - val_loss: 237.9906\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.0768 - val_loss: 234.3756\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.8508 - val_loss: 233.2135\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  41 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 6141.8876 - val_loss: 1412.5812\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1322.9237 - val_loss: 655.7055\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 637.1962 - val_loss: 624.7741\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 607.5744 - val_loss: 568.2180\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 595.5369 - val_loss: 529.3730\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 510.9631 - val_loss: 500.3481\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 466.2297 - val_loss: 474.7900\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 488.3179 - val_loss: 447.4450\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 441.2011 - val_loss: 424.6456\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 413.8853 - val_loss: 406.6861\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 417.3753 - val_loss: 385.6922\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 356.6186 - val_loss: 366.1671\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 333.4102 - val_loss: 348.5822\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 290.4379 - val_loss: 329.9393\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.4097 - val_loss: 310.0035\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 282.5051 - val_loss: 291.1475\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.3652 - val_loss: 273.9639\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.8407 - val_loss: 256.1952\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.3085 - val_loss: 239.2498\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.3560 - val_loss: 224.8861\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.6187 - val_loss: 207.2334\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.5564 - val_loss: 192.2321\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.7693 - val_loss: 179.0350\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.3756 - val_loss: 168.4449\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.0705 - val_loss: 158.9639\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7255 - val_loss: 152.5444\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 124.2716 - val_loss: 141.8345\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8089 - val_loss: 135.4114\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9672 - val_loss: 130.3940\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.7077 - val_loss: 128.2311\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.5049 - val_loss: 125.4653\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.9721 - val_loss: 122.3014\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.2605 - val_loss: 121.2892\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.5711 - val_loss: 123.1021\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.4399 - val_loss: 124.2328\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.3931 - val_loss: 121.4603\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.5009 - val_loss: 118.6747\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.5833 - val_loss: 118.9871\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.3710 - val_loss: 114.3558\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.4769 - val_loss: 121.0551\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.8372 - val_loss: 114.4551\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1005 - val_loss: 115.4550\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.1511 - val_loss: 111.3557\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 94.1415 - val_loss: 111.3364\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.1941 - val_loss: 110.6113\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 86.1893 - val_loss: 116.2813\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.0791 - val_loss: 109.1268\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.9514 - val_loss: 109.4029\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.8777 - val_loss: 110.0976\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.4613 - val_loss: 106.7654\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.3192 - val_loss: 108.8120\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.2513 - val_loss: 106.8990\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.7140 - val_loss: 106.7816\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.7278 - val_loss: 106.4201\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.8436 - val_loss: 104.3081\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.9577 - val_loss: 104.4397\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.4463 - val_loss: 103.8796\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.1114 - val_loss: 105.9180\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 73.5699 - val_loss: 102.6260\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 76.7133 - val_loss: 101.7934\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.2360 - val_loss: 102.4870\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.5965 - val_loss: 101.1028\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.3591 - val_loss: 100.3045\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.2341 - val_loss: 99.7236\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.2474 - val_loss: 100.2450\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 79.6428 - val_loss: 99.2409\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.0362 - val_loss: 110.6649\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.5215 - val_loss: 104.6359\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.3095 - val_loss: 108.9823\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.0962 - val_loss: 100.5588\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.8338 - val_loss: 97.6676\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 80.0908 - val_loss: 95.0076\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 80.5886 - val_loss: 94.0197\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.4522 - val_loss: 94.3487\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.1327 - val_loss: 93.2797\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.3358 - val_loss: 94.7164\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.0136 - val_loss: 92.0068\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 78.9634 - val_loss: 92.1824\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 71.6274 - val_loss: 92.3067\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 80.7283 - val_loss: 91.1740\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 75.6525 - val_loss: 92.3002\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.5848 - val_loss: 89.5434\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.2861 - val_loss: 99.4960\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 80.4552 - val_loss: 89.9957\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 76.1826 - val_loss: 90.7930\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 76.3595 - val_loss: 89.9164\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.0407 - val_loss: 89.2679\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 78.8346 - val_loss: 91.5308\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 81.8242 - val_loss: 95.0457\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.0943 - val_loss: 91.1442\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 72.8253 - val_loss: 90.9293\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.4456 - val_loss: 89.6080\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.2943 - val_loss: 87.6810\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.2826 - val_loss: 89.7154\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 76.6309 - val_loss: 88.6696\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.9286 - val_loss: 92.8646\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.4511 - val_loss: 88.1019\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.3808 - val_loss: 86.3903\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 66.4055 - val_loss: 85.1840\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 70.7168 - val_loss: 86.9390\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  42 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 273647.0625 - val_loss: 149759.6719\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126634.1953 - val_loss: 64951.9453\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 56920.9614 - val_loss: 28380.2559\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 25542.1810 - val_loss: 12224.8018\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11334.2053 - val_loss: 5027.6318\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4823.1839 - val_loss: 2147.5884\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2015.4033 - val_loss: 1203.7365\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1246.8868 - val_loss: 917.1577\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 872.7456 - val_loss: 697.4129\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 761.8933 - val_loss: 618.1199\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 595.1284 - val_loss: 556.8090\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 563.3648 - val_loss: 537.7584\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 498.8818 - val_loss: 480.6242\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 473.2890 - val_loss: 460.8852\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 480.8135 - val_loss: 434.2743\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 437.2887 - val_loss: 425.7257\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 481.9017 - val_loss: 393.9442\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 419.9105 - val_loss: 385.1104\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 383.4090 - val_loss: 365.1556\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 361.7161 - val_loss: 354.9505\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 371.1444 - val_loss: 350.4908\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 362.3103 - val_loss: 327.1214\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 358.6038 - val_loss: 323.4918\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.5830 - val_loss: 319.2041\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 325.8383 - val_loss: 303.8564\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 331.6979 - val_loss: 303.0976\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 326.0266 - val_loss: 290.6269\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 302.7948 - val_loss: 291.8663\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 300.2588 - val_loss: 284.2372\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 297.2725 - val_loss: 281.9652\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 297.5083 - val_loss: 276.3546\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.0136 - val_loss: 275.3484\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.7073 - val_loss: 267.7188\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.2386 - val_loss: 263.6404\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 289.9887 - val_loss: 264.1756\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 260.0598 - val_loss: 258.1986\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.6042 - val_loss: 261.6036\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 264.6385 - val_loss: 256.8574\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.5193 - val_loss: 249.6739\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.9843 - val_loss: 249.4100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 296.7993 - val_loss: 245.9723\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.8570 - val_loss: 245.9297\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.5153 - val_loss: 247.1553\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.9597 - val_loss: 246.2590\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.1928 - val_loss: 243.9910\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 239.6130 - val_loss: 239.8296\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.7134 - val_loss: 243.1183\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 249.2780 - val_loss: 237.4172\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.2901 - val_loss: 237.5555\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.0778 - val_loss: 236.4528\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.3391 - val_loss: 243.2011\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.9546 - val_loss: 233.7323\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.0927 - val_loss: 235.4449\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.5654 - val_loss: 233.6627\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250.0692 - val_loss: 231.2462\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.0872 - val_loss: 230.1453\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.9062 - val_loss: 224.3186\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.5327 - val_loss: 227.7392\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.0502 - val_loss: 232.1333\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 230.2495 - val_loss: 226.0408\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.0787 - val_loss: 223.8772\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.2649 - val_loss: 224.0022\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.7321 - val_loss: 230.7548\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.3592 - val_loss: 217.4292\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.2839 - val_loss: 222.4695\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.2269 - val_loss: 222.0165\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.0791 - val_loss: 216.9101\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.6402 - val_loss: 222.7228\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 249.9404 - val_loss: 215.9860\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 243.3950 - val_loss: 220.2390\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.4287 - val_loss: 215.6405\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.2131 - val_loss: 214.9424\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 246.1957 - val_loss: 213.3040\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.6147 - val_loss: 213.5660\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 228.7052 - val_loss: 215.7372\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 237.2175 - val_loss: 211.3172\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.2648 - val_loss: 219.8941\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.6089 - val_loss: 210.1414\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.7349 - val_loss: 213.8620\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.2354 - val_loss: 210.4642\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 233.8464 - val_loss: 207.4295\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 231.0696 - val_loss: 206.8016\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 238.4509 - val_loss: 207.2339\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.9401 - val_loss: 210.7683\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.3998 - val_loss: 203.8484\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 237.0700 - val_loss: 206.6214\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.4358 - val_loss: 202.9408\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 209.8228 - val_loss: 205.3518\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.7892 - val_loss: 208.9438\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.1653 - val_loss: 201.5675\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 214.4042 - val_loss: 202.7625\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.5994 - val_loss: 210.4978\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 219.1605 - val_loss: 202.8916\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.8661 - val_loss: 201.0996\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.1228 - val_loss: 208.1760\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.4481 - val_loss: 196.0118\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 206.3851 - val_loss: 213.8895\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.9228 - val_loss: 198.1903\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.6580 - val_loss: 204.9943\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.5049 - val_loss: 201.4324\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  43 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 308570.3346 - val_loss: 154223.9531\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117504.9233 - val_loss: 38373.4453\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 25177.4146 - val_loss: 4302.6489\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3530.3052 - val_loss: 3860.6924\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3321.0586 - val_loss: 2861.8569\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2671.9098 - val_loss: 2482.2295\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2086.7910 - val_loss: 2085.5376\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2084.0747 - val_loss: 1759.9216\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1522.3762 - val_loss: 1512.2465\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1294.3903 - val_loss: 1296.5062\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1305.0994 - val_loss: 1091.5461\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1109.9016 - val_loss: 942.0031\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 867.8468 - val_loss: 806.0228\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 940.6102 - val_loss: 704.9478\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 642.9605 - val_loss: 607.8561\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 697.4267 - val_loss: 536.7393\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 570.6030 - val_loss: 478.9695\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 472.1361 - val_loss: 420.1138\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 498.5504 - val_loss: 379.7036\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 479.3795 - val_loss: 342.3216\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 434.5964 - val_loss: 314.9260\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 399.6090 - val_loss: 288.2724\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 333.1738 - val_loss: 274.7719\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.8723 - val_loss: 253.3528\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 269.9559 - val_loss: 240.2792\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 330.5769 - val_loss: 232.7250\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.9404 - val_loss: 218.3186\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.5247 - val_loss: 210.4525\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 210.9868 - val_loss: 203.9953\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.5746 - val_loss: 199.7485\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.2473 - val_loss: 192.4081\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.3472 - val_loss: 186.8324\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.1367 - val_loss: 183.1695\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.1155 - val_loss: 180.3783\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.2631 - val_loss: 175.4829\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.7758 - val_loss: 173.2841\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.5578 - val_loss: 169.7248\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.4864 - val_loss: 166.7731\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.2426 - val_loss: 167.8973\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.2244 - val_loss: 162.9984\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.0303 - val_loss: 158.5550\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 191.8828 - val_loss: 155.8338\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.0856 - val_loss: 156.1414\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.2495 - val_loss: 150.4895\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.5937 - val_loss: 149.2046\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.3157 - val_loss: 147.3811\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.2317 - val_loss: 150.6090\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.7459 - val_loss: 142.4793\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.4820 - val_loss: 140.6580\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.9803 - val_loss: 139.2549\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.9289 - val_loss: 138.8867\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.1305 - val_loss: 141.6438\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4561 - val_loss: 137.7169\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.6359 - val_loss: 133.9604\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.0586 - val_loss: 130.7716\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.8031 - val_loss: 129.3461\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.1605 - val_loss: 128.4474\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.1077 - val_loss: 129.3519\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.7409 - val_loss: 128.7006\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.0951 - val_loss: 124.6318\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.0707 - val_loss: 123.7147\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.4403 - val_loss: 123.4995\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.8838 - val_loss: 121.3827\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.6742 - val_loss: 124.5228\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.2853 - val_loss: 119.2572\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.1235 - val_loss: 117.7522\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.3524 - val_loss: 117.0084\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.1351 - val_loss: 117.7375\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.8089 - val_loss: 115.5951\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.0796 - val_loss: 114.1143\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.1869 - val_loss: 113.5063\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.3278 - val_loss: 112.5275\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 117.5586 - val_loss: 115.2867\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 125.0824 - val_loss: 116.2392\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.2465 - val_loss: 111.6880\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 116.9755 - val_loss: 110.1428\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.0917 - val_loss: 112.5715\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 112.7693 - val_loss: 108.7165\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.6813 - val_loss: 110.9318\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3469 - val_loss: 108.7975\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.3976 - val_loss: 108.1367\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 108.6277 - val_loss: 106.3062\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.9201 - val_loss: 105.8261\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.8546 - val_loss: 104.9968\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.7012 - val_loss: 104.7917\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.0152 - val_loss: 104.7052\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.0190 - val_loss: 106.3291\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.2033 - val_loss: 108.7037\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.2104 - val_loss: 109.4419\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.2439 - val_loss: 103.5758\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.7767 - val_loss: 103.6539\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.3092 - val_loss: 105.9536\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.4480 - val_loss: 103.1615\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.0286 - val_loss: 101.3018\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.6776 - val_loss: 104.2455\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.7927 - val_loss: 100.6621\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.8087 - val_loss: 104.8565\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.7395 - val_loss: 99.9671\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.9892 - val_loss: 101.1265\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.9583 - val_loss: 104.2950\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  44 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 53559.0648 - val_loss: 24995.6582\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 19386.4369 - val_loss: 6415.5981\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4378.3399 - val_loss: 1458.0183\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1548.1142 - val_loss: 1429.0249\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1421.4421 - val_loss: 1189.8873\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1164.3767 - val_loss: 1094.2510\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1074.6614 - val_loss: 990.0479\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 909.0641 - val_loss: 900.0450\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 814.9125 - val_loss: 819.2269\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 829.0846 - val_loss: 743.0638\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 797.4417 - val_loss: 672.1454\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 659.4746 - val_loss: 612.1583\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 563.9211 - val_loss: 554.5919\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 557.1169 - val_loss: 506.2202\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 489.1010 - val_loss: 461.5603\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 476.3802 - val_loss: 424.1740\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 440.3649 - val_loss: 390.7327\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 383.7273 - val_loss: 364.6412\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 338.0941 - val_loss: 337.0210\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 362.9355 - val_loss: 314.5218\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 290.1653 - val_loss: 297.4598\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 319.5496 - val_loss: 281.0177\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.9061 - val_loss: 266.0900\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.6741 - val_loss: 255.0915\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245.7077 - val_loss: 241.5861\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 251.3397 - val_loss: 232.4404\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.0280 - val_loss: 221.9326\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 244.7044 - val_loss: 213.7689\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 205.6052 - val_loss: 206.1149\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.2558 - val_loss: 200.8265\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.8341 - val_loss: 193.4545\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.9340 - val_loss: 187.5934\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.2215 - val_loss: 182.1941\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.6959 - val_loss: 177.5724\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.3503 - val_loss: 173.1069\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.0088 - val_loss: 169.1438\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.1729 - val_loss: 164.9152\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.1964 - val_loss: 161.3655\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.2486 - val_loss: 160.2702\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.1905 - val_loss: 155.4459\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.8268 - val_loss: 152.5413\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.7761 - val_loss: 150.3525\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.4099 - val_loss: 147.9188\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.8200 - val_loss: 146.0080\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.4689 - val_loss: 143.2615\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.7521 - val_loss: 141.4687\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 141.6579 - val_loss: 139.7846\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.6571 - val_loss: 137.7725\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.9929 - val_loss: 139.4837\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.1080 - val_loss: 134.5596\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 130.4836 - val_loss: 133.7813\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.7037 - val_loss: 131.8395\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.3894 - val_loss: 130.8874\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.9049 - val_loss: 129.2742\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.9329 - val_loss: 128.1968\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.4359 - val_loss: 127.6449\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.6095 - val_loss: 126.4343\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.9752 - val_loss: 125.2611\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.1579 - val_loss: 124.6012\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.1152 - val_loss: 123.5106\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.4045 - val_loss: 122.9019\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.1816 - val_loss: 122.0079\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.5045 - val_loss: 122.1837\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.3210 - val_loss: 120.6335\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.4542 - val_loss: 121.9475\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 123.5501 - val_loss: 121.0322\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.4531 - val_loss: 121.4153\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0513 - val_loss: 118.8213\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.8605 - val_loss: 117.7924\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.3799 - val_loss: 117.0474\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.3480 - val_loss: 119.8073\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.2715 - val_loss: 116.0246\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.5457 - val_loss: 116.0318\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.5879 - val_loss: 116.3639\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.1262 - val_loss: 115.9680\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.7423 - val_loss: 114.9795\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.9365 - val_loss: 114.6222\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.7716 - val_loss: 113.8614\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.4047 - val_loss: 113.3518\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.9978 - val_loss: 113.0555\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 116.3563 - val_loss: 113.2552\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.1756 - val_loss: 112.3496\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.0021 - val_loss: 112.4672\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.6340 - val_loss: 111.8002\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.1740 - val_loss: 111.6880\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.3678 - val_loss: 111.4398\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.8222 - val_loss: 110.9980\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.2196 - val_loss: 111.0867\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3590 - val_loss: 112.5917\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7006 - val_loss: 110.6399\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.0632 - val_loss: 111.4665\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.6558 - val_loss: 110.1782\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.3633 - val_loss: 110.5295\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.3937 - val_loss: 111.1250\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 106.8537 - val_loss: 108.9345\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 114.5633 - val_loss: 109.9137\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.8695 - val_loss: 108.6417\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.3530 - val_loss: 108.5701\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.4819 - val_loss: 108.3148\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.8864 - val_loss: 107.9639\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  45 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 18ms/step - loss: 2527.4851 - val_loss: 1410.6993\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1344.0313 - val_loss: 795.2408\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 795.1451 - val_loss: 492.0508\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 469.5758 - val_loss: 388.3234\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 383.5761 - val_loss: 339.3426\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.4003 - val_loss: 300.6931\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 309.5980 - val_loss: 272.1542\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.2598 - val_loss: 251.2130\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.4487 - val_loss: 241.0755\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.9379 - val_loss: 223.4518\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 195.9658 - val_loss: 216.0688\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.3754 - val_loss: 207.8922\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.2447 - val_loss: 199.8415\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 183.0971 - val_loss: 194.0099\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.4906 - val_loss: 188.9035\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 183.1499 - val_loss: 184.3462\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.6914 - val_loss: 180.7396\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.5037 - val_loss: 175.0896\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.3621 - val_loss: 173.9988\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.3954 - val_loss: 175.2546\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.5228 - val_loss: 164.5924\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.1087 - val_loss: 161.1045\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.4301 - val_loss: 156.9898\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.2243 - val_loss: 154.1555\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.6754 - val_loss: 152.0728\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.6963 - val_loss: 149.3220\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.7649 - val_loss: 147.2348\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.3612 - val_loss: 143.0638\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.7145 - val_loss: 141.4424\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.5405 - val_loss: 137.7063\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.0441 - val_loss: 135.7316\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.7616 - val_loss: 135.0190\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.4369 - val_loss: 130.1667\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.0714 - val_loss: 124.1588\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.5957 - val_loss: 122.3351\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.4975 - val_loss: 118.2537\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.9541 - val_loss: 117.1322\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.4382 - val_loss: 113.2806\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.9024 - val_loss: 109.8954\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.4022 - val_loss: 107.2669\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.3092 - val_loss: 127.6122\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.9359 - val_loss: 110.5797\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.7183 - val_loss: 119.3381\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.9809 - val_loss: 102.1891\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.9309 - val_loss: 99.2521\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 107.6088 - val_loss: 97.4115\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.2521 - val_loss: 98.4922\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.4728 - val_loss: 98.8735\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.8067 - val_loss: 95.1270\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.2344 - val_loss: 101.0506\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.5647 - val_loss: 93.5782\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 109.8881 - val_loss: 95.5604\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.8698 - val_loss: 92.0446\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.6269 - val_loss: 91.5625\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.9231 - val_loss: 91.5312\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.2749 - val_loss: 91.2341\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.5585 - val_loss: 94.3638\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.6942 - val_loss: 89.7315\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.2733 - val_loss: 89.6289\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.5051 - val_loss: 89.1424\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.3799 - val_loss: 88.9533\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.6158 - val_loss: 96.7309\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.7589 - val_loss: 88.2051\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 100.1171 - val_loss: 96.3002\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 92.5624 - val_loss: 88.6670\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.3473 - val_loss: 94.8175\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.6908 - val_loss: 94.6425\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.6272 - val_loss: 91.6839\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.5986 - val_loss: 87.7378\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.6998 - val_loss: 95.4915\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 85.3849 - val_loss: 87.1596\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.1989 - val_loss: 88.5142\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.3353 - val_loss: 92.5404\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1774 - val_loss: 86.1353\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.9053 - val_loss: 88.4043\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.2719 - val_loss: 85.2080\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 81.3946 - val_loss: 85.0804\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.6974 - val_loss: 86.7749\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.2301 - val_loss: 93.3571\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 92.5095 - val_loss: 84.5711\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.3756 - val_loss: 85.1298\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.6028 - val_loss: 86.3912\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 91.2421 - val_loss: 101.1862\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.7860 - val_loss: 89.9573\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.4990 - val_loss: 88.2875\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.0718 - val_loss: 85.9286\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.2056 - val_loss: 88.2263\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 92.1390 - val_loss: 87.8224\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.3265 - val_loss: 88.6860\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 85.9487 - val_loss: 83.4422\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.5052 - val_loss: 84.1355\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.5084 - val_loss: 88.9467\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.4657 - val_loss: 85.6645\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.1981 - val_loss: 87.4664\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.7793 - val_loss: 83.6891\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.9159 - val_loss: 83.7974\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.5346 - val_loss: 83.1285\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.7825 - val_loss: 86.6207\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.2773 - val_loss: 94.8213\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.3197 - val_loss: 82.5085\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  46 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 20ms/step - loss: 37201.8605 - val_loss: 18369.0645\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14483.8767 - val_loss: 5681.5317\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4158.4022 - val_loss: 1613.4333\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1203.5962 - val_loss: 847.0015\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 772.5422 - val_loss: 769.5437\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 610.1066 - val_loss: 685.9596\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 582.8956 - val_loss: 639.3333\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 570.4890 - val_loss: 606.8631\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 581.4376 - val_loss: 579.2890\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 519.3708 - val_loss: 555.2687\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 522.2795 - val_loss: 531.5614\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 485.2269 - val_loss: 511.2545\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 464.4028 - val_loss: 491.5783\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 415.4220 - val_loss: 472.9952\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 435.5107 - val_loss: 454.2514\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 397.0935 - val_loss: 436.5336\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 394.3237 - val_loss: 418.9954\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 368.9634 - val_loss: 402.8092\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 327.6810 - val_loss: 386.7728\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 360.0633 - val_loss: 373.2423\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 307.8630 - val_loss: 360.7155\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 344.4034 - val_loss: 350.3831\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 298.4242 - val_loss: 337.8327\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 321.1245 - val_loss: 327.4330\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.6487 - val_loss: 316.8150\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 278.0260 - val_loss: 307.0298\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.1821 - val_loss: 297.9868\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 256.3301 - val_loss: 289.7199\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 285.2541 - val_loss: 281.7618\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.5850 - val_loss: 275.5220\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 237.4976 - val_loss: 270.6739\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.2450 - val_loss: 264.5186\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.2486 - val_loss: 260.1478\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.9326 - val_loss: 254.7115\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.0674 - val_loss: 250.9125\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.8762 - val_loss: 246.6757\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 217.3457 - val_loss: 243.6152\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.8529 - val_loss: 240.2426\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207.4958 - val_loss: 237.6854\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 194.6390 - val_loss: 236.3327\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.0821 - val_loss: 233.1774\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.9123 - val_loss: 231.5365\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.2909 - val_loss: 229.3152\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.6866 - val_loss: 226.3129\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.1356 - val_loss: 226.1625\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.4391 - val_loss: 222.4521\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.3888 - val_loss: 221.3911\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.0306 - val_loss: 221.0119\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.5962 - val_loss: 217.3256\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.6173 - val_loss: 218.8347\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.1970 - val_loss: 214.3390\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.3270 - val_loss: 213.5768\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.6187 - val_loss: 211.4577\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.0475 - val_loss: 209.6176\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.0294 - val_loss: 210.7026\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.3596 - val_loss: 207.1876\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 180.5671 - val_loss: 207.3898\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.1384 - val_loss: 203.9901\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.0410 - val_loss: 205.1211\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.9558 - val_loss: 203.2677\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.5378 - val_loss: 199.2777\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.9315 - val_loss: 198.6192\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.9287 - val_loss: 197.3160\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.4348 - val_loss: 194.9538\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.1492 - val_loss: 195.6613\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.5865 - val_loss: 193.5413\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.5108 - val_loss: 194.5163\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.1292 - val_loss: 189.9134\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.1171 - val_loss: 192.7379\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.3057 - val_loss: 188.7609\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 162.7693 - val_loss: 188.8590\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.7823 - val_loss: 187.6139\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.4782 - val_loss: 184.3177\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.9650 - val_loss: 182.3917\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.3638 - val_loss: 187.0833\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.1176 - val_loss: 180.4518\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.4247 - val_loss: 179.1559\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.5726 - val_loss: 183.0166\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.2693 - val_loss: 176.9413\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.4784 - val_loss: 178.0206\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.7047 - val_loss: 174.9530\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 143.2303 - val_loss: 174.2116\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.8419 - val_loss: 172.6365\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.2717 - val_loss: 177.3387\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.0754 - val_loss: 171.4917\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.3315 - val_loss: 169.9946\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.7356 - val_loss: 168.7240\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.5599 - val_loss: 173.2682\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.3448 - val_loss: 166.4746\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.7817 - val_loss: 169.6626\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.1318 - val_loss: 166.4680\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.6473 - val_loss: 163.7233\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.3320 - val_loss: 162.7421\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.4298 - val_loss: 163.5413\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.7394 - val_loss: 162.1143\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.9946 - val_loss: 160.1041\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.2081 - val_loss: 160.1755\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.4828 - val_loss: 158.2241\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.3468 - val_loss: 158.7495\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.9469 - val_loss: 157.0523\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  47 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 2481.9969 - val_loss: 704.7540\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 753.6694 - val_loss: 560.6292\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 497.9976 - val_loss: 369.0341\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 375.3913 - val_loss: 268.1069\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 264.6318 - val_loss: 230.8142\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.6463 - val_loss: 208.0219\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.3990 - val_loss: 197.7755\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.0747 - val_loss: 185.3976\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.5971 - val_loss: 177.0078\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.6952 - val_loss: 166.6564\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.6419 - val_loss: 160.1615\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.0130 - val_loss: 152.0777\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.4474 - val_loss: 146.6245\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.2273 - val_loss: 141.9983\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.1089 - val_loss: 136.5195\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.8498 - val_loss: 133.0822\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.0501 - val_loss: 127.9208\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.6519 - val_loss: 136.0813\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.3436 - val_loss: 121.2739\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.9440 - val_loss: 118.5706\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.4959 - val_loss: 117.3406\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.7647 - val_loss: 116.1155\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.5888 - val_loss: 113.3335\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.6453 - val_loss: 114.6246\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 128.7474 - val_loss: 111.2322\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.7915 - val_loss: 114.0320\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8544 - val_loss: 109.3429\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.5909 - val_loss: 108.7419\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.4742 - val_loss: 109.8501\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.3867 - val_loss: 109.3143\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.2811 - val_loss: 110.0378\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.8150 - val_loss: 114.4149\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.6117 - val_loss: 106.9189\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.3981 - val_loss: 105.1604\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.5543 - val_loss: 108.4108\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.5998 - val_loss: 105.2639\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.4994 - val_loss: 104.6011\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.8854 - val_loss: 103.2640\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.5872 - val_loss: 113.9802\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.7479 - val_loss: 110.0071\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.9066 - val_loss: 107.3208\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.1646 - val_loss: 105.7252\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.0598 - val_loss: 108.1920\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 117.0405 - val_loss: 102.1832\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.3061 - val_loss: 106.5819\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.4458 - val_loss: 107.6341\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.5900 - val_loss: 105.4929\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.0367 - val_loss: 101.9192\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.4856 - val_loss: 105.3027\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.7477 - val_loss: 99.8957\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.8547 - val_loss: 100.2244\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.9112 - val_loss: 99.2351\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 104.6496 - val_loss: 103.0459\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 106.6057 - val_loss: 99.3648\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.0727 - val_loss: 101.7565\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 112.1128 - val_loss: 112.0113\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.1193 - val_loss: 110.2944\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.4535 - val_loss: 97.6132\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.2942 - val_loss: 96.3860\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.1805 - val_loss: 95.7723\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.3674 - val_loss: 97.0786\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.9810 - val_loss: 95.9912\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3307 - val_loss: 92.4306\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 107.0064 - val_loss: 97.2644\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.5024 - val_loss: 90.9999\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.0817 - val_loss: 93.2847\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.7517 - val_loss: 90.4673\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.7428 - val_loss: 87.9128\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.2135 - val_loss: 92.6475\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.7574 - val_loss: 88.6161\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.0422 - val_loss: 84.3864\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.0435 - val_loss: 86.5742\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.0681 - val_loss: 84.2005\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.2183 - val_loss: 80.6835\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.4869 - val_loss: 82.0462\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.3914 - val_loss: 79.4913\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.8351 - val_loss: 93.5821\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.6924 - val_loss: 84.6495\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 90.5767 - val_loss: 81.1595\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.1319 - val_loss: 77.5777\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.1279 - val_loss: 74.8424\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.7011 - val_loss: 77.8861\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.3211 - val_loss: 72.9715\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.4778 - val_loss: 77.0630\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.1271 - val_loss: 72.3980\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.8206 - val_loss: 71.9237\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 74.2168 - val_loss: 70.6400\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.5415 - val_loss: 77.6860\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.6498 - val_loss: 70.1801\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.4718 - val_loss: 69.6357\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 76.6444 - val_loss: 69.7712\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 68.4360 - val_loss: 76.7148\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 74.8566 - val_loss: 78.5134\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.2604 - val_loss: 67.1532\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 73.7248 - val_loss: 71.6619\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.8849 - val_loss: 66.0279\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 74.6717 - val_loss: 71.4119\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.7170 - val_loss: 67.6215\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 75.9102 - val_loss: 65.2562\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 75.1887 - val_loss: 64.5752\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  48 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 146498.2619 - val_loss: 53282.2656\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 37216.9732 - val_loss: 10284.5859\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7651.3570 - val_loss: 2427.7126\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2026.0657 - val_loss: 1932.6973\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2090.8978 - val_loss: 1781.0162\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 1709.8358 - val_loss: 1623.8468\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1841.1864 - val_loss: 1496.4305\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1600.7256 - val_loss: 1370.1372\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1450.6529 - val_loss: 1241.8085\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 1271.1861 - val_loss: 1144.5649\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1137.2774 - val_loss: 1078.3323\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1056.1194 - val_loss: 988.4500\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 994.5451 - val_loss: 910.9046\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 851.2088 - val_loss: 844.5159\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 863.6309 - val_loss: 794.1002\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 716.1571 - val_loss: 737.4359\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 758.5270 - val_loss: 699.6662\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 723.2843 - val_loss: 672.0075\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 599.2606 - val_loss: 639.0053\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 636.9002 - val_loss: 620.3185\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 617.1060 - val_loss: 596.2080\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 582.8755 - val_loss: 573.2706\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 528.3221 - val_loss: 560.2230\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 532.3550 - val_loss: 542.4051\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 490.7912 - val_loss: 523.3782\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 483.3565 - val_loss: 516.1208\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 472.6835 - val_loss: 497.6064\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 476.8690 - val_loss: 486.7633\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 425.6657 - val_loss: 471.4730\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 426.8686 - val_loss: 462.7213\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 437.0139 - val_loss: 452.9783\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 409.2848 - val_loss: 438.5667\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 419.0168 - val_loss: 429.0727\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 426.8441 - val_loss: 421.7323\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 402.2660 - val_loss: 412.5882\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 364.9095 - val_loss: 408.6194\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 363.4007 - val_loss: 392.0031\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 403.1798 - val_loss: 391.3998\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 364.5334 - val_loss: 379.4288\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 375.9501 - val_loss: 374.8331\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 368.9023 - val_loss: 365.7136\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 346.9930 - val_loss: 358.7073\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 318.9960 - val_loss: 355.9065\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 296.2001 - val_loss: 348.0497\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 323.6896 - val_loss: 340.1539\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 293.1059 - val_loss: 336.2632\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.6303 - val_loss: 331.2164\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.5855 - val_loss: 324.4599\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 301.6406 - val_loss: 321.5809\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.3127 - val_loss: 313.4009\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 302.7580 - val_loss: 317.0585\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 264.9681 - val_loss: 305.0294\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.1746 - val_loss: 302.2241\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.1437 - val_loss: 297.3794\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 260.0547 - val_loss: 292.5292\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 285.5705 - val_loss: 288.7395\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.4543 - val_loss: 283.5911\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 283.6072 - val_loss: 281.7683\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.0492 - val_loss: 277.3182\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.7460 - val_loss: 274.0952\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.4913 - val_loss: 271.3705\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 257.6766 - val_loss: 266.3403\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 244.6787 - val_loss: 263.5466\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.0817 - val_loss: 261.4214\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.0224 - val_loss: 257.1219\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.5455 - val_loss: 253.9007\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.0229 - val_loss: 251.0634\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 231.9540 - val_loss: 247.3810\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.8539 - val_loss: 245.2011\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.2374 - val_loss: 243.4880\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 201.7021 - val_loss: 240.1080\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.4293 - val_loss: 236.4735\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.5284 - val_loss: 231.9488\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.0040 - val_loss: 234.1789\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.9789 - val_loss: 226.1269\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.2300 - val_loss: 226.5701\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.1036 - val_loss: 220.3869\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.0138 - val_loss: 219.6977\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 208.4612 - val_loss: 216.1110\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 176.3157 - val_loss: 212.2957\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.9130 - val_loss: 212.5780\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 183.5080 - val_loss: 207.7707\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 205.0482 - val_loss: 204.0519\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.3740 - val_loss: 202.4142\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.4285 - val_loss: 199.8553\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.3096 - val_loss: 197.0390\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.3928 - val_loss: 196.6233\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.9501 - val_loss: 192.0982\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.8893 - val_loss: 191.6668\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.6925 - val_loss: 189.4661\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.2475 - val_loss: 185.8425\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 160.7436 - val_loss: 183.1846\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.3994 - val_loss: 182.7406\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.1706 - val_loss: 178.7690\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 152.4392 - val_loss: 178.7767\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.8802 - val_loss: 176.3389\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.7967 - val_loss: 173.5979\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 162.0847 - val_loss: 172.3165\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.2663 - val_loss: 170.7542\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.7033 - val_loss: 168.2152\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  49 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 20ms/step - loss: 7495.6607 - val_loss: 2920.8015\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1867.3693 - val_loss: 488.6263\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 558.8766 - val_loss: 430.6667\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 469.1531 - val_loss: 352.8066\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 406.6154 - val_loss: 317.8871\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 328.8165 - val_loss: 290.2563\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 282.2882 - val_loss: 285.2828\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 294.1596 - val_loss: 279.8932\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 289.4275 - val_loss: 277.6726\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 266.1385 - val_loss: 274.3736\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.5320 - val_loss: 272.4709\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.2970 - val_loss: 268.7717\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.0483 - val_loss: 267.9328\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 266.3491 - val_loss: 265.0914\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.1958 - val_loss: 263.7348\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 251.5923 - val_loss: 258.7812\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.5499 - val_loss: 256.1035\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 256.0269 - val_loss: 259.1537\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.9785 - val_loss: 252.4887\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.7469 - val_loss: 251.8528\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 256.5502 - val_loss: 246.4652\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 241.0102 - val_loss: 243.7725\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.2010 - val_loss: 240.2761\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 232.2812 - val_loss: 239.3889\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 224.9012 - val_loss: 234.1613\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.6966 - val_loss: 232.6402\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 221.3433 - val_loss: 228.1949\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.0976 - val_loss: 227.7647\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.4654 - val_loss: 223.9875\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.8141 - val_loss: 218.0477\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 210.9099 - val_loss: 213.6352\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 221.6771 - val_loss: 212.4565\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 204.9035 - val_loss: 207.4429\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 203.2980 - val_loss: 204.2105\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.7994 - val_loss: 198.8827\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.6695 - val_loss: 195.6011\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.3579 - val_loss: 190.9993\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.3955 - val_loss: 185.5580\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.3698 - val_loss: 179.5932\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 176.6152 - val_loss: 172.8599\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.2717 - val_loss: 162.4583\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 173.6984 - val_loss: 158.4709\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.5020 - val_loss: 162.7648\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.7195 - val_loss: 146.8480\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.8777 - val_loss: 142.9755\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 158.3140 - val_loss: 137.2435\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.7994 - val_loss: 134.9339\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.5886 - val_loss: 128.7131\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 138.6452 - val_loss: 127.1251\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 139.2589 - val_loss: 122.8205\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.9464 - val_loss: 117.8558\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.7536 - val_loss: 113.3256\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.2885 - val_loss: 114.3262\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.9284 - val_loss: 112.5358\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.7810 - val_loss: 107.8825\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.1056 - val_loss: 107.8696\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.7251 - val_loss: 116.2247\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.8402 - val_loss: 113.4148\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.1767 - val_loss: 104.0422\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.6091 - val_loss: 99.7167\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.3985 - val_loss: 98.3367\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.5784 - val_loss: 96.9008\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.8587 - val_loss: 96.6788\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2327 - val_loss: 99.4271\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.0581 - val_loss: 97.7423\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9634 - val_loss: 94.4871\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.9860 - val_loss: 95.9362\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.4975 - val_loss: 93.9367\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.7054 - val_loss: 91.0124\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.2448 - val_loss: 92.0593\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.3388 - val_loss: 89.9626\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.5830 - val_loss: 89.0366\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 116.1935 - val_loss: 89.1552\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.2150 - val_loss: 95.1257\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.1961 - val_loss: 90.7949\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.0786 - val_loss: 89.2861\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.5732 - val_loss: 88.5857\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.5324 - val_loss: 86.1100\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.9452 - val_loss: 94.4202\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.2053 - val_loss: 87.1313\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.8384 - val_loss: 82.3518\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.5006 - val_loss: 81.9617\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.3898 - val_loss: 81.9176\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.1706 - val_loss: 82.7897\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 93.6758 - val_loss: 84.6549\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.1301 - val_loss: 80.9995\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.7882 - val_loss: 83.4909\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.6727 - val_loss: 79.5573\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.8977 - val_loss: 77.2880\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.1161 - val_loss: 78.7216\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.8748 - val_loss: 77.0343\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.7667 - val_loss: 77.9007\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.9606 - val_loss: 77.4485\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.0633 - val_loss: 78.4126\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.0071 - val_loss: 73.9292\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.2090 - val_loss: 75.8861\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.2741 - val_loss: 73.9922\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 90.8764 - val_loss: 73.5662\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 80.2873 - val_loss: 75.4061\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.4202 - val_loss: 73.5937\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  50 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 31ms/step - loss: 15892.2188 - val_loss: 10758.2754\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8745.7456 - val_loss: 6100.8555\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4937.3518 - val_loss: 3430.4785\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2871.4839 - val_loss: 1939.5737\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1787.9716 - val_loss: 1115.6771\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1055.1323 - val_loss: 702.7171\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 660.5695 - val_loss: 558.0722\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 514.5972 - val_loss: 507.3985\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 491.7598 - val_loss: 480.5078\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 467.3562 - val_loss: 453.4245\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 411.3160 - val_loss: 429.4957\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 410.5455 - val_loss: 408.1681\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 383.5675 - val_loss: 392.0392\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 351.8364 - val_loss: 377.8337\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 358.2929 - val_loss: 362.7668\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 333.6689 - val_loss: 351.8494\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 349.4100 - val_loss: 339.2186\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 323.0761 - val_loss: 325.2774\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 312.0450 - val_loss: 315.7454\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 297.4657 - val_loss: 304.3057\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 307.1756 - val_loss: 296.4571\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 270.2184 - val_loss: 287.9431\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 275.6463 - val_loss: 280.0663\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.8549 - val_loss: 271.1824\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.2673 - val_loss: 264.8581\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.9915 - val_loss: 260.5162\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 245.5858 - val_loss: 254.8426\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 262.1610 - val_loss: 249.7619\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 267.4346 - val_loss: 243.8524\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.6876 - val_loss: 238.2157\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 239.4443 - val_loss: 231.0802\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 228.5722 - val_loss: 225.0568\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 242.1066 - val_loss: 214.9243\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.1531 - val_loss: 206.2750\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 229.7326 - val_loss: 199.4474\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 213.7887 - val_loss: 196.2439\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.3833 - val_loss: 188.2887\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.3296 - val_loss: 183.2338\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.3057 - val_loss: 177.3200\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 186.1105 - val_loss: 171.7156\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.4348 - val_loss: 168.4455\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.2639 - val_loss: 163.2736\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.8293 - val_loss: 159.3382\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.1704 - val_loss: 154.8594\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.2919 - val_loss: 152.2587\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.8622 - val_loss: 147.9023\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 169.9202 - val_loss: 144.6347\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.2632 - val_loss: 140.7725\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 150.5730 - val_loss: 137.9976\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.5788 - val_loss: 135.7528\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 156.9860 - val_loss: 133.9007\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.4097 - val_loss: 129.8811\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.3234 - val_loss: 127.0008\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 136.7239 - val_loss: 128.3602\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.6128 - val_loss: 122.2681\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.9590 - val_loss: 120.8909\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.0964 - val_loss: 118.6242\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.7848 - val_loss: 115.6072\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.4517 - val_loss: 114.1340\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.7718 - val_loss: 112.3425\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.3639 - val_loss: 109.8154\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.9526 - val_loss: 109.2677\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.8833 - val_loss: 107.6533\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.1728 - val_loss: 108.8522\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 120.2114 - val_loss: 105.8062\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0133 - val_loss: 105.5588\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.6491 - val_loss: 104.7266\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.0107 - val_loss: 103.3124\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.7431 - val_loss: 102.7538\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.2895 - val_loss: 101.2354\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.9503 - val_loss: 103.1528\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 116.1732 - val_loss: 98.2577\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.0062 - val_loss: 100.2498\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.7992 - val_loss: 97.7021\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 113.5569 - val_loss: 99.4767\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.2929 - val_loss: 95.6145\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.5152 - val_loss: 95.0406\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 91.3474 - val_loss: 94.1310\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.2011 - val_loss: 95.8204\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.3996 - val_loss: 92.5489\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 90.8104 - val_loss: 94.0175\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.7541 - val_loss: 91.0557\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.3175 - val_loss: 92.7664\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 93.8770 - val_loss: 90.6937\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.9284 - val_loss: 89.3805\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.6677 - val_loss: 88.5312\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1304 - val_loss: 89.2343\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.9741 - val_loss: 89.0761\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.0878 - val_loss: 87.4993\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 104.9174 - val_loss: 85.8759\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 105.5254 - val_loss: 84.8186\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.8342 - val_loss: 86.1417\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 88.6457 - val_loss: 87.1623\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.7765 - val_loss: 86.4597\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.9200 - val_loss: 84.0611\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.4049 - val_loss: 84.6223\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.6929 - val_loss: 88.7467\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.1310 - val_loss: 83.2553\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.5588 - val_loss: 85.7309\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.3149 - val_loss: 82.6406\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Total Execution Time :  0:08:21.781673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iJzACFtCn3M",
        "outputId": "ef9c25ac-6374-4fb4-9859-74cd9add82d1"
      },
      "source": [
        "# Calculate the Mean of the MSE of 50 models\n",
        "mean_of_mse = stats.mean(list_of_mse)\n",
        "\n",
        "# Calculate the Standard Deviation of the MSE of 50 models\n",
        "std_of_mse = stats.stdev(list_of_mse)\n",
        "\n",
        "# Print the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nMean of the MSE of 50 Models : ' , str(mean_of_mse))\n",
        "print('Standard Deviation of MSE of 50 Models : ' , str(std_of_mse))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean of the MSE of 50 Models :  132.55491108188656\n",
            "Standard Deviation of MSE of 50 Models :  84.06283205976719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LNz_gSHCn3N"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqyyONQmCn3N"
      },
      "source": [
        "#### <font color = green> Comparision of Mean of MSE with Mean of MSE from PART B </font>\n",
        "<table style=\"width:20%\">\n",
        "  <tr>\n",
        "    <th>Mean of MSE of PART A</th>\n",
        "    <th>Mean of MSE of PART B</th>\n",
        "    <th>Mean of MSE of PART C</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>212.13</td>\n",
        "    <td>184.57</td>\n",
        "    <td>132.55</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "The table above compares the Mean of **MSE for PART A**, **Mean of MSE for PART B** and **Mean of MSE for PART C**. As can be seen, the value of Mean of MSE of PART C is marginally larger than that of PART B. This shows that the effect of **normalizing the features** as well as **increasing the number of epochs by 2** did not improve the performance of the regression model and helps it in finding the line of best fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nh9T3pkCn3P"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRDVyPvhCn3Q"
      },
      "source": [
        "# <font color = blue> END OF PART C </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0UvOA3aCn3W"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAtCVXkoCn3W"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xDgW2CnCn3X"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHUKzvaHCn3X"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WYd9DRbCn3Y"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CeOu5IdCn3Y"
      },
      "source": [
        "# <font color = blue> PART D : BASELINE MODEL WITH INCREASED HIDDEN LAYERS </font>\n",
        "\n",
        "\n",
        "In this part, all the tasks from <b>PART B</b> are performed, but this time the number of hidden layers are increased to 3\n",
        "\n",
        "<b>The new model will have : </b>\n",
        "<ul>\n",
        "        <li> Input layer with 10 nodes </li>\n",
        "        <li> 3 hidden layers, each with 10 nodes and ReLU activation function </li>\n",
        "        <li> Adam optimizer and mean squared error loss function </li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1rwXyJECn3Z"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zr-t0JbCn3a"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmIZ41TqCn3a"
      },
      "source": [
        "## <font color = darkorange>Task 1 : Train and Test the Baseline Model with 100 epochs and Increased Hidden Layers</font>\n",
        "\n",
        "In order to train and test the the baseline model with normalized features, 100 epochs and increased hidden layers, the following steps are performed :\n",
        "<ol>\n",
        "    <li>Normalize the features (X)</li>\n",
        "    <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "    <li>Create a new model with 100 epochs</li>\n",
        "    <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "    <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "    <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "    <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcdNGzrnCn3b"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Normalize the features (X) </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE7JGjHtCn3b"
      },
      "source": [
        "<b>Note</b> : As the features (X) have already been normalized the features (X), hence this part is skipped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98Si1vQnCn3c"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Randomly split the data into <i>X_train, X_test, Y_train, Y_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-FNd1NGCn3d"
      },
      "source": [
        "# Creating X_train, X_test, Y_train and Y_test sets\n",
        "X_train, X_test, Y_train, Y_test = data_split()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66xj8syHCn3d"
      },
      "source": [
        "### <font color = #2980B9> Step 3 : Create a new regression model with 3 hidden layers, each with 10 nodes and ReLU activation  </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ztnox-hCn3e"
      },
      "source": [
        "def three_layer_regression_model () :\n",
        "    \n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, activation='relu', input_shape=(X.shape[1],)))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVvXvamACn3g"
      },
      "source": [
        "### <font color = #2980B9> Step 4 : Train the model using <i>X_train, Y_train</i> using 50 epochs </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Z52Yw3Cn3h"
      },
      "source": [
        "<b>Note </b> : Since the regression model has already been created using `def regression_model` in <b>TASK 1</b> and there are no changes being made to it, hence there is no need to write the code for the model again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnJnKEkcCn3h",
        "outputId": "98b382eb-4822-4bce-edd6-1d3f7cb884bb"
      },
      "source": [
        "model = regression_model()\n",
        "\n",
        "# Fit the model on the train set\n",
        "model.fit(X_train, Y_train, validation_split=0.3, epochs=100)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 13157.8243 - val_loss: 2299.0500\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1881.2792 - val_loss: 1679.4698\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1680.5527 - val_loss: 1218.0470\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1194.1488 - val_loss: 1033.3153\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 967.5937 - val_loss: 884.7729\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 900.6545 - val_loss: 811.4247\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 888.2007 - val_loss: 755.4598\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 860.8392 - val_loss: 700.1383\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 724.7038 - val_loss: 649.0769\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 634.5249 - val_loss: 599.3982\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 626.8894 - val_loss: 567.6930\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 595.5547 - val_loss: 531.6534\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 592.1534 - val_loss: 503.3137\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 544.2331 - val_loss: 475.8618\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 474.2524 - val_loss: 444.0976\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 468.8579 - val_loss: 424.8435\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 466.5515 - val_loss: 400.2213\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 452.6753 - val_loss: 383.2569\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 437.5670 - val_loss: 367.2395\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 380.7301 - val_loss: 349.0379\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 379.7984 - val_loss: 338.8297\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 349.5478 - val_loss: 320.1749\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 321.3255 - val_loss: 312.3942\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 318.0548 - val_loss: 296.2316\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 305.7575 - val_loss: 291.0972\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 297.6036 - val_loss: 274.3331\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280.0590 - val_loss: 281.2597\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 294.2456 - val_loss: 256.2063\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 283.3905 - val_loss: 248.8147\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 277.3148 - val_loss: 240.2917\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 247.9697 - val_loss: 232.4566\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244.5891 - val_loss: 229.8996\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 232.4454 - val_loss: 220.9712\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 230.4978 - val_loss: 217.3325\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 204.4535 - val_loss: 206.5932\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 207.9604 - val_loss: 203.5491\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 206.7674 - val_loss: 195.9471\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 198.0023 - val_loss: 199.3597\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 226.2951 - val_loss: 185.0733\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 204.2638 - val_loss: 181.1722\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 187.0167 - val_loss: 180.3293\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.7403 - val_loss: 174.4125\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 176.4231 - val_loss: 167.9538\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 174.8604 - val_loss: 163.2995\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 184.7959 - val_loss: 161.8345\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 156.1704 - val_loss: 155.9352\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.4745 - val_loss: 153.8140\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 150.5890 - val_loss: 149.1723\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 149.1616 - val_loss: 150.2654\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 140.9521 - val_loss: 143.2315\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.5089 - val_loss: 147.9000\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 144.7647 - val_loss: 138.6204\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 129.4719 - val_loss: 135.1926\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 138.5062 - val_loss: 132.2523\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 133.6675 - val_loss: 135.9464\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 131.2374 - val_loss: 128.3278\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 142.2409 - val_loss: 126.5127\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 129.5952 - val_loss: 124.9044\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119.3960 - val_loss: 121.9211\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 118.8508 - val_loss: 119.9434\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117.6554 - val_loss: 118.2245\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 117.6299 - val_loss: 121.6554\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 104.0227 - val_loss: 116.6031\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 123.5006 - val_loss: 114.5692\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 108.7687 - val_loss: 112.4282\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.9143 - val_loss: 110.9606\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 111.9248 - val_loss: 109.8918\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105.2511 - val_loss: 112.4781\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.6594 - val_loss: 107.6353\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.9414 - val_loss: 106.2042\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 107.1301 - val_loss: 109.7005\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 116.3036 - val_loss: 104.8998\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.7223 - val_loss: 103.2801\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97.9811 - val_loss: 101.8003\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122.9585 - val_loss: 100.8181\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.3354 - val_loss: 99.8204\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 120.6974 - val_loss: 107.2205\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106.4940 - val_loss: 98.5984\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 106.9460 - val_loss: 99.8188\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 98.4719 - val_loss: 95.7456\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 101.8446 - val_loss: 94.8936\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 106.9652 - val_loss: 94.3466\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.9912 - val_loss: 97.6015\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 100.5687 - val_loss: 93.5108\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.8098 - val_loss: 93.3187\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 89.2093 - val_loss: 93.0786\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 91.6689 - val_loss: 92.0861\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99.1811 - val_loss: 94.2079\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.0208 - val_loss: 92.8299\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 92.1318 - val_loss: 91.5031\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95.9742 - val_loss: 91.7850\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 102.9379 - val_loss: 91.7509\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90.7503 - val_loss: 97.8847\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 101.7714 - val_loss: 91.6350\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 85.4097 - val_loss: 90.4041\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 89.2905 - val_loss: 89.6591\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 11ms/step - loss: 83.3752 - val_loss: 91.5361\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 101.7982 - val_loss: 92.7955\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 88.3184 - val_loss: 90.1452\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 82.9613 - val_loss: 89.0359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56d4353a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtK60SwZCn3i"
      },
      "source": [
        "### <font color = #2980B9> Step 5 : Get the predictions on the X_test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7iEpF-DCn3i"
      },
      "source": [
        "# Store the predictions in a variable Y_Predicted\n",
        "Y_predicted = predict()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uKv5LATCn3i"
      },
      "source": [
        "### <font color = #2980B9> Step 6 : Compute the <i>mean squared error</i> on the test set using sklearn </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch41wHTFCn3j",
        "outputId": "ce326d10-554d-4545-b563-478a52a517e3"
      },
      "source": [
        "# Calculate the mean square error\n",
        "\n",
        "mse = calculate_mse()\n",
        "print('Mean Square Error (MSE) of the Baseline Model with Normalized Features is : ' , str(mse))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Square Error (MSE) of the Baseline Model with Normalized Features is :  103.483370755894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlTs1U74Cn3j"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIYzm8UPCn3k"
      },
      "source": [
        "<p/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvNZCuYsCn3k"
      },
      "source": [
        "## <font color = darkorange>Task 2 : Create 50 Models and Calculate the <i>µ</i> & <i>σ</i> of their MSE Errors with new Features</font>\n",
        "\n",
        "In order to train 50 models with new features (normalized features) and calulate the mean (µ) and standard deviation (σ) of their mean square errors (MSE) the following steps are performed :\n",
        "<ol>\n",
        "    <li>Create an empty list <code>list_of_mse</code> to store the mean square error of each of the models</li>\n",
        "    <li>Define a for loop and perform each of the following steps in the loop</li>\n",
        "        <ol>\n",
        "        <li>Randomly split the data into <i>X_train, X_test, Y_train, Y_test</i> sets</li>\n",
        "        <li>Train the model using <i>X_train, Y_train</i> using <b>50</b> epochs</li>\n",
        "        <li>Evaluate the model using <i>X_test, Y_test</i></li>\n",
        "        <li>Get the predictions on the <i>X_test</i> set </li>\n",
        "        <li>Compute the <b>mean squared error</b> on the test set using sklearn</li>\n",
        "    </ol>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3pn2_KOCn3k"
      },
      "source": [
        "### <font color = #2980B9> Step 1 : Creating the <i>list_of_mse</i> list</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQqBYVXBCn3l"
      },
      "source": [
        "# Create the empty lists\n",
        "list_of_mse = []"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhgQuaXcCn3n"
      },
      "source": [
        "### <font color = #2980B9> Step 2 : Creating 50 Models, Calculating The MSE for Each and <i>µ</i> & <i>σ</i> of the 50 MSE Values in <i>list_of_mse</i> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-3I7GDfCn3n",
        "outputId": "044bf5e4-a14b-45a1-a735-715b7836a9c8"
      },
      "source": [
        "# Create the for loop to split the data, create, compile & fit model, evaluate & nake predictions, caluclate mse and store\n",
        "# in list_of_mse\n",
        "\n",
        "start_time = datetime.now() # Starting time of the for loop execution\n",
        "\n",
        "for i in range(50) :\n",
        "    # Split the data into train and test set\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "    \n",
        "    # Create and compile the regression model using the function regression_model as defined in TASK 1\n",
        "    model = regression_model()\n",
        "\n",
        "    # Fit the model on the train set\n",
        "    print('\\n\\n\\nTraining Model # ' , i+1 , '\\n\\n') # Print the Model Number that is being trained\n",
        "    model.fit(X_train, Y_train, validation_split=0.3, epochs=100)\n",
        "    print('\\n')\n",
        "    \n",
        "    # Make prediction on the test set\n",
        "    Y_predicted = model.predict(X_test)\n",
        "    \n",
        "    # Calculate the mean square error\n",
        "    mse = mean_squared_error(Y_test, Y_predicted)\n",
        "    \n",
        "    # Add the mse to the list_of_mse list\n",
        "    list_of_mse.append(mse)\n",
        "\n",
        "end_time = datetime.now() # Ending time of the for loop execution\n",
        "\n",
        "# Print time taken for fitting 50 models and calucating the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nTotal Execution Time : ' , format(end_time - start_time))\n",
        "    "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 113.2738 - val_loss: 115.8358\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.0145 - val_loss: 117.7740\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  27 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 16ms/step - loss: 1586.9627 - val_loss: 759.0740\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 793.9290 - val_loss: 459.2501\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 485.5961 - val_loss: 377.8925\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 394.8160 - val_loss: 312.0142\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 341.6868 - val_loss: 280.9560\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 304.9843 - val_loss: 259.7516\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 283.2035 - val_loss: 243.6577\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.4686 - val_loss: 227.9231\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.6493 - val_loss: 214.4528\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.8825 - val_loss: 202.5734\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.9172 - val_loss: 194.4463\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.4989 - val_loss: 192.6344\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 175.3220 - val_loss: 182.0398\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.7814 - val_loss: 178.4387\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.5225 - val_loss: 178.3529\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 167.9270 - val_loss: 173.8162\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.5600 - val_loss: 170.6898\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.4021 - val_loss: 163.8369\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.2135 - val_loss: 164.4326\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.1410 - val_loss: 160.2911\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.8521 - val_loss: 158.1947\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.9887 - val_loss: 158.0636\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 146.7693 - val_loss: 157.8676\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.7108 - val_loss: 154.2696\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.9181 - val_loss: 152.5320\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.2925 - val_loss: 151.3104\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.9005 - val_loss: 151.9407\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.3211 - val_loss: 152.5958\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.6103 - val_loss: 148.4505\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.5268 - val_loss: 148.5382\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.5739 - val_loss: 146.6854\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.0049 - val_loss: 146.1862\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 123.7870 - val_loss: 148.3554\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.7627 - val_loss: 144.1223\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.7743 - val_loss: 143.7099\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.3132 - val_loss: 144.7243\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.2070 - val_loss: 141.9711\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 117.6218 - val_loss: 140.6501\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.4300 - val_loss: 143.9821\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.7083 - val_loss: 140.2628\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.4198 - val_loss: 139.7359\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.9563 - val_loss: 139.0968\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.7607 - val_loss: 137.9736\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.1788 - val_loss: 140.4339\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.1803 - val_loss: 146.9055\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.2695 - val_loss: 140.1744\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.5255 - val_loss: 135.2372\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.5266 - val_loss: 135.3924\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.6698 - val_loss: 138.9830\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.9998 - val_loss: 148.6443\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.8618 - val_loss: 132.8187\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.0624 - val_loss: 133.3431\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.2923 - val_loss: 132.9540\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.8477 - val_loss: 133.5661\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.3558 - val_loss: 135.0680\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.4973 - val_loss: 134.1309\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.1183 - val_loss: 131.4850\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 99.6829 - val_loss: 130.5696\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.4037 - val_loss: 131.4082\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.5913 - val_loss: 133.9568\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.0673 - val_loss: 145.1860\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.3760 - val_loss: 129.1237\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.2640 - val_loss: 128.7618\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.8847 - val_loss: 128.9592\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.8424 - val_loss: 127.3548\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.6342 - val_loss: 131.5391\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.9154 - val_loss: 127.3680\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.2822 - val_loss: 127.1814\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.4481 - val_loss: 125.0113\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 97.8543 - val_loss: 124.7965\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.7310 - val_loss: 126.5565\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.2911 - val_loss: 124.3281\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.2776 - val_loss: 127.6784\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 94.3935 - val_loss: 131.3973\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.9096 - val_loss: 124.0974\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.4943 - val_loss: 123.4309\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.6717 - val_loss: 124.4530\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.7263 - val_loss: 122.5060\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.3626 - val_loss: 122.1267\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.2497 - val_loss: 122.5217\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.6369 - val_loss: 123.1068\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.0462 - val_loss: 121.1740\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.1471 - val_loss: 122.6498\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.9678 - val_loss: 122.9824\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 92.9829 - val_loss: 119.9097\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.9414 - val_loss: 120.8561\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.8665 - val_loss: 119.1207\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.7605 - val_loss: 120.1885\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.1236 - val_loss: 118.4143\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.1660 - val_loss: 118.9809\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.5017 - val_loss: 119.9508\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.6637 - val_loss: 124.2829\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.6563 - val_loss: 117.5874\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.0315 - val_loss: 115.9686\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.2054 - val_loss: 119.8768\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 84.5626 - val_loss: 117.2505\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.3774 - val_loss: 116.0129\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.0330 - val_loss: 115.4968\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.6382 - val_loss: 116.7143\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.1279 - val_loss: 114.4826\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  28 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 5262.8210 - val_loss: 1916.4502\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1622.2506 - val_loss: 582.9145\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 623.2560 - val_loss: 499.7520\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 527.5545 - val_loss: 451.3940\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 476.6594 - val_loss: 422.4725\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 462.1003 - val_loss: 389.1250\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 400.0148 - val_loss: 363.2581\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 431.7477 - val_loss: 343.6833\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 388.3896 - val_loss: 330.1298\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 358.0780 - val_loss: 317.9367\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 336.8994 - val_loss: 310.6778\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 340.7137 - val_loss: 304.7221\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 311.9490 - val_loss: 300.7927\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 321.1683 - val_loss: 296.7825\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.9983 - val_loss: 293.5124\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 307.0649 - val_loss: 293.0239\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.8349 - val_loss: 291.3452\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 303.9609 - val_loss: 288.8340\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 274.6810 - val_loss: 289.0971\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 278.5160 - val_loss: 287.3625\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.3272 - val_loss: 285.7825\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 253.5720 - val_loss: 286.2304\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.7049 - val_loss: 284.4510\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 303.4262 - val_loss: 283.9755\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.0883 - val_loss: 283.9244\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 287.5638 - val_loss: 282.5504\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 269.2701 - val_loss: 281.7177\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 283.7004 - val_loss: 283.1697\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.7166 - val_loss: 281.4115\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 281.6170 - val_loss: 280.1977\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.4254 - val_loss: 280.7014\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.8875 - val_loss: 279.0014\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 263.2188 - val_loss: 278.8486\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.4742 - val_loss: 277.1156\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 282.7875 - val_loss: 276.8809\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.7436 - val_loss: 275.7881\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 280.5535 - val_loss: 274.7130\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 269.9936 - val_loss: 273.9745\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.9337 - val_loss: 273.5702\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.5758 - val_loss: 272.0904\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 267.9935 - val_loss: 271.2461\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.9959 - val_loss: 271.0991\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 266.3014 - val_loss: 269.7530\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.5491 - val_loss: 269.4793\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.6701 - val_loss: 268.0876\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.4497 - val_loss: 268.9492\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 246.2658 - val_loss: 266.2446\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.6932 - val_loss: 265.5998\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 245.9659 - val_loss: 264.5042\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 246.5660 - val_loss: 263.6373\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 249.7405 - val_loss: 263.6096\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.2942 - val_loss: 261.7014\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.2506 - val_loss: 261.8063\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.7030 - val_loss: 260.7012\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.2799 - val_loss: 260.0167\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.9300 - val_loss: 258.5305\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 254.7687 - val_loss: 257.4753\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 230.8186 - val_loss: 256.7612\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.6612 - val_loss: 255.9165\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.6331 - val_loss: 254.8304\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.2667 - val_loss: 255.0411\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.2570 - val_loss: 253.3712\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.7276 - val_loss: 251.7656\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 246.1473 - val_loss: 251.2741\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.2035 - val_loss: 250.1111\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.0142 - val_loss: 251.7194\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 261.7386 - val_loss: 249.7264\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.2821 - val_loss: 247.9241\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 233.3091 - val_loss: 246.3141\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.6817 - val_loss: 246.1227\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 245.6798 - val_loss: 244.1641\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.9607 - val_loss: 244.2060\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.6176 - val_loss: 242.6154\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.5462 - val_loss: 241.6640\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.8472 - val_loss: 240.8794\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 239.9324 - val_loss: 241.5639\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.3525 - val_loss: 239.0073\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.0277 - val_loss: 237.9028\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.0327 - val_loss: 237.4818\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.9711 - val_loss: 237.5491\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 241.4200 - val_loss: 237.5059\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 205.1945 - val_loss: 235.3406\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 238.1938 - val_loss: 236.1898\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 224.6384 - val_loss: 233.2687\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.3261 - val_loss: 231.8661\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.3250 - val_loss: 231.7957\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.7766 - val_loss: 229.9658\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 224.1946 - val_loss: 229.5801\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.4831 - val_loss: 228.7126\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.1564 - val_loss: 227.0179\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.9337 - val_loss: 228.5360\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 199.2838 - val_loss: 224.8750\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.6059 - val_loss: 226.2606\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.4437 - val_loss: 223.1414\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 220.6862 - val_loss: 224.7880\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.8494 - val_loss: 222.4919\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 234.1125 - val_loss: 220.7584\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.1017 - val_loss: 219.3806\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 225.3141 - val_loss: 218.2771\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 205.8198 - val_loss: 217.9330\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  29 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 169559.4292 - val_loss: 99354.5000\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88286.3778 - val_loss: 41661.9062\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 37827.2089 - val_loss: 13947.0859\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 12984.2180 - val_loss: 5371.6284\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5652.0572 - val_loss: 3900.0549\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4353.7850 - val_loss: 3523.0208\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3664.9088 - val_loss: 3035.7939\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2931.6712 - val_loss: 2561.5479\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2777.9028 - val_loss: 2158.1592\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 2150.3283 - val_loss: 1851.9037\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1993.6902 - val_loss: 1610.9695\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1631.9404 - val_loss: 1426.8093\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1349.0915 - val_loss: 1287.5858\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1394.4629 - val_loss: 1183.5760\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1088.5701 - val_loss: 1108.3953\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1163.9266 - val_loss: 1040.1534\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1054.8122 - val_loss: 996.2000\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 952.9822 - val_loss: 947.3958\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 980.1430 - val_loss: 909.4984\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 859.8518 - val_loss: 876.1302\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 853.8382 - val_loss: 841.1449\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 810.4874 - val_loss: 817.0273\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 855.1551 - val_loss: 787.9261\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 709.2267 - val_loss: 767.8910\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 798.7529 - val_loss: 738.0874\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 744.2272 - val_loss: 719.4179\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 626.9362 - val_loss: 697.1943\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 658.4195 - val_loss: 678.4409\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 654.5223 - val_loss: 660.7097\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 658.5628 - val_loss: 642.9438\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 609.1114 - val_loss: 627.4175\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 533.1514 - val_loss: 606.1556\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 510.4136 - val_loss: 591.9919\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 579.5200 - val_loss: 577.2922\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 534.3628 - val_loss: 563.6891\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 480.9378 - val_loss: 552.9363\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 476.4969 - val_loss: 535.5735\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 507.2019 - val_loss: 522.5432\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 473.3156 - val_loss: 511.6703\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 435.6782 - val_loss: 500.1665\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 431.8113 - val_loss: 490.6531\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 429.3403 - val_loss: 479.2246\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 398.8338 - val_loss: 468.8295\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 418.2225 - val_loss: 459.3074\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 370.2658 - val_loss: 451.4735\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 412.3160 - val_loss: 442.5549\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 394.6196 - val_loss: 432.0957\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375.9531 - val_loss: 426.4582\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 372.8339 - val_loss: 416.1666\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 363.6332 - val_loss: 410.3427\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 372.4987 - val_loss: 402.4885\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 348.8474 - val_loss: 397.0127\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 325.8798 - val_loss: 389.7436\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 343.8586 - val_loss: 382.1454\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 308.6044 - val_loss: 376.7043\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 299.8670 - val_loss: 370.3521\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 302.3920 - val_loss: 365.5031\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 308.6574 - val_loss: 358.6719\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 303.1126 - val_loss: 353.6720\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 285.0899 - val_loss: 349.0122\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.3850 - val_loss: 344.3788\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.3354 - val_loss: 339.1699\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 288.9428 - val_loss: 335.1082\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 263.5497 - val_loss: 331.2707\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 275.5325 - val_loss: 325.8549\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278.3870 - val_loss: 322.6564\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 259.8285 - val_loss: 318.3065\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.2438 - val_loss: 314.5406\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 257.7426 - val_loss: 310.5009\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.7429 - val_loss: 307.2349\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 261.4657 - val_loss: 303.6532\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 271.4895 - val_loss: 300.5866\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.5378 - val_loss: 297.3187\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 233.0301 - val_loss: 294.1461\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.0458 - val_loss: 290.9875\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.5853 - val_loss: 288.1069\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.0286 - val_loss: 285.2477\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.2670 - val_loss: 282.9701\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.3976 - val_loss: 279.7994\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 231.6995 - val_loss: 277.1269\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 229.6623 - val_loss: 275.3301\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 210.9665 - val_loss: 272.1859\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.3958 - val_loss: 269.8401\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.0140 - val_loss: 267.9248\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.4859 - val_loss: 265.7162\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.4892 - val_loss: 262.9039\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 223.8642 - val_loss: 261.1673\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.2309 - val_loss: 258.6900\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.9072 - val_loss: 256.6945\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.3766 - val_loss: 254.7146\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.8647 - val_loss: 252.6389\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 213.0871 - val_loss: 250.7936\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.5018 - val_loss: 248.7884\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.9692 - val_loss: 246.9859\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 192.0551 - val_loss: 245.5119\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.4860 - val_loss: 243.5700\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.2265 - val_loss: 241.6921\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.4938 - val_loss: 239.9084\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.0527 - val_loss: 238.3921\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.1524 - val_loss: 236.8898\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  30 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 8200.7260 - val_loss: 1574.8402\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 823.6258 - val_loss: 573.9669\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 589.0298 - val_loss: 432.1825\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 349.8480 - val_loss: 342.1919\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 273.9434 - val_loss: 246.9759\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 245.1007 - val_loss: 213.2613\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 203.3013 - val_loss: 202.6687\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.1347 - val_loss: 188.3035\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.5867 - val_loss: 182.3388\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.2972 - val_loss: 177.8272\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.3876 - val_loss: 169.6960\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.2331 - val_loss: 166.9241\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.5935 - val_loss: 158.9032\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.8157 - val_loss: 164.5241\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.1994 - val_loss: 151.4361\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.8432 - val_loss: 151.7751\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 134.7051 - val_loss: 146.7736\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.8781 - val_loss: 144.7818\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.0124 - val_loss: 141.8247\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.4214 - val_loss: 140.2401\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.8462 - val_loss: 146.2253\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.3746 - val_loss: 137.0292\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.3256 - val_loss: 134.1483\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.5331 - val_loss: 132.2945\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.8926 - val_loss: 128.9054\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.8360 - val_loss: 135.8171\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.4277 - val_loss: 126.1339\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.0481 - val_loss: 125.1094\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.6450 - val_loss: 127.4399\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.1426 - val_loss: 127.5447\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.7600 - val_loss: 122.1937\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 116.5039 - val_loss: 120.8199\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.1524 - val_loss: 126.8185\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.8483 - val_loss: 118.9216\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.5863 - val_loss: 118.2959\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.3578 - val_loss: 119.6564\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.0834 - val_loss: 119.5401\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.1662 - val_loss: 119.5498\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 116.4083 - val_loss: 116.1160\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.9083 - val_loss: 119.2204\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.8130 - val_loss: 121.0417\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.9493 - val_loss: 113.6529\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.9665 - val_loss: 113.0290\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.4554 - val_loss: 117.7696\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.1340 - val_loss: 115.3616\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.8633 - val_loss: 114.5319\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.6014 - val_loss: 112.8832\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 115.4373 - val_loss: 119.0074\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.9237 - val_loss: 111.9169\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.7142 - val_loss: 111.3897\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.7470 - val_loss: 123.0886\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.3995 - val_loss: 110.1707\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.8470 - val_loss: 109.5269\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.7221 - val_loss: 109.3109\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.4513 - val_loss: 109.2005\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.4468 - val_loss: 110.7230\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.9306 - val_loss: 112.2142\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.0016 - val_loss: 109.9804\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.2894 - val_loss: 114.1437\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.8002 - val_loss: 112.4502\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.5091 - val_loss: 116.2412\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.3593 - val_loss: 107.7264\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.8439 - val_loss: 115.1663\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.9985 - val_loss: 107.6585\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.3290 - val_loss: 111.8541\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.0335 - val_loss: 119.2849\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.2051 - val_loss: 110.2169\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 106.7185 - val_loss: 107.1191\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 108.8416 - val_loss: 107.2007\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.8070 - val_loss: 110.1781\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.8285 - val_loss: 109.4560\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.3403 - val_loss: 110.5669\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.3000 - val_loss: 114.2108\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.7142 - val_loss: 106.4765\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.8635 - val_loss: 107.6033\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 104.0840 - val_loss: 105.9049\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3780 - val_loss: 105.9433\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 95.9990 - val_loss: 106.4919\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.0696 - val_loss: 107.1912\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.4902 - val_loss: 107.3058\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.1059 - val_loss: 105.6917\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.7782 - val_loss: 108.4761\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.9392 - val_loss: 105.9575\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.5629 - val_loss: 107.5279\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.5918 - val_loss: 106.1046\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.9508 - val_loss: 104.3590\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.8518 - val_loss: 106.2027\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.0514 - val_loss: 105.2392\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.3585 - val_loss: 105.0123\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.0334 - val_loss: 112.8727\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.3140 - val_loss: 108.1925\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.7666 - val_loss: 103.6429\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 99.4330 - val_loss: 102.2695\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.6773 - val_loss: 104.8666\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.9499 - val_loss: 102.2649\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.0210 - val_loss: 103.6503\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.2690 - val_loss: 107.9007\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.0798 - val_loss: 101.5636\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.8440 - val_loss: 100.4560\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.1657 - val_loss: 102.0407\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  31 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 17ms/step - loss: 3210.2570 - val_loss: 2848.0190\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2158.4549 - val_loss: 2241.1133\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1672.6289 - val_loss: 1777.5223\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1441.3503 - val_loss: 1303.1268\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1055.5488 - val_loss: 944.7804\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 820.5120 - val_loss: 694.0550\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 610.0163 - val_loss: 543.8857\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 487.0693 - val_loss: 488.3933\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 462.9825 - val_loss: 377.7474\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 361.7400 - val_loss: 329.1943\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 332.6386 - val_loss: 297.6331\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 304.8293 - val_loss: 287.0580\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.2182 - val_loss: 259.0854\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 239.8211 - val_loss: 255.9261\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 271.8493 - val_loss: 234.7115\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 242.5910 - val_loss: 231.1810\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.0754 - val_loss: 251.3939\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227.3564 - val_loss: 212.6304\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 211.3261 - val_loss: 208.1826\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.9420 - val_loss: 203.2715\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.9594 - val_loss: 208.0732\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 214.2283 - val_loss: 253.8860\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.7973 - val_loss: 211.7817\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.6033 - val_loss: 199.0939\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.8242 - val_loss: 183.7797\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.5287 - val_loss: 202.2473\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 180.2035 - val_loss: 180.7173\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 178.4728 - val_loss: 175.0367\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.3424 - val_loss: 172.7245\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.5297 - val_loss: 185.2026\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.7080 - val_loss: 173.1528\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.0427 - val_loss: 169.1112\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.7177 - val_loss: 163.6907\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.1116 - val_loss: 162.2570\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.4441 - val_loss: 158.8398\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.8088 - val_loss: 163.4855\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.0783 - val_loss: 158.2894\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.2192 - val_loss: 160.1057\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.1725 - val_loss: 182.6837\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 153.9746 - val_loss: 155.4436\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.8374 - val_loss: 156.0035\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.1610 - val_loss: 150.4699\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.1988 - val_loss: 148.2122\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.3465 - val_loss: 178.2955\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.8657 - val_loss: 158.6626\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.8199 - val_loss: 149.9139\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.1750 - val_loss: 147.6945\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.7030 - val_loss: 144.9516\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.3175 - val_loss: 147.6648\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.0758 - val_loss: 143.7000\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.3884 - val_loss: 145.0185\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.0704 - val_loss: 138.8954\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.4204 - val_loss: 138.1871\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.1145 - val_loss: 151.4014\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.8661 - val_loss: 151.2537\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.2690 - val_loss: 149.3654\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.1334 - val_loss: 135.1163\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.8947 - val_loss: 134.5842\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.1081 - val_loss: 163.3177\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.6513 - val_loss: 163.1943\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.0072 - val_loss: 140.2290\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.2942 - val_loss: 190.3982\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.1507 - val_loss: 131.5612\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.6908 - val_loss: 131.7973\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.5520 - val_loss: 143.0343\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.6851 - val_loss: 134.9159\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.9767 - val_loss: 130.6661\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.6415 - val_loss: 173.2779\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.5929 - val_loss: 131.5331\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.1198 - val_loss: 151.8414\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.1194 - val_loss: 144.8834\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 124.4203 - val_loss: 132.9609\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.0218 - val_loss: 138.9762\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.4140 - val_loss: 130.0188\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.1453 - val_loss: 128.1665\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.9774 - val_loss: 129.3640\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.7050 - val_loss: 129.3649\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.6165 - val_loss: 148.7487\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.4173 - val_loss: 135.6955\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 134.6760 - val_loss: 126.5413\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.5908 - val_loss: 145.1674\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.8414 - val_loss: 125.9851\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.7704 - val_loss: 126.9038\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.3094 - val_loss: 128.4104\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4969 - val_loss: 132.6693\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.9263 - val_loss: 178.9558\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 122.3114 - val_loss: 126.2238\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 132.8064 - val_loss: 126.4922\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.2051 - val_loss: 126.1317\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.7443 - val_loss: 126.5985\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.8757 - val_loss: 126.3988\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.8060 - val_loss: 155.7646\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.9851 - val_loss: 125.8840\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.1836 - val_loss: 127.9158\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.8095 - val_loss: 179.2480\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6099 - val_loss: 143.5870\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.4409 - val_loss: 126.2429\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.1710 - val_loss: 127.9856\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.8573 - val_loss: 129.2320\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.8782 - val_loss: 135.4271\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  32 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 35920.1912 - val_loss: 8704.7783\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 5752.8582 - val_loss: 1207.2876\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1323.9007 - val_loss: 1344.8154\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1111.5733 - val_loss: 746.1511\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 768.6670 - val_loss: 579.3110\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 645.5935 - val_loss: 474.3463\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 510.0554 - val_loss: 402.7416\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 474.5555 - val_loss: 352.0056\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 354.1584 - val_loss: 327.3716\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 376.8055 - val_loss: 305.8289\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 354.8349 - val_loss: 291.0489\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 336.4016 - val_loss: 279.8081\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 309.8272 - val_loss: 266.4159\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 292.0527 - val_loss: 259.4026\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.4935 - val_loss: 250.7151\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.3616 - val_loss: 242.0319\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 284.4832 - val_loss: 233.7109\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 272.3640 - val_loss: 227.5409\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.5704 - val_loss: 221.5659\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 277.2381 - val_loss: 214.5461\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 252.7416 - val_loss: 207.9881\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.1692 - val_loss: 200.4186\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.0677 - val_loss: 197.9679\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 243.4283 - val_loss: 190.6015\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 226.0049 - val_loss: 185.6199\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.7289 - val_loss: 180.4976\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.1828 - val_loss: 172.8828\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 210.3822 - val_loss: 171.5901\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 209.4022 - val_loss: 166.5245\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.6013 - val_loss: 158.7206\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.5408 - val_loss: 158.4583\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.3993 - val_loss: 152.0117\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 198.9865 - val_loss: 147.4061\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 199.9482 - val_loss: 143.5085\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.2245 - val_loss: 142.1172\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.6343 - val_loss: 139.5261\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 173.0217 - val_loss: 138.9003\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.2617 - val_loss: 135.5015\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.3090 - val_loss: 131.9715\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.0482 - val_loss: 129.0638\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.6257 - val_loss: 128.4085\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.4551 - val_loss: 132.1187\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.8929 - val_loss: 127.4653\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.7148 - val_loss: 125.2615\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.5852 - val_loss: 123.7028\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.0786 - val_loss: 128.5443\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.4777 - val_loss: 116.3524\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.4622 - val_loss: 120.8318\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.7572 - val_loss: 117.9124\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.7929 - val_loss: 113.1982\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.9002 - val_loss: 111.1497\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.7709 - val_loss: 115.6935\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.7324 - val_loss: 112.4572\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 146.5008 - val_loss: 107.9132\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.9095 - val_loss: 106.8163\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.3737 - val_loss: 107.2102\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.1969 - val_loss: 106.5581\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 140.9177 - val_loss: 104.2553\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.9634 - val_loss: 100.8294\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.3597 - val_loss: 111.9588\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.6019 - val_loss: 100.8042\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.1265 - val_loss: 98.6540\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.5033 - val_loss: 109.7809\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.2732 - val_loss: 103.2278\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.4616 - val_loss: 95.6065\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.1522 - val_loss: 97.7890\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.3596 - val_loss: 95.1572\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.8686 - val_loss: 93.5210\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.8587 - val_loss: 92.0523\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.8288 - val_loss: 100.4528\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 118.8590 - val_loss: 90.3576\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.7669 - val_loss: 91.9277\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.5272 - val_loss: 101.7060\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.2493 - val_loss: 92.4937\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.1178 - val_loss: 96.9725\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.0823 - val_loss: 85.8882\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.6318 - val_loss: 85.0999\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.7822 - val_loss: 88.2811\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.4851 - val_loss: 86.6637\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.5929 - val_loss: 95.5957\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.2313 - val_loss: 83.5220\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.3086 - val_loss: 104.4076\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.6598 - val_loss: 82.1877\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.0337 - val_loss: 80.4547\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.0179 - val_loss: 86.3242\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.4802 - val_loss: 85.2217\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.1436 - val_loss: 88.0823\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.2530 - val_loss: 81.3124\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.9385 - val_loss: 80.1663\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.7585 - val_loss: 77.0965\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.2222 - val_loss: 79.3576\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.2249 - val_loss: 76.9234\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.4449 - val_loss: 88.3124\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.4489 - val_loss: 89.0072\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.7752 - val_loss: 80.8039\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 86.5288 - val_loss: 91.7502\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.9301 - val_loss: 81.4415\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.9249 - val_loss: 74.3088\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.9579 - val_loss: 77.6917\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.6388 - val_loss: 84.1999\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  33 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 23515.2123 - val_loss: 2848.9258\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2730.3361 - val_loss: 3020.0903\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2364.7201 - val_loss: 1831.1661\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1661.2188 - val_loss: 1627.1346\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1470.3316 - val_loss: 1474.3424\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1235.8493 - val_loss: 1301.4706\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1056.1961 - val_loss: 1161.6844\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 925.6827 - val_loss: 1031.4015\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 812.3409 - val_loss: 904.9052\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 784.9405 - val_loss: 787.3469\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 690.4745 - val_loss: 688.0601\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 563.6990 - val_loss: 600.7736\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 510.2134 - val_loss: 528.1982\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 450.0080 - val_loss: 457.7917\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 408.2481 - val_loss: 407.0150\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 363.1021 - val_loss: 364.2537\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 360.7992 - val_loss: 330.0219\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 308.4638 - val_loss: 303.3816\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.3244 - val_loss: 284.0861\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 259.7428 - val_loss: 266.2377\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 292.9302 - val_loss: 258.0432\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.6819 - val_loss: 260.1203\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 229.0015 - val_loss: 233.7711\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.7918 - val_loss: 228.5975\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.8579 - val_loss: 236.3976\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 218.9522 - val_loss: 216.0329\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 212.7281 - val_loss: 211.1726\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.6802 - val_loss: 213.3713\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 197.5458 - val_loss: 207.9448\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 187.1663 - val_loss: 200.8395\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.8940 - val_loss: 198.9551\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 184.7473 - val_loss: 197.2839\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.7940 - val_loss: 192.8063\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.8088 - val_loss: 192.2793\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.5445 - val_loss: 190.0072\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.6952 - val_loss: 186.4910\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.4912 - val_loss: 186.1557\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.9943 - val_loss: 185.1901\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 177.1427 - val_loss: 180.7639\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.4021 - val_loss: 180.2464\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.6687 - val_loss: 175.7001\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.3355 - val_loss: 180.1510\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.5439 - val_loss: 182.5769\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.7001 - val_loss: 168.4739\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.7840 - val_loss: 166.1683\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.1602 - val_loss: 164.9746\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.3810 - val_loss: 162.8684\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.3019 - val_loss: 166.8988\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.9804 - val_loss: 161.1959\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.6328 - val_loss: 158.0417\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.4385 - val_loss: 155.6894\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 129.3767 - val_loss: 153.8163\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.2870 - val_loss: 152.5022\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.2121 - val_loss: 150.7154\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.9655 - val_loss: 167.0533\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.7803 - val_loss: 148.7981\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.0716 - val_loss: 149.8690\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.2709 - val_loss: 145.2258\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.5510 - val_loss: 144.3470\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.0935 - val_loss: 150.4862\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.1600 - val_loss: 142.8428\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.8345 - val_loss: 143.3439\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.9298 - val_loss: 138.9327\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.9315 - val_loss: 138.6224\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.8375 - val_loss: 138.3290\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.8040 - val_loss: 137.1846\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.0800 - val_loss: 137.4615\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.2612 - val_loss: 137.1902\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.7042 - val_loss: 132.8103\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.5956 - val_loss: 133.8345\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 105.3797 - val_loss: 129.9920\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.3556 - val_loss: 129.4913\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.4641 - val_loss: 127.6011\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.5389 - val_loss: 124.8938\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 99.8677 - val_loss: 122.6402\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 108.3063 - val_loss: 119.9525\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.4531 - val_loss: 118.7851\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.7098 - val_loss: 118.4745\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.9661 - val_loss: 115.3499\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.3892 - val_loss: 112.4978\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.5188 - val_loss: 111.1242\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.3901 - val_loss: 109.8948\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.5838 - val_loss: 109.2326\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.4138 - val_loss: 109.7404\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.3722 - val_loss: 112.3460\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.4296 - val_loss: 105.9855\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.3539 - val_loss: 106.2053\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.9223 - val_loss: 103.8164\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.6110 - val_loss: 104.1309\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.0476 - val_loss: 117.7421\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.1187 - val_loss: 101.5666\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.2286 - val_loss: 99.5894\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.8637 - val_loss: 100.3223\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 73.2615 - val_loss: 101.1809\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.6113 - val_loss: 110.4831\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.8691 - val_loss: 105.2939\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.5794 - val_loss: 101.8966\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.9064 - val_loss: 99.0353\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.5001 - val_loss: 95.8654\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.6678 - val_loss: 94.6624\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  34 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 164772.7647 - val_loss: 116256.6641\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97449.0101 - val_loss: 64486.8242\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 51658.8667 - val_loss: 33358.4023\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 26080.9640 - val_loss: 16181.9023\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 12555.4200 - val_loss: 7356.3813\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5498.7325 - val_loss: 3276.7417\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2180.1872 - val_loss: 1497.4084\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1124.7289 - val_loss: 732.7746\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 612.0209 - val_loss: 507.3638\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 463.8937 - val_loss: 457.6999\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 406.1910 - val_loss: 426.3796\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 405.8623 - val_loss: 383.1432\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 347.8897 - val_loss: 333.9608\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 304.6144 - val_loss: 297.1252\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 305.7443 - val_loss: 275.1833\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.0330 - val_loss: 262.1313\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 280.8524 - val_loss: 251.1683\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 246.3764 - val_loss: 248.2298\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.8168 - val_loss: 237.9509\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 236.1015 - val_loss: 234.5580\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.7360 - val_loss: 233.3497\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.0914 - val_loss: 220.8424\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.2024 - val_loss: 218.2337\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 230.0117 - val_loss: 213.0744\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.1088 - val_loss: 207.4072\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.8533 - val_loss: 203.4765\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 230.7759 - val_loss: 199.5976\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.0561 - val_loss: 198.0564\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.4414 - val_loss: 194.0689\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.3279 - val_loss: 190.7412\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.7451 - val_loss: 188.4364\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.8873 - val_loss: 184.9280\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.5444 - val_loss: 189.2426\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.4376 - val_loss: 184.7780\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.3858 - val_loss: 177.3762\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.5812 - val_loss: 173.2251\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.3906 - val_loss: 170.9359\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.4418 - val_loss: 168.6428\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.5713 - val_loss: 167.3482\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.2891 - val_loss: 164.0985\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.2064 - val_loss: 162.4430\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.3608 - val_loss: 159.2200\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.8408 - val_loss: 157.6512\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.3385 - val_loss: 155.9809\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.6089 - val_loss: 154.1866\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165.7657 - val_loss: 153.1136\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.8355 - val_loss: 149.6905\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.3922 - val_loss: 148.5618\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.4477 - val_loss: 147.6437\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.9640 - val_loss: 150.5351\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.1093 - val_loss: 144.1683\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.7348 - val_loss: 142.1226\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.7782 - val_loss: 141.4031\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.7005 - val_loss: 140.8285\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.8980 - val_loss: 138.0061\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.3593 - val_loss: 136.1708\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.9201 - val_loss: 143.9379\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.2793 - val_loss: 134.4264\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.3485 - val_loss: 132.6721\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.3740 - val_loss: 133.5595\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.1808 - val_loss: 133.6784\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.1574 - val_loss: 130.7934\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.6055 - val_loss: 128.4263\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 131.4509 - val_loss: 127.7376\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.0759 - val_loss: 126.5085\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.8371 - val_loss: 124.5297\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.3511 - val_loss: 124.1776\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.8335 - val_loss: 130.6212\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.0595 - val_loss: 121.8440\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.2342 - val_loss: 121.3655\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.8892 - val_loss: 120.4986\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.1871 - val_loss: 120.6561\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 139.0674 - val_loss: 119.1699\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.7070 - val_loss: 118.6542\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.6765 - val_loss: 118.2505\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.2882 - val_loss: 117.8295\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.9560 - val_loss: 118.6623\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.8747 - val_loss: 122.9728\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.9875 - val_loss: 114.5971\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.7338 - val_loss: 116.6231\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.8288 - val_loss: 113.4034\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.2140 - val_loss: 112.6359\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.3797 - val_loss: 113.1083\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.0945 - val_loss: 112.5663\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 123.1007 - val_loss: 119.4723\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.8039 - val_loss: 116.7530\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.8990 - val_loss: 111.4023\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.9790 - val_loss: 110.2489\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.7332 - val_loss: 110.4622\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.3410 - val_loss: 108.8487\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.2001 - val_loss: 108.4499\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.4811 - val_loss: 111.2461\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.1030 - val_loss: 107.6656\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.6184 - val_loss: 108.2758\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.7443 - val_loss: 108.8600\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.6137 - val_loss: 106.4811\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.5697 - val_loss: 106.3124\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.9062 - val_loss: 105.9086\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.9934 - val_loss: 106.1425\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.7153 - val_loss: 105.1663\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  35 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 21540.5562 - val_loss: 6735.8320\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5141.8253 - val_loss: 1413.8657\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1135.9183 - val_loss: 1087.2639\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 831.3193 - val_loss: 971.7303\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 751.8792 - val_loss: 828.3014\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 687.7038 - val_loss: 731.8018\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 611.7655 - val_loss: 660.5726\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 618.0194 - val_loss: 595.1951\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 500.2295 - val_loss: 544.4311\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 472.0380 - val_loss: 496.8391\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 432.1975 - val_loss: 453.2502\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 402.0337 - val_loss: 419.9237\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 341.1684 - val_loss: 389.4113\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 335.9142 - val_loss: 361.3418\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 315.7052 - val_loss: 339.4401\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 336.4042 - val_loss: 321.1351\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 309.4389 - val_loss: 306.0085\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.8029 - val_loss: 292.6147\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.6446 - val_loss: 282.5354\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 262.6565 - val_loss: 274.4753\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 292.6319 - val_loss: 267.5825\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.8664 - val_loss: 261.6268\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 258.0236 - val_loss: 256.9527\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.5084 - val_loss: 252.7715\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 250.8806 - val_loss: 248.6998\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 263.4666 - val_loss: 246.1970\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 262.1808 - val_loss: 243.7007\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 279.6335 - val_loss: 241.8144\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.7425 - val_loss: 240.1785\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.0439 - val_loss: 238.3895\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.5403 - val_loss: 237.0135\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.8907 - val_loss: 235.3479\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 257.0876 - val_loss: 234.0215\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 249.8700 - val_loss: 232.3926\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.4091 - val_loss: 231.3418\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.0103 - val_loss: 229.7060\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 235.6841 - val_loss: 228.1804\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.0513 - val_loss: 227.0248\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.2898 - val_loss: 225.5034\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 246.0414 - val_loss: 224.0140\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.0448 - val_loss: 222.4955\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.0491 - val_loss: 221.2294\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.0316 - val_loss: 219.5959\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 225.7833 - val_loss: 218.1906\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.1839 - val_loss: 217.1524\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.8606 - val_loss: 215.5756\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.6335 - val_loss: 213.6530\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 219.4164 - val_loss: 212.0542\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 237.6590 - val_loss: 210.2938\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 227.1924 - val_loss: 208.8584\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.5519 - val_loss: 207.0864\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 234.9891 - val_loss: 205.3018\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.8877 - val_loss: 203.6171\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.8216 - val_loss: 201.8643\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.7094 - val_loss: 199.9713\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.7068 - val_loss: 198.1970\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.1952 - val_loss: 196.6556\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 213.8166 - val_loss: 194.4994\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.1367 - val_loss: 192.6595\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 194.7489 - val_loss: 190.8949\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.0242 - val_loss: 189.0131\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 189.6322 - val_loss: 186.5137\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.2577 - val_loss: 184.3499\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.5329 - val_loss: 182.2801\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.6011 - val_loss: 180.3307\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.4426 - val_loss: 178.5188\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.0043 - val_loss: 175.9968\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.6601 - val_loss: 173.5968\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 174.2819 - val_loss: 171.5756\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.6885 - val_loss: 169.4884\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.5503 - val_loss: 167.3000\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.5528 - val_loss: 166.0521\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.0510 - val_loss: 163.0295\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.4587 - val_loss: 161.5859\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.2289 - val_loss: 159.2883\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.1770 - val_loss: 157.0973\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.2010 - val_loss: 155.2254\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.8228 - val_loss: 153.3849\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.1148 - val_loss: 152.0326\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.3011 - val_loss: 150.4431\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.9572 - val_loss: 148.3129\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.9000 - val_loss: 146.3533\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.0913 - val_loss: 144.9742\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 144.2757 - val_loss: 143.7685\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.4027 - val_loss: 141.6849\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.3278 - val_loss: 140.0367\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.3612 - val_loss: 138.7366\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 134.4929 - val_loss: 137.1046\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.2391 - val_loss: 135.3598\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.6581 - val_loss: 133.9865\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.7534 - val_loss: 131.8416\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.3841 - val_loss: 130.8181\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.1826 - val_loss: 129.0450\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.3153 - val_loss: 128.7835\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.8442 - val_loss: 127.2995\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.9857 - val_loss: 126.9793\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.1493 - val_loss: 125.3570\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.8129 - val_loss: 125.4153\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.9631 - val_loss: 123.5894\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.2753 - val_loss: 122.8160\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  36 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 18ms/step - loss: 17604.7748 - val_loss: 5725.1475\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6253.2861 - val_loss: 5827.5845\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5150.8965 - val_loss: 4622.0151\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5229.5547 - val_loss: 4025.4165\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4430.1234 - val_loss: 3512.9612\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3920.2236 - val_loss: 3059.3965\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3118.6430 - val_loss: 2635.8054\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2739.3766 - val_loss: 2290.6921\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2456.5873 - val_loss: 1984.0665\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2076.9525 - val_loss: 1727.7762\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 1892.0372 - val_loss: 1509.5294\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1564.3710 - val_loss: 1313.1173\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1240.6033 - val_loss: 1195.9315\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1273.7725 - val_loss: 1019.1652\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 970.8188 - val_loss: 903.7046\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 864.7137 - val_loss: 825.6473\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 748.7739 - val_loss: 719.4516\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 691.2400 - val_loss: 635.0802\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 646.6720 - val_loss: 566.6429\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 521.4391 - val_loss: 501.5915\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 519.1781 - val_loss: 447.6472\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 426.3774 - val_loss: 394.6750\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 398.8632 - val_loss: 382.0572\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 364.7659 - val_loss: 319.4175\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.1958 - val_loss: 296.8381\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 265.0853 - val_loss: 278.6714\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 287.5240 - val_loss: 247.8071\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.2847 - val_loss: 224.8305\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.4195 - val_loss: 214.1831\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.3104 - val_loss: 196.7894\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 198.6515 - val_loss: 186.1490\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.6539 - val_loss: 176.2660\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 170.7430 - val_loss: 163.0871\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.1319 - val_loss: 165.2817\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.3470 - val_loss: 167.5466\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.6457 - val_loss: 145.0324\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.0104 - val_loss: 140.4004\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.5917 - val_loss: 134.3785\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.4085 - val_loss: 135.6329\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.6138 - val_loss: 139.9108\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.2547 - val_loss: 135.8360\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.5032 - val_loss: 123.5765\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.5706 - val_loss: 132.2941\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.6192 - val_loss: 119.5234\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.8274 - val_loss: 120.7061\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 124.9530 - val_loss: 122.5235\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.8925 - val_loss: 120.1861\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.0656 - val_loss: 124.2158\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.4373 - val_loss: 114.1294\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.3897 - val_loss: 120.2945\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.0540 - val_loss: 112.9617\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.7119 - val_loss: 109.8535\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.7634 - val_loss: 113.8709\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.3141 - val_loss: 116.3700\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3478 - val_loss: 110.4132\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.7447 - val_loss: 108.9912\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 122.2218 - val_loss: 107.6586\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.9041 - val_loss: 106.7497\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 119.0612 - val_loss: 111.3809\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.4830 - val_loss: 121.9641\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.0511 - val_loss: 130.9130\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.2214 - val_loss: 117.8833\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.0639 - val_loss: 108.0672\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.1290 - val_loss: 118.7217\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.7909 - val_loss: 118.6703\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.0994 - val_loss: 118.0631\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.2139 - val_loss: 104.8043\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 114.7322 - val_loss: 105.8997\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.3230 - val_loss: 105.5356\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.6656 - val_loss: 105.7832\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.0637 - val_loss: 111.7457\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.4701 - val_loss: 117.8368\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.0782 - val_loss: 108.2686\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.2671 - val_loss: 119.7537\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.9848 - val_loss: 129.6901\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.9921 - val_loss: 113.1602\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.2251 - val_loss: 109.8945\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.6390 - val_loss: 112.2597\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.5570 - val_loss: 119.6955\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.8566 - val_loss: 110.4659\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.4332 - val_loss: 104.9933\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.1737 - val_loss: 102.4919\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.0281 - val_loss: 119.2450\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.9473 - val_loss: 110.1459\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.8304 - val_loss: 116.9105\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.7078 - val_loss: 112.3409\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.3379 - val_loss: 102.1829\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.2649 - val_loss: 106.7603\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.4817 - val_loss: 104.9345\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.5694 - val_loss: 103.9977\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.7886 - val_loss: 102.6003\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.5252 - val_loss: 122.3843\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.3275 - val_loss: 107.6810\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.3408 - val_loss: 103.3792\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.2177 - val_loss: 108.8203\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.8209 - val_loss: 101.0795\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.0016 - val_loss: 104.3130\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.3883 - val_loss: 114.7609\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.2219 - val_loss: 117.5325\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.4729 - val_loss: 113.1588\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  37 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 26ms/step - loss: 15783.3487 - val_loss: 5114.9556\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3901.9064 - val_loss: 1424.5591\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1420.9527 - val_loss: 985.1337\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1013.0099 - val_loss: 883.6589\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 975.1845 - val_loss: 730.8870\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 705.5585 - val_loss: 639.4331\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 659.5345 - val_loss: 568.8290\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 585.0046 - val_loss: 513.4184\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 598.0127 - val_loss: 464.8206\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 515.3161 - val_loss: 426.4066\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 472.0113 - val_loss: 393.7519\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 390.7079 - val_loss: 368.4280\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 364.4443 - val_loss: 343.9169\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 403.1536 - val_loss: 326.0159\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 352.2469 - val_loss: 312.6000\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 339.2581 - val_loss: 299.8021\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 322.0724 - val_loss: 288.7209\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 318.0905 - val_loss: 276.6336\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 342.1556 - val_loss: 267.7206\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 261.2849 - val_loss: 260.2471\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 294.4646 - val_loss: 251.9277\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.0981 - val_loss: 244.4004\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 284.2683 - val_loss: 238.7626\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 300.8882 - val_loss: 232.7469\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253.7058 - val_loss: 227.6490\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 260.3789 - val_loss: 222.6062\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 254.2816 - val_loss: 217.8029\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 270.5391 - val_loss: 213.4852\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 255.6110 - val_loss: 209.4555\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 244.7075 - val_loss: 205.4066\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 229.0613 - val_loss: 201.6214\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 214.2157 - val_loss: 198.2256\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 237.7141 - val_loss: 194.3070\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.6338 - val_loss: 191.2777\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 209.2647 - val_loss: 188.4971\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.3720 - val_loss: 185.3626\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.9962 - val_loss: 182.4822\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 221.6981 - val_loss: 179.7143\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 246.0490 - val_loss: 177.7267\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 232.7807 - val_loss: 174.2728\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.8082 - val_loss: 171.4190\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.5608 - val_loss: 169.2574\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.8479 - val_loss: 166.7198\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.6990 - val_loss: 164.4942\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 203.8026 - val_loss: 162.3931\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 195.8532 - val_loss: 159.4658\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.6537 - val_loss: 157.6168\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.7417 - val_loss: 156.1158\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 203.2623 - val_loss: 153.5707\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.1249 - val_loss: 151.5039\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.6127 - val_loss: 150.3500\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.8474 - val_loss: 147.9021\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.1908 - val_loss: 146.2536\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.6753 - val_loss: 143.9316\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 174.0662 - val_loss: 142.0933\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.3972 - val_loss: 140.6912\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 180.9691 - val_loss: 139.2915\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.4625 - val_loss: 137.0831\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.4876 - val_loss: 135.5586\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.3256 - val_loss: 133.9167\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.5689 - val_loss: 132.6063\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 182.0461 - val_loss: 131.0859\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 167.2579 - val_loss: 128.8639\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.4145 - val_loss: 127.5351\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.8524 - val_loss: 126.9908\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.6574 - val_loss: 124.3694\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.7975 - val_loss: 123.6060\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 137.2538 - val_loss: 121.5162\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.3573 - val_loss: 120.3282\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.3230 - val_loss: 118.9193\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.7336 - val_loss: 116.9162\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.3654 - val_loss: 117.5823\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.9549 - val_loss: 114.4124\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.2744 - val_loss: 113.4717\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.3372 - val_loss: 111.9457\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.4714 - val_loss: 110.9147\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.4528 - val_loss: 109.2434\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.0893 - val_loss: 108.2640\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.4696 - val_loss: 106.4579\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.3837 - val_loss: 106.1108\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.9654 - val_loss: 104.7306\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.2250 - val_loss: 104.2398\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.4289 - val_loss: 101.9940\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.3437 - val_loss: 101.1677\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.2990 - val_loss: 99.8203\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.4322 - val_loss: 99.5753\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.7514 - val_loss: 97.6839\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.9371 - val_loss: 96.4810\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.2912 - val_loss: 96.0062\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.2115 - val_loss: 94.4249\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.1851 - val_loss: 93.9622\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.5309 - val_loss: 93.2789\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.6012 - val_loss: 91.6694\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8706 - val_loss: 90.7992\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.0579 - val_loss: 90.1900\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.9675 - val_loss: 88.5873\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.0120 - val_loss: 87.7262\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.1257 - val_loss: 88.1113\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.2863 - val_loss: 86.0092\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.7220 - val_loss: 86.7421\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  38 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 16871.2725 - val_loss: 8787.5371\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 6604.1381 - val_loss: 3456.4741\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2573.6885 - val_loss: 1840.1810\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1469.5126 - val_loss: 1409.2275\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1302.8300 - val_loss: 1233.6417\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 1182.2209 - val_loss: 1129.0074\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1136.7629 - val_loss: 1036.3566\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1088.1123 - val_loss: 931.8213\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 968.3201 - val_loss: 801.7236\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 734.6770 - val_loss: 657.0887\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 656.7694 - val_loss: 540.4289\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 552.7096 - val_loss: 447.1122\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 436.3133 - val_loss: 376.9005\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 386.9149 - val_loss: 327.9155\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 372.4924 - val_loss: 288.7206\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 318.4473 - val_loss: 264.7656\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 289.8300 - val_loss: 247.1712\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 276.2958 - val_loss: 235.7989\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 266.0343 - val_loss: 226.6589\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 273.4123 - val_loss: 218.5895\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 272.1728 - val_loss: 211.8288\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.3815 - val_loss: 207.9659\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 255.3416 - val_loss: 203.1495\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 216.1665 - val_loss: 199.9894\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 226.5816 - val_loss: 195.5034\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 209.0648 - val_loss: 191.9812\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.5961 - val_loss: 189.0575\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 220.2849 - val_loss: 185.4565\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 221.7982 - val_loss: 182.8609\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 199.4541 - val_loss: 180.2469\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.3007 - val_loss: 177.8643\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.0530 - val_loss: 175.4565\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.3063 - val_loss: 173.1908\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 219.7667 - val_loss: 170.8162\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 204.4408 - val_loss: 168.8859\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 194.7460 - val_loss: 166.3718\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 188.9309 - val_loss: 164.5640\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 180.9900 - val_loss: 162.7122\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.9445 - val_loss: 160.8633\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.9738 - val_loss: 159.0570\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.1997 - val_loss: 157.3947\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.4378 - val_loss: 155.9072\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.9157 - val_loss: 155.0811\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.3215 - val_loss: 153.2768\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.9230 - val_loss: 151.7534\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.3576 - val_loss: 150.4379\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.1728 - val_loss: 149.2782\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.0339 - val_loss: 148.1263\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.1516 - val_loss: 146.9458\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.2584 - val_loss: 146.0332\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.9375 - val_loss: 145.6764\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 141.7863 - val_loss: 144.3711\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.1263 - val_loss: 144.3288\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.6650 - val_loss: 142.3510\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.0379 - val_loss: 142.2700\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.2649 - val_loss: 141.7516\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 135.1919 - val_loss: 140.9542\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.3794 - val_loss: 139.2829\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.2406 - val_loss: 139.6981\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 140.4298 - val_loss: 138.2563\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.5265 - val_loss: 139.9690\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.3787 - val_loss: 139.8617\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.7945 - val_loss: 137.0809\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.1930 - val_loss: 136.2345\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.7327 - val_loss: 135.9854\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.8007 - val_loss: 135.3601\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.2095 - val_loss: 138.6021\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.5408 - val_loss: 136.5125\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.1311 - val_loss: 133.2425\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.4084 - val_loss: 132.5540\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.0252 - val_loss: 133.9054\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.3642 - val_loss: 130.9511\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.5894 - val_loss: 132.1706\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.2876 - val_loss: 129.7578\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.5146 - val_loss: 131.9483\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.1876 - val_loss: 127.7895\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 116.0041 - val_loss: 126.6670\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 106.3094 - val_loss: 126.5469\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.4666 - val_loss: 126.9445\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.3013 - val_loss: 124.3331\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.9991 - val_loss: 123.9400\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.1996 - val_loss: 122.8894\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 98.2029 - val_loss: 121.8698\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.6002 - val_loss: 120.9479\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.0358 - val_loss: 120.8813\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.6447 - val_loss: 120.7405\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.5665 - val_loss: 120.9978\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.9174 - val_loss: 124.2885\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.1070 - val_loss: 120.2228\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.6197 - val_loss: 118.1508\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.1512 - val_loss: 116.9137\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.3438 - val_loss: 116.8624\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.2171 - val_loss: 115.5525\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.0477 - val_loss: 114.7445\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.9391 - val_loss: 125.1415\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.8105 - val_loss: 114.1175\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.0432 - val_loss: 113.3633\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 97.4089 - val_loss: 116.2321\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.0690 - val_loss: 112.8126\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.0709 - val_loss: 110.9475\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  39 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 2181.0052 - val_loss: 895.9660\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 668.1308 - val_loss: 533.2637\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 460.5068 - val_loss: 418.9595\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 359.0701 - val_loss: 351.1259\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 290.8186 - val_loss: 320.7099\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 274.9260 - val_loss: 293.3172\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 244.3635 - val_loss: 268.9991\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.9027 - val_loss: 254.6811\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 202.9223 - val_loss: 251.0703\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.3372 - val_loss: 232.0705\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 186.6955 - val_loss: 224.5203\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 182.5922 - val_loss: 221.2470\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 179.6955 - val_loss: 212.8821\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.1634 - val_loss: 205.5269\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165.2431 - val_loss: 200.3151\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165.5487 - val_loss: 204.3962\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.2780 - val_loss: 193.1291\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.9743 - val_loss: 189.6600\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.7355 - val_loss: 187.0385\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.9902 - val_loss: 183.7000\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.9380 - val_loss: 185.2382\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.2402 - val_loss: 181.1117\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.1367 - val_loss: 177.6507\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 139.3143 - val_loss: 178.1043\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.7211 - val_loss: 176.0800\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.3608 - val_loss: 172.8132\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.6840 - val_loss: 170.0852\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.3519 - val_loss: 168.4005\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.6583 - val_loss: 177.6191\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.0674 - val_loss: 169.5288\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.0728 - val_loss: 164.3518\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.6280 - val_loss: 164.0366\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.2366 - val_loss: 161.4966\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.0570 - val_loss: 166.3552\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.4449 - val_loss: 159.4027\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.6299 - val_loss: 157.1368\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.7924 - val_loss: 163.0308\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.5290 - val_loss: 154.8584\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.0392 - val_loss: 154.0278\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.6617 - val_loss: 154.5876\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.0580 - val_loss: 154.8165\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 125.7559 - val_loss: 150.3019\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.9201 - val_loss: 150.3553\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.9514 - val_loss: 145.4160\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.3226 - val_loss: 144.4148\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 112.2714 - val_loss: 145.3701\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.1225 - val_loss: 142.0360\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.7941 - val_loss: 141.0247\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.5533 - val_loss: 140.2436\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 108.6368 - val_loss: 138.0972\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.4826 - val_loss: 138.4587\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.4368 - val_loss: 135.2319\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.5155 - val_loss: 137.5078\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.3322 - val_loss: 132.0647\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.5257 - val_loss: 131.0596\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.8165 - val_loss: 131.6179\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.7356 - val_loss: 131.9121\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.2956 - val_loss: 126.9714\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.3558 - val_loss: 126.5841\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.2416 - val_loss: 124.0395\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.4591 - val_loss: 123.9893\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.5003 - val_loss: 122.9036\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.6255 - val_loss: 120.5661\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1321 - val_loss: 123.5165\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.3730 - val_loss: 118.5763\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.3676 - val_loss: 117.4370\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.3180 - val_loss: 118.1599\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.4722 - val_loss: 115.7182\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.6661 - val_loss: 117.5591\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.9766 - val_loss: 116.9172\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.6181 - val_loss: 111.8390\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.1345 - val_loss: 110.7188\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.3034 - val_loss: 110.2221\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.1314 - val_loss: 108.8238\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.3713 - val_loss: 108.4413\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.1055 - val_loss: 110.7998\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.3664 - val_loss: 110.0333\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.3165 - val_loss: 106.2206\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.8511 - val_loss: 107.4582\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.7266 - val_loss: 103.5068\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.2177 - val_loss: 103.7734\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 80.0188 - val_loss: 101.3658\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.9903 - val_loss: 99.3703\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 72.8053 - val_loss: 97.8439\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.8041 - val_loss: 97.4811\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 69.5016 - val_loss: 101.9703\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 76.3183 - val_loss: 97.5353\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 69.8405 - val_loss: 105.1509\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.4253 - val_loss: 95.3061\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.0567 - val_loss: 92.0875\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.4787 - val_loss: 90.7422\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 63.1069 - val_loss: 90.1052\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 61.6088 - val_loss: 95.0583\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 69.9574 - val_loss: 93.5051\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 69.8187 - val_loss: 88.3524\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 73.8610 - val_loss: 88.6131\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.8169 - val_loss: 89.6895\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 68.9837 - val_loss: 88.7672\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 71.7968 - val_loss: 89.2187\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 72.5852 - val_loss: 87.1025\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  40 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 46972.0391 - val_loss: 25177.0879\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 21355.3835 - val_loss: 11381.8125\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 9311.1463 - val_loss: 5271.1753\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 4309.9796 - val_loss: 2503.0811\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1876.3108 - val_loss: 1429.3459\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1316.7866 - val_loss: 1080.0054\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 959.2456 - val_loss: 962.7084\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 940.2801 - val_loss: 875.9218\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 767.7837 - val_loss: 805.4059\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 683.6814 - val_loss: 748.5946\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 635.1013 - val_loss: 694.6811\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 640.3682 - val_loss: 649.2420\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 557.7387 - val_loss: 608.5957\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 548.3312 - val_loss: 569.5223\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 556.2794 - val_loss: 525.2838\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 523.5208 - val_loss: 485.0616\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 396.4510 - val_loss: 446.8163\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 416.2379 - val_loss: 407.4746\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 360.1407 - val_loss: 369.5847\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 314.5760 - val_loss: 338.7520\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 307.1400 - val_loss: 302.7961\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 278.0509 - val_loss: 275.1096\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 254.3873 - val_loss: 242.1869\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 220.7936 - val_loss: 216.5735\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 198.0068 - val_loss: 203.4919\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 176.5856 - val_loss: 197.1696\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 169.3254 - val_loss: 191.6102\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165.0194 - val_loss: 185.3391\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.7842 - val_loss: 181.9192\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.7338 - val_loss: 176.2532\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.5152 - val_loss: 171.2361\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.8743 - val_loss: 172.9790\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.9711 - val_loss: 168.5105\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.3593 - val_loss: 165.1292\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137.0844 - val_loss: 162.6442\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.6418 - val_loss: 162.8751\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.5293 - val_loss: 158.9861\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.0676 - val_loss: 157.4528\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.0125 - val_loss: 157.4486\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.1168 - val_loss: 157.5423\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.7505 - val_loss: 155.5180\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.3581 - val_loss: 153.7865\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.8376 - val_loss: 153.0705\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 122.2588 - val_loss: 150.6134\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4107 - val_loss: 151.6174\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.8215 - val_loss: 150.5628\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.1641 - val_loss: 149.3862\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.3250 - val_loss: 150.9883\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.8666 - val_loss: 146.4518\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.2421 - val_loss: 146.0279\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.7706 - val_loss: 148.8121\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.6548 - val_loss: 145.7548\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.6130 - val_loss: 143.6123\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.7131 - val_loss: 143.2287\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 118.0632 - val_loss: 143.9124\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.9872 - val_loss: 142.4315\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.2998 - val_loss: 146.9741\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.5871 - val_loss: 140.4763\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3525 - val_loss: 140.8911\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.2869 - val_loss: 139.0555\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.1377 - val_loss: 139.3589\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.2992 - val_loss: 139.1699\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.9606 - val_loss: 138.0317\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4900 - val_loss: 136.7271\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.9344 - val_loss: 136.6535\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.8501 - val_loss: 136.1023\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.1036 - val_loss: 135.8467\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.0273 - val_loss: 135.3980\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.0645 - val_loss: 135.5136\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.0861 - val_loss: 134.1501\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 98.6059 - val_loss: 134.9457\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.5540 - val_loss: 132.9505\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.0269 - val_loss: 133.5453\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.5483 - val_loss: 132.7147\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.2636 - val_loss: 132.0028\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.1685 - val_loss: 131.8728\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.5408 - val_loss: 131.1024\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.4511 - val_loss: 130.8564\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.3529 - val_loss: 128.9480\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1945 - val_loss: 129.1211\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.4972 - val_loss: 128.4641\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 110.3727 - val_loss: 128.3281\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.1427 - val_loss: 127.0760\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.7094 - val_loss: 127.4730\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.3769 - val_loss: 126.5435\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.8514 - val_loss: 126.5389\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.9357 - val_loss: 125.8615\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.7022 - val_loss: 124.8351\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.0800 - val_loss: 124.2427\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 97.2232 - val_loss: 125.6273\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.4518 - val_loss: 123.5922\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.5954 - val_loss: 122.0689\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.3496 - val_loss: 125.3081\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.2945 - val_loss: 121.3553\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.8390 - val_loss: 125.5309\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.4893 - val_loss: 119.8907\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.2517 - val_loss: 119.2710\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.0655 - val_loss: 121.0059\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.3964 - val_loss: 120.1902\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8305 - val_loss: 127.2012\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  41 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 424.2227 - val_loss: 297.8171\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 273.9769 - val_loss: 289.0417\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 248.1360 - val_loss: 256.4170\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 229.5243 - val_loss: 250.2092\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 212.2115 - val_loss: 244.1015\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.9326 - val_loss: 239.3575\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.4153 - val_loss: 236.3843\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.7301 - val_loss: 232.0084\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 188.7515 - val_loss: 226.0223\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.5594 - val_loss: 229.3545\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 188.2246 - val_loss: 220.0368\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 195.4589 - val_loss: 216.3495\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 196.5755 - val_loss: 214.3259\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.9022 - val_loss: 208.9578\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 183.3548 - val_loss: 206.4029\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.3363 - val_loss: 199.0667\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.9132 - val_loss: 198.0530\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 188.9871 - val_loss: 198.5617\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.9278 - val_loss: 192.9530\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 158.4904 - val_loss: 188.6591\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.3419 - val_loss: 184.2929\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.4771 - val_loss: 191.3706\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.3354 - val_loss: 180.2838\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.8126 - val_loss: 178.1104\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.4298 - val_loss: 174.5449\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 148.3574 - val_loss: 174.6031\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.5482 - val_loss: 170.7372\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 138.9516 - val_loss: 172.6054\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.5010 - val_loss: 168.1403\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.2321 - val_loss: 162.1605\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 144.3122 - val_loss: 162.5223\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.9567 - val_loss: 156.1415\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.1180 - val_loss: 158.1830\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.5498 - val_loss: 155.7620\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.6148 - val_loss: 153.7655\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.7348 - val_loss: 165.4630\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.8786 - val_loss: 149.2741\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.1190 - val_loss: 144.1666\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 129.0675 - val_loss: 156.1232\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127.2871 - val_loss: 141.8301\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.5665 - val_loss: 150.1565\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.6059 - val_loss: 143.8534\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 132.3052 - val_loss: 138.5819\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130.7342 - val_loss: 137.4356\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.8965 - val_loss: 154.7782\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.7799 - val_loss: 134.8004\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.4801 - val_loss: 134.6443\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.8127 - val_loss: 137.7773\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.6826 - val_loss: 135.5906\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.7056 - val_loss: 134.5871\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.4619 - val_loss: 129.1185\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.0337 - val_loss: 132.9377\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.0343 - val_loss: 127.8703\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.5964 - val_loss: 130.6902\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 129.7949 - val_loss: 129.6532\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.1322 - val_loss: 125.6280\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.4764 - val_loss: 127.9049\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.9948 - val_loss: 124.5749\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.6754 - val_loss: 127.0753\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.5118 - val_loss: 125.5987\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.1553 - val_loss: 121.0310\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.7300 - val_loss: 119.2495\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.8924 - val_loss: 121.3601\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.6992 - val_loss: 120.4650\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.6796 - val_loss: 118.6640\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.5552 - val_loss: 116.1723\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.0236 - val_loss: 115.8672\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.6024 - val_loss: 131.2005\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.5680 - val_loss: 115.8023\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.8913 - val_loss: 111.8954\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.8729 - val_loss: 111.8141\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.2388 - val_loss: 124.2060\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.9330 - val_loss: 109.1086\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.2843 - val_loss: 112.6344\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.0268 - val_loss: 107.9189\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.1980 - val_loss: 110.8013\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.1280 - val_loss: 106.9936\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.8468 - val_loss: 105.2030\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.3862 - val_loss: 106.3901\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.2262 - val_loss: 104.7828\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.0609 - val_loss: 101.7634\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.6037 - val_loss: 104.8249\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.8621 - val_loss: 101.2031\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.9380 - val_loss: 100.9234\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.8009 - val_loss: 98.2793\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.6009 - val_loss: 97.8413\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.3295 - val_loss: 96.8761\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.8334 - val_loss: 97.2686\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.8041 - val_loss: 99.0324\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.6624 - val_loss: 95.5050\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.1711 - val_loss: 94.9541\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.3019 - val_loss: 92.8093\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.3318 - val_loss: 92.5049\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.2549 - val_loss: 96.8630\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.9357 - val_loss: 91.5745\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.8841 - val_loss: 90.7755\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.2954 - val_loss: 90.4994\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.7175 - val_loss: 92.3586\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 87.1591 - val_loss: 88.2827\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 80.5510 - val_loss: 96.5794\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  42 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 24174.6141 - val_loss: 13090.9121\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 9725.6909 - val_loss: 4355.5454\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3121.5017 - val_loss: 2486.9561\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1991.7876 - val_loss: 1945.9653\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1659.2265 - val_loss: 1598.3463\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1434.9822 - val_loss: 1387.0249\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1360.8884 - val_loss: 1223.6235\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 967.8367 - val_loss: 1101.4772\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1092.4683 - val_loss: 998.8945\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 867.8732 - val_loss: 918.4050\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 832.6766 - val_loss: 857.5181\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 778.7001 - val_loss: 790.3335\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 763.6844 - val_loss: 735.5107\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 699.7432 - val_loss: 689.5458\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 593.2992 - val_loss: 648.2828\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 542.8362 - val_loss: 611.7877\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 571.5469 - val_loss: 579.6625\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 542.4519 - val_loss: 544.7217\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 517.7998 - val_loss: 519.3497\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 505.9382 - val_loss: 490.3165\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 472.2257 - val_loss: 469.3107\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 463.0028 - val_loss: 451.3570\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 438.0251 - val_loss: 433.3929\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 419.7496 - val_loss: 416.3477\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 438.5180 - val_loss: 403.4292\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 398.0275 - val_loss: 387.9589\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 390.5295 - val_loss: 377.3709\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 390.1610 - val_loss: 365.9554\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 378.1302 - val_loss: 352.0713\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 348.6465 - val_loss: 344.9654\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 356.6669 - val_loss: 336.6216\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 378.3490 - val_loss: 329.2280\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 355.5769 - val_loss: 318.6969\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 350.2042 - val_loss: 314.5314\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 311.3388 - val_loss: 307.3509\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 306.4573 - val_loss: 303.5534\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 293.3568 - val_loss: 294.2979\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 318.8019 - val_loss: 290.1269\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 308.7167 - val_loss: 283.2684\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 288.9349 - val_loss: 278.3939\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.7321 - val_loss: 273.9033\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.4111 - val_loss: 269.7152\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 281.6192 - val_loss: 264.4659\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 286.1767 - val_loss: 260.5928\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 285.9885 - val_loss: 254.5917\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 284.6007 - val_loss: 252.8797\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 266.3565 - val_loss: 247.9223\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 237.6592 - val_loss: 243.8485\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 242.4383 - val_loss: 238.7148\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 262.7760 - val_loss: 235.7173\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 248.8884 - val_loss: 232.4415\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 254.8331 - val_loss: 227.1712\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 262.6493 - val_loss: 226.9547\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 235.3484 - val_loss: 221.3086\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 238.5965 - val_loss: 218.6011\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 226.3078 - val_loss: 216.5489\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.2322 - val_loss: 211.4316\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.3534 - val_loss: 208.9062\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 228.3473 - val_loss: 211.6965\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 255.1390 - val_loss: 202.7055\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.0822 - val_loss: 201.3968\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 216.3038 - val_loss: 196.9122\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 215.8243 - val_loss: 197.6464\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 208.6079 - val_loss: 194.4694\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.8002 - val_loss: 189.7295\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.2948 - val_loss: 188.7646\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206.1787 - val_loss: 186.3644\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.8114 - val_loss: 182.4299\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 185.9830 - val_loss: 182.9085\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 206.0033 - val_loss: 177.5049\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 194.9536 - val_loss: 177.4885\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.5790 - val_loss: 174.3466\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.3877 - val_loss: 171.4534\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.0346 - val_loss: 169.7032\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 203.1483 - val_loss: 168.8266\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.6971 - val_loss: 165.2176\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.5894 - val_loss: 163.9515\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 189.8877 - val_loss: 163.3630\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 184.4985 - val_loss: 160.4763\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 202.7341 - val_loss: 158.8336\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.7249 - val_loss: 157.7148\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.5757 - val_loss: 155.7957\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.6531 - val_loss: 155.2397\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.4807 - val_loss: 152.6415\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 179.8347 - val_loss: 151.1725\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.6848 - val_loss: 150.3728\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.9241 - val_loss: 147.8743\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 196.4301 - val_loss: 146.2738\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.5912 - val_loss: 145.3641\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.0157 - val_loss: 145.1448\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.9495 - val_loss: 142.5224\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 177.4133 - val_loss: 141.1259\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.6538 - val_loss: 139.8512\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.8372 - val_loss: 139.3882\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.9225 - val_loss: 137.7901\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.8825 - val_loss: 135.6182\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.5825 - val_loss: 137.1653\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.4682 - val_loss: 132.3176\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 151.4144 - val_loss: 133.1173\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.2928 - val_loss: 131.0326\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  43 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 593062.1434 - val_loss: 410786.2812\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 382149.2114 - val_loss: 253527.6719\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 232487.4458 - val_loss: 157177.1250\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142930.6425 - val_loss: 96458.2031\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87049.6944 - val_loss: 56449.7539\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 49947.7222 - val_loss: 27278.2070\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 22681.6961 - val_loss: 10222.0693\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8310.5706 - val_loss: 4473.3223\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3907.6263 - val_loss: 3497.9619\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3284.5563 - val_loss: 2879.9292\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2478.5115 - val_loss: 2134.6863\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1658.1832 - val_loss: 1788.4969\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1516.1740 - val_loss: 1574.9528\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1230.4926 - val_loss: 1408.1079\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1255.0709 - val_loss: 1261.8560\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1020.9940 - val_loss: 1153.0364\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 911.8070 - val_loss: 1047.8604\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 810.3207 - val_loss: 961.8557\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 714.5698 - val_loss: 882.5580\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 712.1313 - val_loss: 813.2994\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 629.5943 - val_loss: 751.8297\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 579.2217 - val_loss: 692.9435\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 550.0952 - val_loss: 641.1932\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 440.1197 - val_loss: 593.3395\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 438.0539 - val_loss: 552.0807\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 405.2649 - val_loss: 511.6921\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 393.3267 - val_loss: 476.9864\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 327.7527 - val_loss: 446.5726\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 331.8320 - val_loss: 419.1109\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 296.5985 - val_loss: 395.0024\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 284.9810 - val_loss: 370.9341\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 279.3870 - val_loss: 354.8942\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 271.1057 - val_loss: 330.6400\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 239.5513 - val_loss: 318.5524\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.9641 - val_loss: 299.6855\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.4709 - val_loss: 285.3584\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 218.4868 - val_loss: 278.4183\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.3604 - val_loss: 262.1096\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 213.2285 - val_loss: 252.8152\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.6094 - val_loss: 245.4820\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 215.3151 - val_loss: 235.9351\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 223.4696 - val_loss: 228.5745\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.7480 - val_loss: 222.8406\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 203.3299 - val_loss: 217.8462\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.4661 - val_loss: 211.5208\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.8411 - val_loss: 212.2365\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.2075 - val_loss: 202.8385\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 190.7493 - val_loss: 199.0617\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.1421 - val_loss: 196.4299\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 183.2439 - val_loss: 192.0200\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165.9592 - val_loss: 187.7087\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.9664 - val_loss: 184.6911\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.9493 - val_loss: 182.3666\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.9577 - val_loss: 178.8707\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.8496 - val_loss: 176.0338\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.6021 - val_loss: 173.5034\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.2069 - val_loss: 171.1942\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.9509 - val_loss: 177.1557\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.1684 - val_loss: 167.1306\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.5829 - val_loss: 169.9217\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.4246 - val_loss: 165.6105\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.9795 - val_loss: 162.1302\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.5797 - val_loss: 160.9218\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.8932 - val_loss: 159.4300\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.2947 - val_loss: 158.1613\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.6633 - val_loss: 157.2039\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.0505 - val_loss: 157.6770\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.4073 - val_loss: 154.0222\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.4479 - val_loss: 152.6366\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.6755 - val_loss: 152.0699\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.2585 - val_loss: 150.8609\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.6706 - val_loss: 149.3783\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.4470 - val_loss: 148.5004\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.7212 - val_loss: 147.6442\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.9958 - val_loss: 151.8796\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.9991 - val_loss: 145.7304\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.5914 - val_loss: 144.9521\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.3580 - val_loss: 145.0598\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.9628 - val_loss: 144.6569\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.0371 - val_loss: 146.5840\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 166.2316 - val_loss: 141.5958\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 157.4367 - val_loss: 141.0696\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.9160 - val_loss: 140.1711\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.3949 - val_loss: 144.6790\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.3768 - val_loss: 139.4942\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.8089 - val_loss: 138.8930\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.3163 - val_loss: 140.6981\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.9913 - val_loss: 137.4892\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.2709 - val_loss: 137.5083\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.7407 - val_loss: 136.0193\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.3165 - val_loss: 135.7223\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 153.0647 - val_loss: 135.6996\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.2988 - val_loss: 134.8058\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 157.2078 - val_loss: 137.5790\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 141.5452 - val_loss: 135.0123\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.7815 - val_loss: 133.9509\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.3332 - val_loss: 135.1303\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 168.4147 - val_loss: 135.1721\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.5768 - val_loss: 131.9911\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 154.7109 - val_loss: 132.6080\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  44 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 4949.3902 - val_loss: 3479.6458\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3237.1883 - val_loss: 2157.2903\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1863.4063 - val_loss: 1516.3723\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1357.0913 - val_loss: 1189.8805\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 991.6658 - val_loss: 930.8192\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 922.6579 - val_loss: 779.4155\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 741.8361 - val_loss: 620.3915\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 593.5220 - val_loss: 524.7853\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 498.4571 - val_loss: 449.4291\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 441.2793 - val_loss: 387.8243\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 370.6333 - val_loss: 343.7383\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 362.8487 - val_loss: 310.6689\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 281.1498 - val_loss: 284.4035\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.4143 - val_loss: 259.0758\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 251.3145 - val_loss: 241.7994\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 222.6707 - val_loss: 227.4639\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.3388 - val_loss: 217.2913\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 201.9494 - val_loss: 205.9841\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.8455 - val_loss: 199.0438\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.4862 - val_loss: 191.6864\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.9245 - val_loss: 185.4068\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 175.9658 - val_loss: 185.0701\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.3188 - val_loss: 174.9343\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.3373 - val_loss: 169.6799\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.8663 - val_loss: 166.1136\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.5720 - val_loss: 170.6656\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.3042 - val_loss: 167.0133\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.2437 - val_loss: 156.7437\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.6580 - val_loss: 156.8546\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.0378 - val_loss: 151.4819\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.4526 - val_loss: 148.1869\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.6314 - val_loss: 157.4315\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 155.0512 - val_loss: 146.9440\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.9145 - val_loss: 144.6976\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.9635 - val_loss: 147.4892\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 120.7082 - val_loss: 139.0643\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 140.0491 - val_loss: 140.1874\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.2572 - val_loss: 135.6694\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134.5090 - val_loss: 136.3244\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.2038 - val_loss: 133.0369\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 121.7792 - val_loss: 133.1340\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.9737 - val_loss: 131.0621\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.4959 - val_loss: 132.2681\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.6525 - val_loss: 143.6251\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.4810 - val_loss: 139.2955\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.8047 - val_loss: 127.5191\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.5585 - val_loss: 127.9922\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.4279 - val_loss: 127.4519\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.0103 - val_loss: 126.4159\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.2923 - val_loss: 133.3154\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.4564 - val_loss: 134.4421\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.1743 - val_loss: 123.2670\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.8464 - val_loss: 121.5156\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.1036 - val_loss: 122.7278\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.2170 - val_loss: 122.3343\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.2606 - val_loss: 121.5456\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.4388 - val_loss: 128.3428\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.0193 - val_loss: 125.6334\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.6769 - val_loss: 143.6002\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.7079 - val_loss: 117.5056\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.1254 - val_loss: 117.3144\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.3443 - val_loss: 118.9019\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.1186 - val_loss: 115.7720\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 104.8394 - val_loss: 115.2425\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.6764 - val_loss: 120.5130\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.6795 - val_loss: 114.9157\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 111.2125 - val_loss: 116.9880\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.9393 - val_loss: 116.4628\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.0291 - val_loss: 111.8789\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.3767 - val_loss: 113.4342\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.2837 - val_loss: 113.9241\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.4972 - val_loss: 109.7064\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.4652 - val_loss: 110.2651\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.1357 - val_loss: 114.2092\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.5354 - val_loss: 121.0985\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.8300 - val_loss: 116.1698\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.3885 - val_loss: 110.1317\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.5947 - val_loss: 105.5020\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 104.1767 - val_loss: 109.7084\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.4782 - val_loss: 109.0113\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.2814 - val_loss: 117.2610\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 97.9807 - val_loss: 105.0875\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.1450 - val_loss: 111.8146\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.9712 - val_loss: 103.4965\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.3201 - val_loss: 108.9614\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.2608 - val_loss: 112.1525\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.4782 - val_loss: 103.7956\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.3460 - val_loss: 97.1427\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.7636 - val_loss: 115.5882\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.4891 - val_loss: 120.8881\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1008 - val_loss: 100.0269\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.5893 - val_loss: 97.0817\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.0620 - val_loss: 106.3111\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 82.6990 - val_loss: 102.5899\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 96.6971 - val_loss: 92.4336\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 94.1615 - val_loss: 110.9310\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.2943 - val_loss: 91.0563\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 87.8635 - val_loss: 113.0979\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.9155 - val_loss: 90.1407\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.7664 - val_loss: 91.6701\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  45 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 1655.4734 - val_loss: 890.9327\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 925.1140 - val_loss: 518.0840\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 520.7894 - val_loss: 329.9940\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 334.2849 - val_loss: 234.8189\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 225.4873 - val_loss: 202.0255\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 207.9846 - val_loss: 177.4682\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.7103 - val_loss: 168.8463\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 165.6493 - val_loss: 167.8255\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.1526 - val_loss: 154.5442\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.4141 - val_loss: 153.6089\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.0604 - val_loss: 150.5328\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.9569 - val_loss: 158.1146\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.9072 - val_loss: 139.0847\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.2286 - val_loss: 141.2437\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.0959 - val_loss: 131.5008\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.3710 - val_loss: 131.0376\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.7611 - val_loss: 129.4947\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 122.4307 - val_loss: 133.3931\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 132.7237 - val_loss: 149.9973\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126.5632 - val_loss: 121.5770\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.9927 - val_loss: 132.4558\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.2934 - val_loss: 117.1915\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.9985 - val_loss: 116.1533\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.3105 - val_loss: 113.6061\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.9908 - val_loss: 114.8883\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 116.7603 - val_loss: 109.7958\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.9254 - val_loss: 109.6309\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.6794 - val_loss: 108.4473\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 105.8558 - val_loss: 107.5590\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 99.1487 - val_loss: 116.6614\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.5974 - val_loss: 114.4545\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.7823 - val_loss: 103.9585\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.0429 - val_loss: 109.6529\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.4630 - val_loss: 102.0420\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.7554 - val_loss: 101.6404\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.8692 - val_loss: 100.6731\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.2256 - val_loss: 99.3239\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.0617 - val_loss: 118.3202\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.0597 - val_loss: 97.7750\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.6532 - val_loss: 99.9516\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.9930 - val_loss: 97.5585\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.0605 - val_loss: 96.3539\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.5329 - val_loss: 101.6368\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.7770 - val_loss: 96.4061\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.5382 - val_loss: 95.1497\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.0302 - val_loss: 99.5507\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.7575 - val_loss: 97.7352\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.6589 - val_loss: 94.4373\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 89.8352 - val_loss: 93.9025\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 79.8534 - val_loss: 93.9205\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.4504 - val_loss: 96.3737\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.6802 - val_loss: 93.3010\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.7209 - val_loss: 95.5981\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.3490 - val_loss: 96.9243\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.8404 - val_loss: 94.3236\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.8699 - val_loss: 91.3314\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.7336 - val_loss: 147.4067\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.9014 - val_loss: 104.1597\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.5167 - val_loss: 104.0354\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 89.6096 - val_loss: 92.6503\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.4582 - val_loss: 93.2476\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.7845 - val_loss: 90.6927\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 93.8828 - val_loss: 94.8079\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.3901 - val_loss: 92.6994\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.9988 - val_loss: 88.0917\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.5193 - val_loss: 104.7386\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.5825 - val_loss: 99.7028\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 70.9635 - val_loss: 87.6692\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.4024 - val_loss: 88.1791\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.1183 - val_loss: 93.3369\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 67.6285 - val_loss: 90.0013\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.7776 - val_loss: 88.2716\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 68.2697 - val_loss: 87.8196\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.0509 - val_loss: 89.7100\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.7816 - val_loss: 86.4067\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 74.7192 - val_loss: 86.6057\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.9462 - val_loss: 91.6598\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 76.1661 - val_loss: 85.3694\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.9220 - val_loss: 107.9821\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.2845 - val_loss: 99.1965\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.5957 - val_loss: 84.9660\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 70.3018 - val_loss: 84.8414\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.7185 - val_loss: 83.7561\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 68.9593 - val_loss: 84.4901\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 78.3836 - val_loss: 84.0907\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.5857 - val_loss: 83.6372\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 66.9552 - val_loss: 82.5316\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 71.7696 - val_loss: 83.6593\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 67.3202 - val_loss: 85.6852\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 68.9360 - val_loss: 83.4205\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 75.7849 - val_loss: 86.1650\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 69.6804 - val_loss: 85.5294\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 73.1092 - val_loss: 82.1053\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 67.1644 - val_loss: 80.7449\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 71.4980 - val_loss: 84.2170\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 72.6284 - val_loss: 91.3390\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 62.4751 - val_loss: 83.8759\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.3664 - val_loss: 83.5214\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 72.2283 - val_loss: 89.8895\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 75.8606 - val_loss: 81.1134\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  46 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 14ms/step - loss: 3359.3004 - val_loss: 2010.7982\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 2056.8497 - val_loss: 1522.1757\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1644.1367 - val_loss: 1319.3226\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1428.2825 - val_loss: 1159.3191\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1265.0138 - val_loss: 1024.4100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1028.7461 - val_loss: 911.5447\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 969.7289 - val_loss: 818.2471\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 806.8192 - val_loss: 732.1235\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 796.1998 - val_loss: 675.8195\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 688.9765 - val_loss: 609.8347\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 628.2413 - val_loss: 563.4493\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 575.0889 - val_loss: 526.9588\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 509.8407 - val_loss: 490.3962\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 506.3341 - val_loss: 459.0680\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 457.2256 - val_loss: 441.1345\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 445.0431 - val_loss: 411.2372\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 385.6309 - val_loss: 397.1701\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 388.6846 - val_loss: 369.8615\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 382.6672 - val_loss: 363.1349\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 382.0942 - val_loss: 340.4081\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 356.5100 - val_loss: 323.5243\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 350.6398 - val_loss: 314.3372\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 294.2704 - val_loss: 296.1583\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 258.0705 - val_loss: 287.7479\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 268.8060 - val_loss: 278.7756\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 285.5020 - val_loss: 264.8647\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 247.8735 - val_loss: 254.1604\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 282.7124 - val_loss: 246.8809\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.7899 - val_loss: 236.4165\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 275.1164 - val_loss: 226.7498\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 216.8145 - val_loss: 217.8721\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.9765 - val_loss: 212.0783\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 221.3124 - val_loss: 205.0627\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.5468 - val_loss: 200.0242\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 195.8964 - val_loss: 191.5405\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.0817 - val_loss: 189.7305\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 203.1213 - val_loss: 177.3114\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 181.1742 - val_loss: 174.3167\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.9903 - val_loss: 169.7492\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 170.2958 - val_loss: 170.3780\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.8499 - val_loss: 167.3835\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.4564 - val_loss: 150.6650\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.1409 - val_loss: 147.0195\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 165.8804 - val_loss: 141.8659\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.4116 - val_loss: 142.5531\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.6796 - val_loss: 134.9458\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.3281 - val_loss: 131.0364\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.3482 - val_loss: 132.0086\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.8196 - val_loss: 127.5483\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 136.1386 - val_loss: 122.3565\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 137.9216 - val_loss: 120.2882\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 125.4387 - val_loss: 118.5055\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.6328 - val_loss: 115.4185\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 131.5353 - val_loss: 126.7442\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 130.7760 - val_loss: 111.1843\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.5783 - val_loss: 110.2689\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.9649 - val_loss: 108.6610\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.7566 - val_loss: 105.9365\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.6946 - val_loss: 103.9994\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.2584 - val_loss: 107.7170\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.9788 - val_loss: 103.4611\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.6291 - val_loss: 102.7769\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.8306 - val_loss: 98.6727\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.1571 - val_loss: 98.1620\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.0707 - val_loss: 98.9325\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 102.2761 - val_loss: 99.5309\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.1345 - val_loss: 95.0943\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.0090 - val_loss: 91.8528\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.4546 - val_loss: 101.3834\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.9537 - val_loss: 94.5752\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.5658 - val_loss: 90.0721\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.4780 - val_loss: 91.0523\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 107.2219 - val_loss: 86.8372\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 105.4681 - val_loss: 85.0937\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.4260 - val_loss: 89.9446\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 95.7526 - val_loss: 84.0255\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 98.7652 - val_loss: 80.8962\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.6477 - val_loss: 81.1150\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.3416 - val_loss: 80.3371\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.4549 - val_loss: 78.6860\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.7940 - val_loss: 77.8308\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.4417 - val_loss: 78.0633\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 106.9556 - val_loss: 75.4159\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 90.5087 - val_loss: 79.8436\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 84.3979 - val_loss: 88.6606\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.1812 - val_loss: 74.0232\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.8315 - val_loss: 76.9020\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 85.5009 - val_loss: 75.8177\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.4600 - val_loss: 75.6779\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.6733 - val_loss: 73.6572\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.9744 - val_loss: 75.7760\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.2283 - val_loss: 73.4972\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 84.5942 - val_loss: 74.5161\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.1056 - val_loss: 70.5844\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.3045 - val_loss: 69.6692\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 80.7285 - val_loss: 69.6158\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 75.4889 - val_loss: 71.2319\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.2259 - val_loss: 69.3124\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 81.8880 - val_loss: 69.9837\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.1955 - val_loss: 71.7488\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  47 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 13ms/step - loss: 10822.5560 - val_loss: 1524.3632\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1776.6167 - val_loss: 1722.4319\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1364.0814 - val_loss: 1281.2946\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1412.3983 - val_loss: 1227.4064\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1277.8425 - val_loss: 1142.0737\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1183.1787 - val_loss: 1088.9559\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1028.9450 - val_loss: 1010.4973\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 942.4692 - val_loss: 973.0148\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 971.8511 - val_loss: 896.0013\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 906.0852 - val_loss: 843.3937\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 852.4880 - val_loss: 788.9591\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 742.5418 - val_loss: 738.9796\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 688.8623 - val_loss: 696.5890\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 744.7081 - val_loss: 634.8204\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 679.0491 - val_loss: 592.2488\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 545.3576 - val_loss: 543.5854\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 590.5909 - val_loss: 508.2626\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 509.2958 - val_loss: 462.4895\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 476.9129 - val_loss: 435.3176\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 434.9572 - val_loss: 391.7709\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 403.6225 - val_loss: 356.4674\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 373.5498 - val_loss: 327.2314\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 313.3100 - val_loss: 303.6492\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 319.5651 - val_loss: 275.4782\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 298.6107 - val_loss: 255.8329\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 264.0284 - val_loss: 233.9578\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 228.7762 - val_loss: 216.9661\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.7108 - val_loss: 208.1082\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 217.1595 - val_loss: 190.5125\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 178.9572 - val_loss: 180.0098\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 189.6633 - val_loss: 173.0290\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.2035 - val_loss: 168.8215\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.1707 - val_loss: 157.0542\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.5165 - val_loss: 154.7175\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.3243 - val_loss: 150.2264\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.1600 - val_loss: 145.0634\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.0528 - val_loss: 149.0593\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 140.7800 - val_loss: 144.2680\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 141.4985 - val_loss: 145.0868\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.2422 - val_loss: 138.1524\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.0401 - val_loss: 135.0605\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 123.9341 - val_loss: 138.8861\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 123.1602 - val_loss: 142.5495\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.9968 - val_loss: 133.3975\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.1098 - val_loss: 144.1959\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 142.1214 - val_loss: 133.3430\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.3999 - val_loss: 124.8216\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.8578 - val_loss: 123.5185\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 116.3081 - val_loss: 127.5621\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.2966 - val_loss: 119.4866\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.4225 - val_loss: 122.3368\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.3710 - val_loss: 117.3669\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.6790 - val_loss: 115.4764\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 122.1902 - val_loss: 115.1034\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.3688 - val_loss: 122.4506\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.0961 - val_loss: 113.1755\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 109.8940 - val_loss: 110.7938\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.8987 - val_loss: 110.2268\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.3261 - val_loss: 109.3579\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 107.3337 - val_loss: 109.9941\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.4024 - val_loss: 107.1967\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 101.6946 - val_loss: 106.2350\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.6435 - val_loss: 108.5317\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.4548 - val_loss: 104.2096\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.8935 - val_loss: 108.7815\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.3269 - val_loss: 102.6374\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.1589 - val_loss: 100.7946\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.2463 - val_loss: 104.2437\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.9644 - val_loss: 100.8473\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.4158 - val_loss: 104.1704\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.2891 - val_loss: 106.5264\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.1772 - val_loss: 105.0012\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.9586 - val_loss: 97.3244\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.4594 - val_loss: 97.7299\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.7918 - val_loss: 98.9633\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.9420 - val_loss: 109.1874\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.3169 - val_loss: 111.6608\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.0398 - val_loss: 103.2709\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.3422 - val_loss: 96.2826\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 91.0658 - val_loss: 102.4632\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.9670 - val_loss: 94.4822\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 84.4058 - val_loss: 94.0389\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.6594 - val_loss: 94.5767\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.6226 - val_loss: 93.2386\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 92.1209 - val_loss: 93.1941\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.9403 - val_loss: 93.0034\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.3180 - val_loss: 95.9597\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 78.7420 - val_loss: 93.0525\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 77.0081 - val_loss: 92.3664\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.9683 - val_loss: 92.0863\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 79.5059 - val_loss: 93.1027\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 86.1212 - val_loss: 92.5462\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.3576 - val_loss: 93.7070\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.6778 - val_loss: 92.3601\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.6242 - val_loss: 91.3120\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 78.7303 - val_loss: 94.6873\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.7199 - val_loss: 114.2209\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.4256 - val_loss: 91.5308\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 82.0067 - val_loss: 91.5167\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 77.6728 - val_loss: 95.7244\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  48 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 15ms/step - loss: 20172.4540 - val_loss: 5513.3716\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 5534.7632 - val_loss: 3772.5784\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3313.3207 - val_loss: 2083.7407\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2017.5723 - val_loss: 1331.3633\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1444.2605 - val_loss: 855.3819\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 960.4498 - val_loss: 586.7702\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 629.3833 - val_loss: 479.9225\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 536.2449 - val_loss: 421.6818\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 467.9536 - val_loss: 383.8691\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 536.0759 - val_loss: 348.4802\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 402.0773 - val_loss: 325.2073\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 437.8466 - val_loss: 299.7091\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 379.2421 - val_loss: 283.4578\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 343.5274 - val_loss: 268.7946\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 311.2510 - val_loss: 255.1751\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 317.2018 - val_loss: 243.6061\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 302.0760 - val_loss: 233.8179\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 277.1859 - val_loss: 222.9466\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 280.1012 - val_loss: 216.1902\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 284.0034 - val_loss: 211.9893\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 276.9391 - val_loss: 200.1328\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 240.1249 - val_loss: 196.0750\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 222.2869 - val_loss: 187.7155\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 215.9601 - val_loss: 180.9097\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 220.5809 - val_loss: 175.8854\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 211.6715 - val_loss: 172.9418\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.2087 - val_loss: 166.7425\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 183.6478 - val_loss: 165.2690\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 192.7855 - val_loss: 160.8657\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 163.6398 - val_loss: 154.4218\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.0089 - val_loss: 152.7305\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.8530 - val_loss: 153.8338\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174.1954 - val_loss: 151.5082\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.6307 - val_loss: 142.0218\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.7282 - val_loss: 139.0685\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 164.0480 - val_loss: 136.6320\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 173.4300 - val_loss: 133.2026\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.9052 - val_loss: 131.7791\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.2788 - val_loss: 127.6994\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.1081 - val_loss: 127.7256\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 136.3566 - val_loss: 124.0021\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 147.4963 - val_loss: 122.6219\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.1887 - val_loss: 119.3380\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 129.7553 - val_loss: 122.4759\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 127.0356 - val_loss: 117.4775\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.1975 - val_loss: 112.0277\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 125.4106 - val_loss: 113.1730\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 114.7042 - val_loss: 108.6504\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 115.3935 - val_loss: 106.6469\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 113.7675 - val_loss: 109.1183\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.5829 - val_loss: 104.3191\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 126.3258 - val_loss: 104.6064\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.7976 - val_loss: 101.2747\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.9894 - val_loss: 101.5328\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.3968 - val_loss: 103.6302\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 109.6525 - val_loss: 98.4600\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.6716 - val_loss: 105.3383\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.4366 - val_loss: 102.1739\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.0755 - val_loss: 95.5161\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 96.4607 - val_loss: 95.0438\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.8081 - val_loss: 103.6870\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.5019 - val_loss: 96.6335\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.0748 - val_loss: 93.0945\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.0556 - val_loss: 93.8577\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.0036 - val_loss: 92.4228\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 100.0548 - val_loss: 91.8371\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.7582 - val_loss: 100.8401\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 87.3228 - val_loss: 100.5470\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 90.2790 - val_loss: 93.5365\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 112.2304 - val_loss: 89.9199\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.0871 - val_loss: 89.5240\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.5385 - val_loss: 94.6765\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.7305 - val_loss: 88.5061\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 94.1077 - val_loss: 88.2775\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.7210 - val_loss: 89.9580\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.8953 - val_loss: 90.8221\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 94.3286 - val_loss: 86.7238\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 93.7990 - val_loss: 88.8157\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 100.3799 - val_loss: 86.1686\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 97.7844 - val_loss: 92.1373\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.9558 - val_loss: 95.5054\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 95.7298 - val_loss: 84.6281\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.6589 - val_loss: 85.3942\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.3695 - val_loss: 88.0002\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 83.6273 - val_loss: 86.3893\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 88.0735 - val_loss: 92.0583\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 86.9701 - val_loss: 87.0402\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 85.7130 - val_loss: 82.5677\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 92.2680 - val_loss: 91.4088\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.7906 - val_loss: 82.4640\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 83.4994 - val_loss: 80.7451\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 78.1156 - val_loss: 80.8918\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 94.0591 - val_loss: 80.6853\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 80.6132 - val_loss: 79.4013\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.4016 - val_loss: 80.5304\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 81.1358 - val_loss: 84.5876\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 88.7972 - val_loss: 83.3582\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 90.8903 - val_loss: 83.3647\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 82.9523 - val_loss: 82.4720\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 84.1651 - val_loss: 79.8409\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  49 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 20ms/step - loss: 1734.6988 - val_loss: 443.6637\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 534.5445 - val_loss: 404.1463\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 369.2464 - val_loss: 381.1738\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 366.0865 - val_loss: 304.6070\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 305.5373 - val_loss: 271.7772\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 306.4461 - val_loss: 238.6664\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 247.2830 - val_loss: 227.7677\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 236.2740 - val_loss: 218.8383\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 229.5731 - val_loss: 208.2214\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 241.2949 - val_loss: 216.0282\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 205.9447 - val_loss: 212.0742\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.1841 - val_loss: 186.9015\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 191.9369 - val_loss: 180.7196\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 193.1304 - val_loss: 181.2901\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 174.2884 - val_loss: 185.9454\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 190.1807 - val_loss: 202.0072\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 171.5990 - val_loss: 160.8024\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 194.7092 - val_loss: 157.2761\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 165.5679 - val_loss: 153.7531\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.0095 - val_loss: 148.5095\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.9326 - val_loss: 144.2834\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.1510 - val_loss: 143.6871\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.6158 - val_loss: 139.0055\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 161.1484 - val_loss: 143.8242\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 148.7846 - val_loss: 133.7719\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.7787 - val_loss: 130.8220\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 133.3517 - val_loss: 142.4104\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 142.5846 - val_loss: 136.3078\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.5877 - val_loss: 137.2457\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 131.6331 - val_loss: 123.7298\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 128.6048 - val_loss: 120.2988\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.2238 - val_loss: 120.8217\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 135.3058 - val_loss: 118.9184\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 133.6924 - val_loss: 116.2006\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 134.1627 - val_loss: 115.9885\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 121.2426 - val_loss: 114.5311\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.6683 - val_loss: 118.9746\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 119.9730 - val_loss: 122.7118\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.9174 - val_loss: 111.7385\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.9644 - val_loss: 110.8456\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 105.7090 - val_loss: 118.3512\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.6248 - val_loss: 120.2490\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 118.3068 - val_loss: 108.5640\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.8033 - val_loss: 116.0629\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.6682 - val_loss: 107.6560\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.6590 - val_loss: 113.1882\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.1681 - val_loss: 109.7112\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.3789 - val_loss: 114.7193\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.0361 - val_loss: 121.0999\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.1671 - val_loss: 107.5846\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8388 - val_loss: 106.8382\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.6108 - val_loss: 104.2037\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 104.2520 - val_loss: 104.9159\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.1290 - val_loss: 106.5492\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 113.2966 - val_loss: 107.6706\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.4640 - val_loss: 113.5589\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.7065 - val_loss: 108.4555\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 103.6322 - val_loss: 105.5601\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 99.9194 - val_loss: 118.0440\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.3383 - val_loss: 143.3216\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 124.1589 - val_loss: 150.7826\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.6549 - val_loss: 112.0892\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 125.9543 - val_loss: 111.2011\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.4819 - val_loss: 102.5907\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 107.4695 - val_loss: 105.4122\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 114.8452 - val_loss: 112.6734\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 120.6439 - val_loss: 102.8472\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.0363 - val_loss: 113.6646\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 117.6214 - val_loss: 124.5937\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 103.0733 - val_loss: 102.6985\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 115.4908 - val_loss: 103.3095\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.4031 - val_loss: 101.5518\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 96.0667 - val_loss: 109.5692\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 117.3814 - val_loss: 112.8155\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 111.8815 - val_loss: 104.4930\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 104.9393 - val_loss: 100.6983\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 91.0102 - val_loss: 101.0719\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.0735 - val_loss: 100.9540\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 108.4765 - val_loss: 102.9305\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 98.0141 - val_loss: 105.1002\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 120.3248 - val_loss: 106.2121\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 114.6349 - val_loss: 101.5547\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 118.1621 - val_loss: 101.1038\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.7413 - val_loss: 101.1891\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 108.2477 - val_loss: 100.8920\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 112.8649 - val_loss: 101.1669\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 110.5362 - val_loss: 107.6153\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.5623 - val_loss: 103.0170\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 117.5845 - val_loss: 103.2617\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 119.4182 - val_loss: 102.2426\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 111.2475 - val_loss: 108.3903\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 101.5902 - val_loss: 100.8459\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 97.0507 - val_loss: 99.6288\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105.4964 - val_loss: 103.4107\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 95.6596 - val_loss: 104.9860\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 102.0294 - val_loss: 107.2666\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 108.1216 - val_loss: 142.3487\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 128.0912 - val_loss: 101.5108\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 110.5581 - val_loss: 105.5657\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106.0469 - val_loss: 99.7209\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Training Model #  50 \n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 1s 19ms/step - loss: 332788.3842 - val_loss: 221998.1250\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191549.4007 - val_loss: 122937.1172\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 105690.4609 - val_loss: 58195.3672\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 45116.1785 - val_loss: 19796.1172\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 14073.4892 - val_loss: 4207.8120\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 3006.2333 - val_loss: 1541.3477\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1492.1286 - val_loss: 1272.8370\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1218.6135 - val_loss: 1016.1495\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 1024.1499 - val_loss: 894.2797\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 892.7780 - val_loss: 777.5812\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 807.3473 - val_loss: 688.3751\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 659.3948 - val_loss: 614.9503\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 616.1407 - val_loss: 546.1976\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 531.7413 - val_loss: 490.0701\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 534.1201 - val_loss: 445.0862\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 443.7792 - val_loss: 405.4165\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 395.4122 - val_loss: 373.7958\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 344.1139 - val_loss: 347.7535\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 339.8917 - val_loss: 324.3766\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 348.5669 - val_loss: 305.7794\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 291.8119 - val_loss: 291.1275\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 293.9592 - val_loss: 277.3260\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 270.2333 - val_loss: 266.6422\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 268.5493 - val_loss: 256.8157\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 252.7042 - val_loss: 248.1204\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 234.3825 - val_loss: 240.8624\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 208.2139 - val_loss: 233.9414\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 240.1327 - val_loss: 228.3593\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 233.0955 - val_loss: 223.0915\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 232.6801 - val_loss: 219.2546\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 200.5125 - val_loss: 213.8785\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 223.3410 - val_loss: 210.1897\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 197.1005 - val_loss: 207.5555\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 187.1237 - val_loss: 203.0867\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 200.0695 - val_loss: 203.0792\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 185.9832 - val_loss: 197.2233\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.6884 - val_loss: 194.8044\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.1699 - val_loss: 193.5507\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 191.9376 - val_loss: 189.9325\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 175.3887 - val_loss: 187.8475\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 179.7681 - val_loss: 187.5108\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 172.8943 - val_loss: 184.4414\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 181.5712 - val_loss: 182.9121\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 192.0575 - val_loss: 181.2810\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 159.3031 - val_loss: 181.1043\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 174.7467 - val_loss: 178.0925\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 171.6202 - val_loss: 177.1780\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.5619 - val_loss: 175.5174\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.6289 - val_loss: 175.7903\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.0098 - val_loss: 175.1665\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 172.7971 - val_loss: 172.4297\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 155.9296 - val_loss: 171.7910\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 169.3771 - val_loss: 171.4491\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.4933 - val_loss: 172.8974\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.8573 - val_loss: 170.4162\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 156.4834 - val_loss: 170.1104\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.5080 - val_loss: 169.6352\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 167.4848 - val_loss: 169.5643\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 161.4006 - val_loss: 167.8443\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.7134 - val_loss: 166.9617\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 168.1770 - val_loss: 168.1711\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 146.7455 - val_loss: 166.2644\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 159.4062 - val_loss: 166.4100\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 156.6003 - val_loss: 167.9326\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 160.1436 - val_loss: 164.9175\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 151.7207 - val_loss: 166.1515\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.2494 - val_loss: 164.7184\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 164.5676 - val_loss: 164.7013\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 15ms/step - loss: 151.6276 - val_loss: 164.4008\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.2163 - val_loss: 164.0854\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.4406 - val_loss: 163.9972\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 163.2557 - val_loss: 163.4567\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.9140 - val_loss: 164.2431\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.7919 - val_loss: 162.2408\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 152.4780 - val_loss: 162.1658\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 153.6671 - val_loss: 163.2373\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 144.8078 - val_loss: 161.7052\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 150.6455 - val_loss: 161.9264\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.1858 - val_loss: 160.8137\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 152.4603 - val_loss: 161.5321\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 145.2204 - val_loss: 160.4094\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 153.6087 - val_loss: 161.0465\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 143.2332 - val_loss: 160.9459\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 160.1305 - val_loss: 162.1945\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 143.9295 - val_loss: 159.2740\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 150.3746 - val_loss: 160.5015\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149.7450 - val_loss: 159.5653\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 7ms/step - loss: 147.3738 - val_loss: 162.0465\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 162.7201 - val_loss: 160.0708\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 162.2957 - val_loss: 157.9225\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 135.7877 - val_loss: 158.0027\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 147.2139 - val_loss: 157.6076\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.0257 - val_loss: 157.4420\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 145.0245 - val_loss: 156.9161\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 146.1806 - val_loss: 156.9178\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 139.3563 - val_loss: 157.3800\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 138.4993 - val_loss: 156.9378\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 158.2488 - val_loss: 156.1306\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 149.0906 - val_loss: 156.0754\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 154.8752 - val_loss: 157.3946\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Total Execution Time :  0:08:20.978575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SymIGqUICn3t",
        "outputId": "6a9609c7-d857-4b61-9d00-865cf27e1fd4"
      },
      "source": [
        "# Calculate the Mean of the MSE of 50 models\n",
        "mean_of_mse = stats.mean(list_of_mse)\n",
        "\n",
        "# Calculate the Standard Deviation of the MSE of 50 models\n",
        "std_of_mse = stats.stdev(list_of_mse)\n",
        "\n",
        "# Print the Mean and Standard Deviation of MSE of 50 models\n",
        "print('\\n\\nMean of the MSE of 50 Models : ' , str(mean_of_mse))\n",
        "print('Standard Deviation of MSE of 50 Models : ' , str(std_of_mse))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean of the MSE of 50 Models :  117.63979555900275\n",
            "Standard Deviation of MSE of 50 Models :  36.43211651176892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWNrbkTXCn3v"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81e4fXjdCn3v"
      },
      "source": [
        "#### <font color = green> Comparision of Mean of MSE with Mean of MSE with PART C </font>\n",
        "<table style=\"width:30%\">\n",
        "  <tr>\n",
        "    <th>Mean of MSE of PART A</th>\n",
        "    <th>Mean of MSE of PART B</th>\n",
        "    <th>Mean of MSE of PART C</th>\n",
        "    <th>Mean of MSE of PART D</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>212.13</td>\n",
        "    <td>184.57</td>\n",
        "    <td>132.55</td>\n",
        "    <td>117.63</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "The table above compares the Mean of **MSE for PART A**, **Mean of MSE for PART B**, **Mean of MSE for PART C** and **Mean of MSE for PART D**. As can be seen, the value of Mean of MSE of PART D is marginally smaller than that of PART C and is the smallest value obtained. This shows that the effect of **normalizing the features** as well as **increasing the number of epochs by 2** yield the best results in terms of the performance of the regression model and helps it in finding the line of best fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9az4aJOCn3v"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOSID8wbCn3w"
      },
      "source": [
        "# <font color = blue> END OF PART D</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVIv0YdDCn3w"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuDlR5dmCn3w"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdvr0uttCn3x"
      },
      "source": [
        "# <font color = ac36e3> END NOTE </font>\n",
        "\n",
        "Although the results above table show that the best performance is achieved by normalizing the features, increasing the number of epochs **and** increasing the number of hidden layers, this might not be decisive. Repeating ***TASK 2*** for **PART A**, **PART B**, **PART C** and **PART D** several times shows different results. However, for the purposes of this project, those results are not included. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNRmwRRSCn3x"
      },
      "source": [
        "<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA7z4Lu6Cn3x"
      },
      "source": [
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZsBqmRPCn3y"
      },
      "source": [
        "# <font color = red> END OF NOTEBOOK </font>"
      ]
    }
  ]
}